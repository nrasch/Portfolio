{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7f99024-550d-44ec-b996-b1160b7f2413",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3d7c0e8-4a7a-4565-878e-dd741d6682b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import logging\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# DEBUGGING\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56971103-2c62-4b37-ba4c-8b182fd28df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS\n",
    "ARCHIVED = \"false\"\n",
    "APIKEY = \"1234ABCD\"\n",
    "TEAMID = \"123456\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399c1fe7-ac2a-4f3b-b96a-0444aeebc2e2",
   "metadata": {},
   "source": [
    "# ClickUp API Lookup Code\n",
    "\n",
    "Most things are done in ClickUp (CU) via ID values, so we need a way to collect them into structures we can utilize during ticket creation.  This also helps avoid hardcoding ID values which can change w/ the addition of new teams, ticket statuses, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfcd4c68-579f-4fbd-ae7b-7de33027fd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CULookup:\n",
    "    \"\"\"\n",
    "    A class for handling ClickUp API interactions to manage spaces, folders, and lists.\n",
    "    This class initializes with a predefined structure for ClickUp data and \n",
    "    provides methods to fetch and organize this data from the ClickUp API.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the CULookup instance with necessary data structures and API settings.\n",
    "        \n",
    "        Sets up:\n",
    "        - A nested dictionary for organizing ClickUp data (lookup).\n",
    "        - An empty dictionary for fields (which might be used later for field data).\n",
    "        - Configuration for API requests, including whether to include archived items and API key.\n",
    "        \"\"\"\n",
    "        # Initialize lookup dictionary with predefined structure\n",
    "        self.lookup = {'evisit': {'spaces': {'P&E - General': {'id': 1304101, 'folders': {}}}}}\n",
    "        \n",
    "        # Initialize fields dictionary for storing field data\n",
    "        self.fields = {}\n",
    "        \n",
    "        # Set whether to include archived items in API requests\n",
    "        self.archived = ARCHIVED\n",
    "        \n",
    "        # Set API key for authentication\n",
    "        self.apikey = APIKEY\n",
    "\n",
    "        # Containers for the various CU lookup IDs and values\n",
    "        self.lists = {}\n",
    "        self.teams_cf = {}\n",
    "        self.allocations_cf = {}\n",
    "        self.tasktype_cf = {}\n",
    "        self.release_cf = {}\n",
    "        self.product_cf = {}\n",
    "        self.figma_cf = {}\n",
    "        self.fb_cf = {}\n",
    "        self.trd_cf = {}\n",
    "        self.specialization_cf = {}\n",
    "\n",
    "    \n",
    "    def perform_lookups(self):\n",
    "        \"\"\"\n",
    "        Orchestrates the fetching of folder data for a specific space and updates the lookup structure.\n",
    "\n",
    "        This method calls `lookup_folders()` to get the folder data for 'P&E - General' space \n",
    "        and then updates the class's `lookup` dictionary with this information.\n",
    "        \"\"\"\n",
    "        # Fetch folders for the specified space and update the lookup dictionary\n",
    "        folders = self.lookup_folders()\n",
    "        self.lookup['evisit']['spaces']['P&E - General']['folders'] = folders        \n",
    "\n",
    "    \n",
    "    def lookup_folders(self):\n",
    "        \"\"\"\n",
    "        Retrieve all folders for a specific space from ClickUp and return them structured.\n",
    "\n",
    "        Args:\n",
    "        None (uses predefined space_id)\n",
    "\n",
    "        Returns:\n",
    "        dict: A dictionary where keys are folder names and values are dictionaries \n",
    "              containing 'id' and 'lists' for each folder.\n",
    "\n",
    "        This method constructs an API request to fetch all folders in a given space, \n",
    "        then processes the response to build a structured dictionary including \n",
    "        nested lists for each folder.\n",
    "        \"\"\"\n",
    "        # Initialize dictionary to store folder data\n",
    "        folders = {}\n",
    "\n",
    "        # This is the P&E - General space\n",
    "        space_id = \"1304101\"\n",
    "        \n",
    "        # Construct URL for fetching folders within a specific space\n",
    "        url = \"https://api.clickup.com/api/v2/space/\" + space_id + \"/folder\"\n",
    "        headers = {\"Authorization\": self.apikey}\n",
    "        query = {\"archived\": self.archived}\n",
    "\n",
    "        # Send GET request to fetch folder data\n",
    "        response = requests.get(url, headers=headers, params=query)\n",
    "        data = response.json()\n",
    "\n",
    "        for f in data['folders']:\n",
    "            # Store basic folder information in the dictionary\n",
    "            folders[f['name']] = {'id': f['id']}\n",
    "            \n",
    "            # Lookup lists within each folder\n",
    "            flist = self.lookup_lists(f['id'])\n",
    "            folders[f['name']]['lists'] = flist\n",
    "            \n",
    "        return folders\n",
    "        \n",
    "    def lookup_lists(self, folder_id):\n",
    "        \"\"\"\n",
    "        Fetch and return all lists within a specific ClickUp folder.\n",
    "    \n",
    "        Args:\n",
    "        folder_id (str): The ID of the folder from which to retrieve lists.\n",
    "    \n",
    "        Returns:\n",
    "        dict: A dictionary where keys are list names and values are dictionaries \n",
    "              containing the list's ID.\n",
    "    \n",
    "        This method constructs an API request to fetch all lists in the given folder, \n",
    "        including or excluding archived lists based on the 'archived' attribute. \n",
    "        It then processes the response to build a structured dictionary of lists.\n",
    "        \"\"\"\n",
    "        # Initialize dictionary to store list data for a folder\n",
    "        lists = {}\n",
    "        \n",
    "        # Construct URL for fetching lists within a specific folder\n",
    "        url = \"https://api.clickup.com/api/v2/folder/\" + folder_id + \"/list\"\n",
    "        headers = {\"Authorization\": self.apikey}\n",
    "        query = {\"archived\": self.archived}\n",
    "\n",
    "        # Send GET request to fetch list data\n",
    "        response = requests.get(url, headers=headers, params=query)\n",
    "        data = response.json()\n",
    "        #print(data)\n",
    "        #return\n",
    "\n",
    "        for f in data['lists']:\n",
    "            # Store basic list information in the dictionary\n",
    "            lists[f['name']] = {'id': f['id']}\n",
    "\n",
    "        return lists\n",
    "\n",
    "\n",
    "    def lookup_fields(self, list_id):\n",
    "        \"\"\"\n",
    "        Fetch all fields for a specific list from ClickUp and return them structured.\n",
    "    \n",
    "        Args:\n",
    "        list_id (str): The ID of the list from which to retrieve fields.\n",
    "    \n",
    "        Returns:\n",
    "        dict: A dictionary where keys are field names and values are dictionaries \n",
    "              containing 'id', 'type', and for dropdown fields, 'options'.\n",
    "    \n",
    "        This method constructs an API request to fetch all fields in a given list, \n",
    "        processes the response to build a structured dictionary, with special handling \n",
    "        for dropdown fields to include their options.\n",
    "        \"\"\"\n",
    "        # Initialize an empty dictionary to store field data\n",
    "        fields = {}\n",
    "        \n",
    "        # Construct the API endpoint URL for fetching list fields\n",
    "        url = \"https://api.clickup.com/api/v2/list/\" + list_id + \"/field\"\n",
    "        \n",
    "        # Set up headers with the API key for authentication\n",
    "        headers = {\"Authorization\": self.apikey, \"Content-Type\": \"application/json\"}\n",
    "        \n",
    "        # Define query parameters, including whether to include archived fields\n",
    "        query = {\"archived\": self.archived}\n",
    "    \n",
    "        # Send GET request to the ClickUp API\n",
    "        response = requests.get(url, headers=headers, params=query)\n",
    "        \n",
    "        # Parse the JSON response from the API\n",
    "        data = response.json()\n",
    "        #print(response)\n",
    "        #return\n",
    "\n",
    "        \n",
    "        # Iterate through each field in the response data\n",
    "        for f in data['fields']:\n",
    "            # Store basic field information: name, ID, and type\n",
    "            fields[f['name']] = {'id': f[\"id\"], 'type': f[\"type\"]}\n",
    "            \n",
    "            # Special handling for dropdown fields\n",
    "            if f[\"type\"] == \"drop_down\":\n",
    "                opts = {}\n",
    "                # Create a dictionary of options for dropdown fields\n",
    "                for o in f[\"type_config\"][\"options\"]:\n",
    "                    opts[o[\"name\"]] = {'id': o[\"id\"]}\n",
    "                \n",
    "                # Add the options to the field's data\n",
    "                fields[f['name']][\"options\"] = opts    \n",
    "    \n",
    "        # Update the instance variable with the newly fetched fields\n",
    "        self.fields = fields\n",
    "        \n",
    "        # Return the dictionary of fields\n",
    "        return fields\n",
    "        \n",
    "    \n",
    "    def find_key(self, nested_dict, target_key):\n",
    "        \"\"\"\n",
    "        Recursively search for a key in a nested dictionary structure.\n",
    "    \n",
    "        Args:\n",
    "        nested_dict (dict): The dictionary to search through, which can be nested.\n",
    "        target_key (str): The key you're looking for.\n",
    "    \n",
    "        Returns:\n",
    "        list: A list of values associated with the target key. \n",
    "              If the key is not found, an empty list is returned.\n",
    "    \n",
    "        This method will search through nested dictionaries and lists to find all \n",
    "        instances where the target key exists, collecting their values.\n",
    "        \"\"\"\n",
    "        # List to store all values associated with the target key\n",
    "        results = []\n",
    "    \n",
    "        def search(d):\n",
    "            # If the current item is a dictionary\n",
    "            if isinstance(d, dict):\n",
    "                for key, value in d.items():\n",
    "                    # If the current key matches the target key, add its value to results\n",
    "                    if key == target_key:\n",
    "                        results.append(value)\n",
    "                    # If the value is either a dict or a list, search within it\n",
    "                    if isinstance(value, (dict, list)):\n",
    "                        search(value)\n",
    "            # If the current item is a list\n",
    "            elif isinstance(d, list):\n",
    "                # Recursively search each item in the list\n",
    "                for item in d:\n",
    "                    search(item)\n",
    "    \n",
    "        # Start the recursive search from the nested dictionary\n",
    "        search(nested_dict)\n",
    "        # Return the accumulated results\n",
    "        return results\n",
    "\n",
    "        \n",
    "    def find_path_to_key(self, nested_dict, target_key):\n",
    "        \"\"\"\n",
    "        Recursively find and return the path to a key in a nested dictionary.\n",
    "    \n",
    "        Args:\n",
    "        nested_dict (dict): The nested dictionary to search through.\n",
    "        target_key (str): The key to find the path for.\n",
    "    \n",
    "        Returns:\n",
    "        list or None: A list representing the path to the key if found, \n",
    "                      or None if the key isn't in the dictionary.\n",
    "    \n",
    "        This method searches through nested structures to find the path to \n",
    "        the first occurrence of the target key.\n",
    "        \"\"\"\n",
    "        def search(d, path):\n",
    "            # Check if the current structure is a dictionary\n",
    "            if isinstance(d, dict):\n",
    "                for key, value in d.items():\n",
    "                    # Extend the current path with the current key\n",
    "                    new_path = path + [key]\n",
    "                    # If the key matches the target, return the path\n",
    "                    if key == target_key:\n",
    "                        return new_path\n",
    "                    # If the value is another dictionary or list, continue searching\n",
    "                    if isinstance(value, (dict, list)):\n",
    "                        result = search(value, new_path)\n",
    "                        if result:\n",
    "                            return result\n",
    "            # Check if the current structure is a list\n",
    "            elif isinstance(d, list):\n",
    "                for i, item in enumerate(d):\n",
    "                    # Extend the path with the list index and search the item\n",
    "                    result = search(item, path + [i])\n",
    "                    if result:\n",
    "                        return result\n",
    "            # If no match found, return None\n",
    "            return None\n",
    "        \n",
    "        # Start the search from the root of the nested dictionary with an empty path\n",
    "        path = search(nested_dict, [])\n",
    "        return path\n",
    "\n",
    "    \n",
    "    def find(self, nested_dict, target_key):\n",
    "        \"\"\"\n",
    "        Find both values and paths for a given key within a nested dictionary structure.\n",
    "    \n",
    "        Args:\n",
    "        nested_dict (dict): The nested dictionary to search through.\n",
    "        target_key (str): The key to search for in the dictionary.\n",
    "    \n",
    "        Returns:\n",
    "        dict: A dictionary with two keys:\n",
    "            - 'values': List of all values associated with the target key.\n",
    "            - 'paths': List of paths to each occurrence of the target key within the nested structure.\n",
    "    \n",
    "        This method leverages two other methods:\n",
    "        - `find_key`: To collect all values linked to the target key.\n",
    "        - `find_path_to_key`: To gather all paths leading to the target key.\n",
    "        \"\"\"\n",
    "        # Find all values associated with the target key\n",
    "        vals = self.find_key(nested_dict, target_key)\n",
    "        \n",
    "        # Find all paths to the target key in the nested structure\n",
    "        paths = self.find_path_to_key(nested_dict, target_key)\n",
    "        \n",
    "        # Combine values and paths into a single result dictionary\n",
    "        result = {'values': vals, 'paths': paths}\n",
    "    \n",
    "        return result\n",
    "\n",
    "    \n",
    "    def create_lookup_library(self):\n",
    "        \"\"\"\n",
    "        Populates dictionaries with IDs for ClickUp lists, sublists, and custom fields. This method:\n",
    "        - Fetches and stores IDs for the Master Backlog list and its sublists.\n",
    "        - Initializes custom field data for a specific strategic list.\n",
    "        - Collects IDs for various custom fields like Team, Allocation, Task Type, Planned Release, Product, \n",
    "          Figma Link, Feature Brief, TRD Link, and Engineering Specialization, storing both the field ID \n",
    "          and, where applicable, the IDs of each option within those fields.\n",
    "        This setup allows for quick reference and manipulation of ClickUp data structures in subsequent operations.\n",
    "        \"\"\"\n",
    "        # Collect IDs for the Master Backlog list and its sublists\n",
    "        tmp = self.lookup_lists('90140376790')\n",
    "        for k, v in tmp.items():\n",
    "            # Store the id of the main list\n",
    "            self.lists[k] = v['id']\n",
    "            if 'lists' in tmp[k]:\n",
    "                # If there are sublists, store their IDs as well\n",
    "                for kk, vv in tmp[k]['lists'].items():\n",
    "                    self.lists[kk] = vv['id']\n",
    "    \n",
    "        # Initialize ClickUp Custom Fields (CF) data for Strategic Projects & VOC list\n",
    "        self.lookup_fields('98198843')\n",
    "    \n",
    "        # Collect IDs for Team custom field\n",
    "        self.teams_cf = {}\n",
    "        tmp = self.find(self.fields, \"Team\")\n",
    "        self.teams_cf['id'] = tmp['values'][0]['id']  # Store the main field ID\n",
    "        for k, v in tmp['values'][0]['options'].items():\n",
    "            # Store each option's ID for 'Team' field\n",
    "            self.teams_cf[k] = v['id']\n",
    "    \n",
    "        # Collect IDs for Allocation custom field\n",
    "        self.allocations_cf = {}\n",
    "        tmp = self.find(self.fields, \"Allocation\")\n",
    "        self.allocations_cf['id'] = tmp['values'][0]['id']  # Store the main field ID\n",
    "        for k, v in tmp['values'][0]['options'].items():\n",
    "            # Store each option's ID for 'Allocation' field\n",
    "            self.allocations_cf[k] = v['id']\n",
    "    \n",
    "        # Collect IDs for Task Type custom field\n",
    "        self.tasktype_cf = {}\n",
    "        tmp = self.find(self.fields, \"Task Type\")\n",
    "        self.tasktype_cf['id'] = tmp['values'][0]['id']  # Store the main field ID\n",
    "        for k, v in tmp['values'][0]['options'].items():\n",
    "            # Store each option's ID for 'Task Type' field\n",
    "            self.tasktype_cf[k] = v['id']\n",
    "    \n",
    "        # Collect IDs for Planned Release custom field\n",
    "        self.release_cf = {}\n",
    "        tmp = self.find(self.fields, \"Planned Release\")\n",
    "        self.release_cf['id'] = tmp['values'][0]['id']  # Store the main field ID\n",
    "        for k, v in tmp['values'][0]['options'].items():\n",
    "            # Store each option's ID for 'Planned Release' field\n",
    "            self.release_cf[k] = v['id']\n",
    "    \n",
    "        # Collect IDs for Product custom field\n",
    "        self.product_cf = {}\n",
    "        tmp = self.find(self.fields, \"Product\")\n",
    "        self.product_cf['id'] = tmp['values'][2]['id']  # Note: Using index 2 here, possibly for a specific reason\n",
    "        for k, v in tmp['values'][2]['options'].items():\n",
    "            # Store each option's ID for 'Product' field\n",
    "            self.product_cf[k] = v['id']\n",
    "    \n",
    "        # Collect ID for Figma Link custom field\n",
    "        tmp = self.find(self.fields, \"Figma Link\")\n",
    "        self.figma_cf = {}\n",
    "        self.figma_cf['id'] = tmp['values'][0]['id']  # Store the main field ID\n",
    "    \n",
    "        # Collect ID for Feature Brief custom field\n",
    "        tmp = self.find(self.fields, \"Feature Brief\")\n",
    "        self.fb_cf = {}\n",
    "        self.fb_cf['id'] = tmp['values'][0]['id']  # Store the main field ID\n",
    "    \n",
    "        # Collect ID for TRD Link custom field\n",
    "        tmp = self.find(self.fields, \"TRD Link\")\n",
    "        self.trd_cf = {}\n",
    "        self.trd_cf['id'] = tmp['values'][0]['id']  # Store the main field ID\n",
    "    \n",
    "        # Collect IDs for Engineering Specialization custom field\n",
    "        self.specialization_cf = {}\n",
    "        tmp = self.find(self.fields, \"Engineering Specialization\")\n",
    "        self.specialization_cf['id'] = tmp['values'][0]['id']  # Store the main field ID\n",
    "        for k, v in tmp['values'][0]['options'].items():\n",
    "            # Store each option's ID for 'Engineering Specialization' field\n",
    "            self.specialization_cf[k] = v['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a4257a4-294f-4ae6-bf70-2630f51c693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect CU data\n",
    "cu = CULookup()  # Create an instance of the CULookup class\n",
    "cu.perform_lookups()  # Perform lookups to gather necessary data\n",
    "cu.create_lookup_library()  # Create a library of lookup values for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972563c0-8f76-4d4a-9a3c-1df2baa5c0a8",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0f9c016-df1a-42fd-887d-54c4f4bb229f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['evisit',\n",
       " 'spaces',\n",
       " 'P&E - General',\n",
       " 'folders',\n",
       " 'Master Backlog',\n",
       " 'lists',\n",
       " 'Shield Team']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cu.find_path_to_key(cu.lookup, \"Shield Team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcd00b9e-1e20-489f-ab70-08181ddbb5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'values': [{'id': '901403893627'}],\n",
       " 'paths': ['evisit',\n",
       "  'spaces',\n",
       "  'P&E - General',\n",
       "  'folders',\n",
       "  'Master Backlog',\n",
       "  'lists',\n",
       "  'Shield Team']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cu.find(cu.lookup, \"Shield Team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd1cb33f-fc8c-498a-8679-0979ce985c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '901403893627'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cu.find_key(cu.lookup, \"Shield Team\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d44995f4-3a52-448a-8156-7d754701598b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '57920976-d91a-45dc-b9b7-b0e84cedd9a2', 'Back-end': 'efc13dde-8af8-4943-9054-a70edd923329', 'Front-end': '5478554b-e47d-4dec-82d1-8441bb0fb016', 'CDX': '33326811-f10e-4485-8443-5d9d2d41ab6f'}\n"
     ]
    }
   ],
   "source": [
    "print(cu.specialization_cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedd9372-18b4-4e76-9051-22078dfed4e0",
   "metadata": {},
   "source": [
    "# ClickUp API Ticket Creation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e93e9094-2661-48cf-9581-7cd5289ad6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskMaker2000:\n",
    "    \"\"\"\n",
    "    A class for creating tickets in ClickUp using their API.\n",
    "\n",
    "    This class facilitates the creation of new tasks in ClickUp by providing \n",
    "    an interface to interact with ClickUp's task creation endpoint.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the TaskMaker2000 instance.\n",
    "\n",
    "        Currently, this method does nothing but can be extended for initialization logic.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def create_ticket(self, task):\n",
    "        \"\"\"\n",
    "        Create a new task in ClickUp for the given list.\n",
    "\n",
    "        Args:\n",
    "        task (dict): A dictionary containing all necessary task details. \n",
    "                     Expected keys include:\n",
    "                     - 'list_id': ID of the list where the task should be added\n",
    "                     - 'name': Task name\n",
    "                     - 'markdown_description': Description in markdown format\n",
    "                     - 'assignees': List of user IDs to assign the task to\n",
    "                     - 'group_assignees': List of group IDs to assign the task to\n",
    "                     - 'tags': List of tags for the task\n",
    "                     - 'status': Status of the task\n",
    "                     - 'priority': Priority level\n",
    "                     - 'due_date': Due date for the task (string format)\n",
    "                     - 'points': Points for the task, if applicable\n",
    "                     - 'parent': Parent task ID if this is a subtask\n",
    "                     - 'links_to': List of tasks or items this task links to\n",
    "                     - 'custom_fields': Dictionary of custom field IDs and values\n",
    "                     - more to follow...\n",
    "\n",
    "        Returns:\n",
    "        None. Prints the response from the API, either as JSON or raw if JSON fails.\n",
    "\n",
    "        Raises:\n",
    "        Any exception from the requests module will be caught and the raw response printed.\n",
    "        \"\"\"\n",
    "        # Set up authentication headers for the API request\n",
    "        headers = {'Authorization': APIKEY}\n",
    "        \n",
    "        # Construct the URL for posting a new task to ClickUp\n",
    "        url = \"https://api.clickup.com/api/v2/list/\" + task['list_id'] + \"/task\"\n",
    "        query = {\"custom_task_ids\": \"true\", \"team_id\": TEAMID}\n",
    "        \n",
    "        # Prepare the JSON data for the new task\n",
    "        json_data = {\n",
    "            \"name\": task['name'],\n",
    "            \"markdown_description\": task['markdown_description'],\n",
    "            \"assignees\": task['assignees'],\n",
    "            \"archived\": False,\n",
    "            \"group_assignees\": task['group_assignees'],\n",
    "            \"tags\": task['tags'],\n",
    "            \"status\": task['status'],\n",
    "            \"priority\": task['priority'],\n",
    "            \"due_date\": task['due_date'],\n",
    "            \"due_date_time\": False,\n",
    "            \"time_estimate\": None,\n",
    "            \"start_date\": None,\n",
    "            \"start_date_time\": False,\n",
    "            \"points\": task['points'],\n",
    "            \"notify_all\": False,\n",
    "            \"parent\": task['parent'],\n",
    "            \"links_to\": task['links_to'],\n",
    "            \"check_required_custom_fields\": False,\n",
    "            \"custom_fields\": task['custom_fields']\n",
    "        }\n",
    "\n",
    "        # Send POST request to create the task\n",
    "        response = requests.post(url, headers=headers, json=json_data)\n",
    "        \n",
    "        # Try to format and print the response as JSON\n",
    "        try:\n",
    "            #json_object = json.dumps(response.json(), indent=4) \n",
    "            return response.json()\n",
    "        except:\n",
    "            # If JSON formatting fails, print the raw response\n",
    "            return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d743f8-5946-45a8-849b-a2604b76a4e3",
   "metadata": {},
   "source": [
    "# CREATING THE TICKETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8d8901-2afd-426a-bcf6-814b68618018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARSE TICKET JSON, INITIALIZE THE CULOOKUP OBJECT, CREATE TICKETS, PRINT RESULT REPORT\n",
    "\n",
    "# Imports\n",
    "import json  # Import the JSON module to work with JSON data\n",
    "\n",
    "# Local variables\n",
    "err = False  # Initialize an error flag to track if any errors occur\n",
    "target_cu_list = 'Strategic Proj. & VOC'  # Define the target list for ClickUp (CU) tickets\n",
    "parent_cu_ticket = '86b210jpx'  # Define the parent ticket ID to add new tickets to\n",
    "created_tickets = {}  # Dictionary to store successfully created tickets\n",
    "skipped_tickets = {}  # Dictionary to store tickets that could not be created\n",
    "\n",
    "# Opening JSON file with ticket data\n",
    "data_file = 'data/ticket_data_both.json'  # Specify the path to the JSON file containing ticket data\n",
    "try:\n",
    "    f = open(data_file)  # Attempt to open the JSON file\n",
    "\n",
    "    # Returns JSON object as a dictionary\n",
    "    data = json.load(f)  # Load the JSON data into a Python dictionary\n",
    "    \n",
    "    # Closing file\n",
    "    f.close()  # Close the file after loading the data\n",
    "except:\n",
    "    # Handle any errors that occur while opening the file\n",
    "    print(f\"Error opening {data_file}.  Aborting.\")  # Print an error message\n",
    "    err = True  # Set the error flag to True\n",
    "\n",
    "if err == False:  # Proceed only if no errors occurred importing the JSON data\n",
    "    # Info\n",
    "    print(f\"Processing `{data_file}` with {len(data)} records.\")  # Print the number of records being processed\n",
    "\n",
    "    for i in range(len(data)):  # Loop through each record in the data\n",
    "        # Assign next record from the JSON ticket data\n",
    "        t = data[i]  # Get the current ticket record\n",
    "    \n",
    "        # Status message for next record in the loop\n",
    "        print(f\"Processing record {i} with title '{t['Ticket Title']}'\")  # Print the title of the current ticket\n",
    "        \n",
    "        # Apply manual fixes for bad data...\n",
    "        t['Release'] = \"March 2025\"  # Set a default release date for the ticket\n",
    "    \n",
    "        # Populate the ticket details to be sent to the CU API\n",
    "        task = {\n",
    "            \"list_id\": cu.lists[target_cu_list],  # Get the list ID for the target CU list\n",
    "            \"name\": t['Ticket Title'],  # Set the ticket title\n",
    "            \"markdown_description\": t['Ticket Description'],  # Set the ticket description\n",
    "            \"assignees\": None,  # No specific assignees\n",
    "            \"group_assignees\": None,  # No group assignees\n",
    "            \"tags\": [],  # Initialize an empty list for tags\n",
    "            \"status\": \"READY FOR DEVELOPMENT\",  # Set the initial status of the ticket\n",
    "            \"priority\": 3,  # Set the priority level\n",
    "            \"due_date\": None,  # No due date specified\n",
    "            \"points\": t['Points'],  # Set the points for the ticket\n",
    "            \"parent\": parent_cu_ticket,  # Set the parent ticket ID\n",
    "            \"links_to\": None,  # No links specified\n",
    "            \"custom_fields\": [  # Populate custom fields with relevant data\n",
    "                {\"id\": cu.allocations_cf['id'], \"value\": cu.allocations_cf[t['Allocation']]},\n",
    "                {\"id\": cu.teams_cf['id'], \"value\": cu.teams_cf[t['Team']]},\n",
    "                {\"id\": cu.tasktype_cf['id'], \"value\": cu.tasktype_cf[t['Task Type']]},\n",
    "                {\"id\": cu.release_cf['id'], \"value\": cu.release_cf[t['Release']]},\n",
    "                {\"id\": cu.product_cf['id'], \"value\": cu.product_cf[t['Product']]},\n",
    "                {\"id\": cu.figma_cf['id'], \"value\": t['Figma Link']},\n",
    "                {\"id\": cu.specialization_cf['id'], \"value\": cu.specialization_cf[t['Specialization']]},\n",
    "                {\"id\": cu.fb_cf['id'], \"value\": t['Feature Brief']},\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "        # Create ticket maker class\n",
    "        tm = TaskMaker2000()  # Instantiate the TaskMaker2000 class to handle ticket creation\n",
    "        \n",
    "        # Create the new ticket and assign the response to a variable for processing\n",
    "        result = tm.create_ticket(task)  # Call the create_ticket method with the task details\n",
    "    \n",
    "        # Logic to handle ticket creation results\n",
    "        if result.get('err') is not None:  # Check if there was an error in ticket creation\n",
    "            skipped_tickets[t['Ticket Title']] = result  # Store the error result in skipped_tickets\n",
    "        else:\n",
    "            created_tickets[result['name']] = result['id']  # Store the successfully created ticket\n",
    "\n",
    "    # Print post-import report\n",
    "    print(\"\\n**All imports complete!**\")  # Indicate that the import process is complete\n",
    "    print(\"Import errors list:\")  # Print header for errors\n",
    "    for k, v in skipped_tickets.items():  # Loop through skipped tickets\n",
    "        print(f\"\\t * {k} :: {v}\")  # Print each skipped ticket and its error\n",
    "    print(\"Import successful list:\")  # Print header for successful imports\n",
    "    for k, v in created_tickets.items():  # Loop through created tickets\n",
    "        print(f\"\\t * {k} :: {v}\")  # Print each successfully created ticket and its ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9316cee2-e902-4174-8490-c71174e778a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE TICKET CREATION RESULTS REPORT TO DISK\n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.now()\n",
    "counter = 1  # Initialize a counter to keep track of file versions\n",
    "\n",
    "# Create the initial filename using the current date and the counter\n",
    "fname = now.strftime(\"%Y-%m-%d\") + \"_ticket_creation_results_\" + str(counter) + \".txt\"\n",
    "\n",
    "# Check if the file with the current filename already exists\n",
    "while os.path.exists(fname):\n",
    "    counter += 1  # Increment the counter if the file exists\n",
    "    # Create a new filename with the updated counter\n",
    "    fname = now.strftime(\"%Y-%m-%d\") + \"_ticket_creation_results_\" + str(counter) + \".txt\"\n",
    "    \n",
    "# Open the file for writing.\n",
    "with open(fname, \"w\") as f:\n",
    "    # Write a header indicating that all imports are complete\n",
    "    f.write(\"**All imports complete!**\\n\\n\")\n",
    "    \n",
    "    # Write a section header for import errors\n",
    "    f.write(\"Import errors list:\\n\")\n",
    "    # Iterate over the skipped_tickets dictionary and write each key-value pair to the file\n",
    "    for k, v in skipped_tickets.items():\n",
    "        f.write(f\"\\t * {k} :: {v}\\n\")  # Format the output for each skipped ticket\n",
    "    \n",
    "    # Write a section header for successful imports\n",
    "    f.write(\"Import successful list:\\n\")\n",
    "    # Iterate over the created_tickets dictionary and write each key-value pair to the file\n",
    "    for k, v in created_tickets.items():\n",
    "        f.write(f\"\\t * {k} :: {v}\\n\")  # Format the output for each successfully created ticket"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5d74b985-49f8-4530-87fe-8abf6c0b78dc",
   "metadata": {},
   "source": [
    "**All imports complete!**\n",
    "\n",
    "Import errors list:\n",
    "\t * Bad Ticket Data - TESTING :: {'err': 'not a valid points selection', 'ECODE': 'ITEM_222'}\n",
    "Import successful list:\n",
    "\t * Good Ticket Data - TESTING :: 86b36qcna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4723e702-bf4f-4167-8d78-03f1ce24e27f",
   "metadata": {},
   "source": [
    "# ADDING DEPENDENCIES\n",
    "\n",
    "### ToDo:  Write results to disk & improve output formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9429cdd2-6276-43b9-93cb-6b80e2d49d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv  # Import the CSV module to handle CSV file operations\n",
    "\n",
    "# Define CSV path and dependency container\n",
    "data_file = \"data/Depends Export for Forms Epic Dec 16.csv\"  # Path to the CSV file\n",
    "data_depends = {}  # Dictionary to store dependencies\n",
    "\n",
    "with open(data_file, 'r') as csv_file:  # Open the CSV file in read mode\n",
    "    csv_reader = csv.reader(csv_file)  # Create a CSV reader object\n",
    "    for row in csv_reader:  # Iterate through each row in the CSV file\n",
    "        data_depends[row[1]] = row[0]  # Map the second column (index 1) to the first column (index 0)\n",
    "\n",
    "# Print the resulting dictionary to see what was collected\n",
    "# print(data_depends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d0e3c7-20c1-4688-ad03-70ce60ed575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track if we have a JSON error\n",
    "err = False\n",
    "\n",
    "# Path to the JSON file containing ticket data\n",
    "data_file = 'data/Forms_sprint_tickets_for_clickup_new.json'  \n",
    "try:\n",
    "    f = open(data_file)  # Attempt to open the JSON file\n",
    "\n",
    "    # Returns JSON object as a dictionary\n",
    "    data = json.load(f)  # Load the JSON data into a Python dictionary\n",
    "    \n",
    "    # Closing file\n",
    "    f.close()  # Close the file after loading the data\n",
    "except:\n",
    "    # Handle any errors that occur while opening the file\n",
    "    print(f\"Error opening {data_file}. Aborting.\")  # Print an error message\n",
    "    err = True  # Exit the script if file cannot be opened\n",
    "\n",
    "\n",
    "# Add dependency info to the CU tickets if the JSON import suceeded\n",
    "if err == False:\n",
    "    for t in range(len(data)):\n",
    "        # Pull ticket title\n",
    "        ticket = data[t]['Ticket Title']\n",
    "        # Skip over tickets with no dependency information\n",
    "        try:\n",
    "            # Split the dependency string into items, stripping any extra whitespace\n",
    "            items = [x.strip() for x in data[t]['Ticket Depends On'].split(\",\")]\n",
    "            \n",
    "            print(f\"Adding {len(items)} dependencies for {ticket}.\")\n",
    "            \n",
    "            # Create API URL; assumes 'data_depends' is a dictionary mapping ticket titles to task IDs\n",
    "            url = f\"https://api.clickup.com/api/v2/task/{data_depends[ticket]}/dependency\"\n",
    "            \n",
    "            # For each dependency, create payload and submit\n",
    "            for i in items:\n",
    "                # Construct payload for API call\n",
    "                payload = { \"depends_on\": data_depends[i] }\n",
    "                headers = {\n",
    "                    \"accept\": \"application/json\",\n",
    "                    \"content-type\": \"application/json\",\n",
    "                    \"Authorization\": \"pk_26286723_BS74MJRX48EO255BQ75VHQTZNG5NXQ88\"\n",
    "                }\n",
    "                # Make the call to the CU API and record the response\n",
    "                response = requests.post(url, json=payload, headers=headers)\n",
    "                print(response.text)\n",
    "        except:\n",
    "            # If there's no 'Ticket Depends On' key or other errors, this will catch them\n",
    "            print(f\"No dependencies for {ticket}.\")\n",
    "        finally:\n",
    "            # Print a new line for better readability in console output\n",
    "            print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
