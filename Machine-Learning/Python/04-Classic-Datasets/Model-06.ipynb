{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#IMDB-Movie-Review-Sentiment-Classification\" data-toc-modified-id=\"IMDB-Movie-Review-Sentiment-Classification-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>IMDB Movie Review Sentiment Classification</a></span></li><li><span><a href=\"#Purpose\" data-toc-modified-id=\"Purpose-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Purpose</a></span></li><li><span><a href=\"#Process\" data-toc-modified-id=\"Process-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Process</a></span></li><li><span><a href=\"#Configure-notebook-and-import-libraries\" data-toc-modified-id=\"Configure-notebook-and-import-libraries-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Configure notebook and import libraries</a></span></li><li><span><a href=\"#Examine-the-data\" data-toc-modified-id=\"Examine-the-data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Examine the data</a></span></li><li><span><a href=\"#Cleaning-and-preprocessing\" data-toc-modified-id=\"Cleaning-and-preprocessing-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Cleaning and preprocessing</a></span></li><li><span><a href=\"#Bag-of-words-feature-creation\" data-toc-modified-id=\"Bag-of-words-feature-creation-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Bag-of-words feature creation</a></span></li><li><span><a href=\"#Model-development\" data-toc-modified-id=\"Model-development-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Model development</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-validation-data-set\" data-toc-modified-id=\"Create-validation-data-set-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Create validation data set</a></span></li><li><span><a href=\"#Initial-pass\" data-toc-modified-id=\"Initial-pass-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Initial pass</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>IMDB Movie Review Sentiment Classification</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left; margin-right: 15px; width: 30%; height: 30%;\" src=\"images/imdb.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "The overall goal of this set of write-ups is to explore a number of machine learning algorithms utilizing natural language processing (NLP) to classify the sentiment in a set of IMDB movie reviews.\n",
    "\n",
    "The specific goals of this write-up include:\n",
    "1. Define the model development process \n",
    "2. Explore and prepare the data\n",
    "3. Create the initial, simple, baseline NLP regression model to classify IMDB movie review sentiments\n",
    "\n",
    "This series of write-ups is inspired by the Kaggle [\n",
    "Bag of Words Meets Bags of Popcorn](https://www.kaggle.com/c/word2vec-nlp-tutorial) competition.    \n",
    "\n",
    "Dataset source:  [IMDB Movie Reviews](https://www.kaggle.com/c/word2vec-nlp-tutorial/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process\n",
    "\n",
    "We'll utilize the following process to guide us through this and the following write-ups on the IDMB movie review dataset:\n",
    "\n",
    "1. Problem definition\n",
    "2. Evaluation Strategy\n",
    "3. Baseline model(s)\n",
    "4. Data validation\n",
    "5. Model development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure notebook and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T21:08:44.796666Z",
     "start_time": "2018-09-18T21:08:44.793666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import set_option\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# http://www.nltk.org/index.html\n",
    "# pip install nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "# pip install BeautifulSoup4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Opens a GUI that allows us to download the NLTK data\n",
    "#nltk.download()\n",
    "\n",
    "dataPath = os.path.join('.', 'datasets', 'imdb_movie_reviews')\n",
    "labeledTrainData = os.path.join(dataPath, 'labeledTrainData.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the data\n",
    "\n",
    "If we open the training data file in a text editor we can see that:\n",
    "* A header row exists with the values 'id\tsentiment\treview'\n",
    "* The values appear to be separated by tabs\n",
    "* There are double quotes around the review text as well as within the contents of the review text\n",
    "\n",
    "Based on the last point we'll tell Pandas to avoid quoting with the parameter `quoting = 3`.\n",
    "\n",
    "Let's go ahead and read the test data file into a Pandas DataFrame and then explore the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(labeledTrainData, sep = '\\t', header = 0, quoting = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shape and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           object\n",
       "sentiment    int64 \n",
       "review       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inspect a sub sample of the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"319_1\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"A friend of mine bought this film for £1, and even then it was grossly overpriced. Despite featuring big names such as Adam Sandler, Billy Bob Thornton and the incredibly talented Burt Young, this film was about as funny as taking a chisel and hammering it straight through your earhole. It uses tired, bottom of the barrel comedic techniques - consistently breaking the fourth wall as Sandler talks to the audience, and seemingly pointless montages of 'hot girls'.&lt;br /&gt;&lt;br /&gt;Adam Sandler plays a waiter on a cruise ship who wants to make it as a successful comedian in order to become successful with women. When the ship's resident comedian - the shamelessly named 'Dickie' due to his unfathomable success with the opposite gender - is presumed lost at sea, Sandler's character Shecker gets his big break. Dickie is not dead, he's rather locked in the bathroom, presumably sea sick.&lt;br /&gt;&lt;br /&gt;Perhaps from his mouth he just vomited the worst film of all time.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"8713_10\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"&lt;br /&gt;&lt;br /&gt;This movie is full of references. Like \\\"Mad Max II\\\", \\\"The wild one\\\" and many others. The ladybug´s face it´s a clear reference (or tribute) to Peter Lorre. This movie is a masterpiece. We´ll talk much more about in the future.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"2486_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"What happens when an army of wetbacks, towelheads, and Godless Eastern European commies gather their forces south of the border? Gary Busey kicks their butts, of course. Another laughable example of Reagan-era cultural fallout, Bulletproof wastes a decent supporting cast headed by L Q Jones and Thalmus Rasulala.\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  sentiment  \\\n",
       "8   \"319_1\"    0           \n",
       "9   \"8713_10\"  1           \n",
       "10  \"2486_3\"   0           \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   review  \n",
       "8   \"A friend of mine bought this film for £1, and even then it was grossly overpriced. Despite featuring big names such as Adam Sandler, Billy Bob Thornton and the incredibly talented Burt Young, this film was about as funny as taking a chisel and hammering it straight through your earhole. It uses tired, bottom of the barrel comedic techniques - consistently breaking the fourth wall as Sandler talks to the audience, and seemingly pointless montages of 'hot girls'.<br /><br />Adam Sandler plays a waiter on a cruise ship who wants to make it as a successful comedian in order to become successful with women. When the ship's resident comedian - the shamelessly named 'Dickie' due to his unfathomable success with the opposite gender - is presumed lost at sea, Sandler's character Shecker gets his big break. Dickie is not dead, he's rather locked in the bathroom, presumably sea sick.<br /><br />Perhaps from his mouth he just vomited the worst film of all time.\"  \n",
       "9   \"<br /><br />This movie is full of references. Like \\\"Mad Max II\\\", \\\"The wild one\\\" and many others. The ladybug´s face it´s a clear reference (or tribute) to Peter Lorre. This movie is a masterpiece. We´ll talk much more about in the future.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "10  \"What happens when an army of wetbacks, towelheads, and Godless Eastern European commies gather their forces south of the border? Gary Busey kicks their butts, of course. Another laughable example of Reagan-era cultural fallout, Bulletproof wastes a decent supporting cast headed by L Q Jones and Thalmus Rasulala.\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Don't truncate\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "df[8:11].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears there is a lot of noise in the `review` column we are going to have to deal with:  punctuation, html, escaped double quotes, currency symbols, and so forth.  \n",
    "\n",
    "Two of the reviews seem to have a clear sentiment, which will hopefully allow the model to train and learn well against:\n",
    "* Row 8 :: \"This movie is a masterpiece.\" --> Clearly positive\n",
    "* Row 10 :: \"... the worst film of all time.\" --> Clearly negative\n",
    "\n",
    "And then we have Row[10] which even as a human I wouldn't be 100% sure if they were being negative and/or sarcastic but in a positive or snarky way.  I would assume this type of review is going to give our learning algorithm some issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "0    12500\n",
       "1    12500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('sentiment').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an even split of likes and dislikes; no one classification has a skewed representation in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ID distribution\n",
    "\n",
    "Kaggle's site has this to say about the ID column:\n",
    "* id - Unique ID of each review\n",
    "\n",
    "It isn't clear; however, if each review is from a unique author, or we have potentially multiple reviews written by the same person.\n",
    "\n",
    "It appears that perhaps the first part of the ID before the underscore might identify the author, and the second part of the ID after the underscore might be the Nth review from that author.\n",
    "\n",
    "We can explore this theory using Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for dupes against the raw ID values\n",
    "df['id'].value_counts().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [5814, 8]\n",
       "Name: id, dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the ID on the underscore\n",
    "split = df['id'].str.replace('\"', '').str.split('_')\n",
    "\n",
    "# Take a look at a sample\n",
    "split.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:\n",
      " (12500,) \n",
      "\n",
      "First five:\n",
      " 1253    2\n",
      "132     2\n",
      "6698    2\n",
      "8472    2\n",
      "83      2\n",
      "dtype: int64 \n",
      "\n",
      "Last five:\n",
      " 9994    2\n",
      "590     2\n",
      "1990    2\n",
      "5863    2\n",
      "6059    2\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pull out the first part of the ID values using a list comprehension, and place results into a Pandas Series object\n",
    "ids = pd.Series([x[0] for x in split])\n",
    "\n",
    "# Let's see if the number of records has changed\n",
    "print(\"Shape:\\n\", ids.value_counts(ascending = False).shape, \"\\n\")\n",
    "print(\"First five:\\n\", ids.value_counts(ascending = False).head(5), \"\\n\")\n",
    "print(\"Last five:\\n\", ids.value_counts(ascending = False).tail(5), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our theory is correct--which it may not be--then each review author has exactly two entries present in the training observations.  This still provides us with a wide range (12500 in fact) of writing styles, word compositions, and so forth.  It also mitigates the possibility that we might have a few authors with a large number of reviews that would skew the algorithm's ability to generalize to unseen observations.\n",
    "\n",
    "If our theory is incorrect then we simply have 25,000 unique reviews each written by a different author, and this can only help the model to generalize.\n",
    "\n",
    "Just for fun; however, let's pick out two reviews by the same author, and see if the writing styles are similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10936</th>\n",
       "      <td>\"12486_2\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Rich ditzy Joan Winfield (a woefully miscast Bette Davis) is engaged to be married to stupid egotistical Allen Brice (Jack Carson looking lost). Her father (Eugene Palette) is determined to stop the marriage and has her kidnapped by pilot Steve Collins (James Cagney. Seriously). They crash land in the desert and hate each other but (sigh) start falling in love.&lt;br /&gt;&lt;br /&gt;This seems to be getting a high rating from reviewers here only because Cagney and Davis are in it. They were both brilliant actors but they were known for dramas NOT comedy and this movie shows why! The script is just horrible--there's not one genuine laugh in the entire movie. The running joke in this has Cagney and Davis falling rump first in a cactus (this is done THREE TIMES!). Only their considerable talents save them from being completely humiliated. As it is they both do their best with the lousy material. Cagney tries his best with his lines and Davis screeches every line full force but it doesn't work. Carson has this \\\"what the hell\\\" look on his face throughout the entire movie (probably because his characters emotions change in seconds). Only Palette with his distinctive voice and over the top readings manges to elicit a few smiles. But, all in all, this was dull and laughless--a real chore to sit through. This gets two stars only for Cagney and Davis' acting and some beautiful cinematography but really--it's not worth seeing. Cagney and Davis hated this film in later years and you can see why.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11427</th>\n",
       "      <td>\"12486_7\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Well, this film is a difficult one really. To be straight with you, this film doesn't contain much of a riveting story, nore does it make u 'want' to know how it'll end...but I'll tell you something now...never have I been as tense and jumped up before in my life! This film sure does deliver the jumps and thrills! To be fair, I did watch it at almost midnight so I was kinda sleepy anyway, so maybe that explains why I was jumpy...or maybe it's because this film does deliver in that aspect! It's basically about a couple who lose their child in a tragic event. They decide to move away and rent a cabin looking thing in the mountains...all looks peaceful and calm until they have their first visitors (i think it's it's the sister of the main character, and she brings along her husband)...during the night, the husband hears noises...checks it out, and thats when things start to go really really wrong...they don't stay for another day and tell the couple they should leave asap as something isn't right...to cut a long story short...eventually they find out what has happened in that house in the past few years and decide it needs to be taken care of.&lt;br /&gt;&lt;br /&gt;It's not a Hollywood blockbuster, nore does it have a huge budget, but please don't let that put you off. It's creepy, tense and very very jumpy! Just give it a try :)\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  sentiment  \\\n",
       "10936  \"12486_2\"  0           \n",
       "11427  \"12486_7\"  1           \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              review  \n",
       "10936  \"Rich ditzy Joan Winfield (a woefully miscast Bette Davis) is engaged to be married to stupid egotistical Allen Brice (Jack Carson looking lost). Her father (Eugene Palette) is determined to stop the marriage and has her kidnapped by pilot Steve Collins (James Cagney. Seriously). They crash land in the desert and hate each other but (sigh) start falling in love.<br /><br />This seems to be getting a high rating from reviewers here only because Cagney and Davis are in it. They were both brilliant actors but they were known for dramas NOT comedy and this movie shows why! The script is just horrible--there's not one genuine laugh in the entire movie. The running joke in this has Cagney and Davis falling rump first in a cactus (this is done THREE TIMES!). Only their considerable talents save them from being completely humiliated. As it is they both do their best with the lousy material. Cagney tries his best with his lines and Davis screeches every line full force but it doesn't work. Carson has this \\\"what the hell\\\" look on his face throughout the entire movie (probably because his characters emotions change in seconds). Only Palette with his distinctive voice and over the top readings manges to elicit a few smiles. But, all in all, this was dull and laughless--a real chore to sit through. This gets two stars only for Cagney and Davis' acting and some beautiful cinematography but really--it's not worth seeing. Cagney and Davis hated this film in later years and you can see why.\"  \n",
       "11427  \"Well, this film is a difficult one really. To be straight with you, this film doesn't contain much of a riveting story, nore does it make u 'want' to know how it'll end...but I'll tell you something now...never have I been as tense and jumped up before in my life! This film sure does deliver the jumps and thrills! To be fair, I did watch it at almost midnight so I was kinda sleepy anyway, so maybe that explains why I was jumpy...or maybe it's because this film does deliver in that aspect! It's basically about a couple who lose their child in a tragic event. They decide to move away and rent a cabin looking thing in the mountains...all looks peaceful and calm until they have their first visitors (i think it's it's the sister of the main character, and she brings along her husband)...during the night, the husband hears noises...checks it out, and thats when things start to go really really wrong...they don't stay for another day and tell the couple they should leave asap as something isn't right...to cut a long story short...eventually they find out what has happened in that house in the past few years and decide it needs to be taken care of.<br /><br />It's not a Hollywood blockbuster, nore does it have a huge budget, but please don't let that put you off. It's creepy, tense and very very jumpy! Just give it a try :)\"                                                                                                                                                                    "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = df[ df['id'].str.contains('12486_') ]\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the writing styles present in the two samples above the theory that these were written by the same author seems to be weakened.  For example, the second sample utilizes '...' a number of times, but we don't see that present in the first sample.  Likewise the first sample uses all uppercase characters for emphasis, but there are none present in the second sample.  And finally, the use (or misuse) of grammar does not match between the two entries either.\n",
    "\n",
    "We can also examine the second part of the ID column and look for patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     5100\n",
      "10    4732\n",
      "8     3009\n",
      "4     2696\n",
      "7     2496\n",
      "3     2420\n",
      "2     2284\n",
      "9     2263\n"
     ]
    }
   ],
   "source": [
    "# Pull out the second part of the ID values using a list comprehension, and place results into a Pandas Series object\n",
    "ids = pd.Series([x[1] for x in split])\n",
    "\n",
    "#Examine the distribution\n",
    "print(ids.value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x6c32828>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visually inspect the distribution\n",
    "plt.plot(ids.value_counts().sort_index(ascending = True, inplace = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There really doesn't see to be a meaningful pattern here, so we'll move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and preprocessing\n",
    "\n",
    "Now that we have a handle on what the data looks like we can begin the cleaning and preprocessing.  Since we are going to implement a [`bag-of-words model`](https://en.wikipedia.org/wiki/Bag-of-words_model) (covered in more detail below) we want to turn each review into a collection of individual words.  \n",
    "\n",
    "So, first let's find a \"messy\" review full of HTML, punctuation, and other items we can review as we apply each step of the cleaning, and see how things are going."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'108    \"The question, when one sees a movie this bad, is not necessarily, \\\\\"How did a movie this bad get made?\\\\\" or even, \\\\\"Why did I see this awful in the first place?\\\\\" but, \\\\\"What have I learned from this experience?\\\\\" Here\\'s what I learned:<br /><br />- Just because the \\\\\"rules\\\\\" of horror movies have been catalogued and satirized countless times in the last ten years doesn\\'t mean someone won\\'t go ahead and make a movie that uses ALL of them, without a shred of humor or irony.<br /><br />- If your movie has to be described as **loosely** based on the video game, you have script problems.<br /><br />- The black character may not always die first, but the Asian character does always know kung-fu.<br /><br />- While you may be proud that you figured out how to do the \\\\\"the Matrix effect\\\\\" on a budget, that doesn\\'t necessarily mean you should use it over and over again ad nausea.<br /><br />- Being Ron Howard\\'s brother does not guarantee choice roles.<br /><br />- Whenever a scene doesn\\'t edit together, just use some footage from the video game, no one will notice.<br /><br />- If your cousin\\'s rap-metal band offers to write your movie\\'s theme for free, politely decline.<br /><br />- Zombie movies are not about people killing zombies. They\\'re about zombies killing people, preferably in the most gruesome way possible. That\\'s what makes them SCARY.<br /><br />- White people who can pay $1600 to get to a rave deserve to die.<br /><br />- If you find an old book, it will tell you everything you need to know. Anything else you will figure out on your own two lines after someone asks, \\\\\"What was that?\\\\\" or, \\\\\"Where are we?\\\\\"<br /><br />- Bare breasts are not horror movie panacea.<br /><br />- A helicopter boom shot and a licensing deal with Sega magically transforms your movie from \\\\\"student film\\\\\" to \\\\\"major studio release\\\\\". Try it!<br /><br />- Just because you can name-drop all three \\\\\"Living Dead\\\\\" movies, that does not make you George Romero. Or even Paul W. S. Anderson.<br /><br />I\\'ve seen worse movies, but only because I\\'ve seen \\\\\"Mortal Kombat: Annihilation.\\\\\"\"'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messy = df.loc[ df['id'] == '\"9170_1\"', 'review'].to_string()\n",
    "messy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one looks like a good candidate.  First, let's deal with the HTML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'108    \"The question, when one sees a movie this bad, is not necessarily, \\\\\"How did a movie this bad get made?\\\\\" or even, \\\\\"Why did I see this awful in the first place?\\\\\" but, \\\\\"What have I learned from this experience?\\\\\" Here\\'s what I learned:- Just because the \\\\\"rules\\\\\" of horror movies have been catalogued and satirized countless times in the last ten years doesn\\'t mean someone won\\'t go ahead and make a movie that uses ALL of them, without a shred of humor or irony.- If your movie has to be described as **loosely** based on the video game, you have script problems.- The black character may not always die first, but the Asian character does always know kung-fu.- While you may be proud that you figured out how to do the \\\\\"the Matrix effect\\\\\" on a budget, that doesn\\'t necessarily mean you should use it over and over again ad nausea.- Being Ron Howard\\'s brother does not guarantee choice roles.- Whenever a scene doesn\\'t edit together, just use some footage from the video game, no one will notice.- If your cousin\\'s rap-metal band offers to write your movie\\'s theme for free, politely decline.- Zombie movies are not about people killing zombies. They\\'re about zombies killing people, preferably in the most gruesome way possible. That\\'s what makes them SCARY.- White people who can pay $1600 to get to a rave deserve to die.- If you find an old book, it will tell you everything you need to know. Anything else you will figure out on your own two lines after someone asks, \\\\\"What was that?\\\\\" or, \\\\\"Where are we?\\\\\"- Bare breasts are not horror movie panacea.- A helicopter boom shot and a licensing deal with Sega magically transforms your movie from \\\\\"student film\\\\\" to \\\\\"major studio release\\\\\". Try it!- Just because you can name-drop all three \\\\\"Living Dead\\\\\" movies, that does not make you George Romero. Or even Paul W. S. Anderson.I\\'ve seen worse movies, but only because I\\'ve seen \\\\\"Mortal Kombat: Annihilation.\\\\\"\"'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = BeautifulSoup(messy)\n",
    "clean.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll remove anything that's not a letter.  This is overly simplistic; however, as sometimes punctuation could imply sentiment.  We'll address this in later iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'        The question  when one sees a movie this bad  is not necessarily    How did a movie this bad get made    or even    Why did I see this awful in the first place    but    What have I learned from this experience    Here s what I learned   Just because the   rules   of horror movies have been catalogued and satirized countless times in the last ten years doesn t mean someone won t go ahead and make a movie that uses ALL of them  without a shred of humor or irony   If your movie has to be described as   loosely   based on the video game  you have script problems   The black character may not always die first  but the Asian character does always know kung fu   While you may be proud that you figured out how to do the   the Matrix effect   on a budget  that doesn t necessarily mean you should use it over and over again ad nausea   Being Ron Howard s brother does not guarantee choice roles   Whenever a scene doesn t edit together  just use some footage from the video game  no one will notice   If your cousin s rap metal band offers to write your movie s theme for free  politely decline   Zombie movies are not about people killing zombies  They re about zombies killing people  preferably in the most gruesome way possible  That s what makes them SCARY   White people who can pay       to get to a rave deserve to die   If you find an old book  it will tell you everything you need to know  Anything else you will figure out on your own two lines after someone asks    What was that    or    Where are we     Bare breasts are not horror movie panacea   A helicopter boom shot and a licensing deal with Sega magically transforms your movie from   student film   to   major studio release    Try it   Just because you can name drop all three   Living Dead   movies  that does not make you George Romero  Or even Paul W  S  Anderson I ve seen worse movies  but only because I ve seen   Mortal Kombat  Annihilation    '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = re.sub(\"[^a-zA-Z]\", ' ', clean.get_text())\n",
    "clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is already starting to look much better.  However, we have a number of \"words\" such as 've' and 't' floating around in the next now.  This is from the punctuation in words such as \"I've\" and \"won't\" being removed.  These will be taken care of when we remove the stop words below.\n",
    "\n",
    "Next let's convert everything to lower case and tokenize the the review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'question', 'when', 'one', 'sees', 'a', 'movie', 'this', 'bad', 'is', 'not', 'necessarily', 'how', 'did', 'a', 'movie', 'this', 'bad', 'get', 'made', 'or', 'even', 'why', 'did', 'i', 'see', 'this', 'awful', 'in', 'the', 'first', 'place', 'but', 'what', 'have', 'i', 'learned', 'from', 'this', 'experience', 'here', 's', 'what', 'i', 'learned', 'just', 'because', 'the', 'rules', 'of', 'horror', 'movies', 'have', 'been', 'catalogued', 'and', 'satirized', 'countless', 'times', 'in', 'the', 'last', 'ten', 'years', 'doesn', 't', 'mean', 'someone', 'won', 't', 'go', 'ahead', 'and', 'make', 'a', 'movie', 'that', 'uses', 'all', 'of', 'them', 'without', 'a', 'shred', 'of', 'humor', 'or', 'irony', 'if', 'your', 'movie', 'has', 'to', 'be', 'described', 'as', 'loosely', 'based', 'on', 'the', 'video', 'game', 'you', 'have', 'script', 'problems', 'the', 'black', 'character', 'may', 'not', 'always', 'die', 'first', 'but', 'the', 'asian', 'character', 'does', 'always', 'know', 'kung', 'fu', 'while', 'you', 'may', 'be', 'proud', 'that', 'you', 'figured', 'out', 'how', 'to', 'do', 'the', 'the', 'matrix', 'effect', 'on', 'a', 'budget', 'that', 'doesn', 't', 'necessarily', 'mean', 'you', 'should', 'use', 'it', 'over', 'and', 'over', 'again', 'ad', 'nausea', 'being', 'ron', 'howard', 's', 'brother', 'does', 'not', 'guarantee', 'choice', 'roles', 'whenever', 'a', 'scene', 'doesn', 't', 'edit', 'together', 'just', 'use', 'some', 'footage', 'from', 'the', 'video', 'game', 'no', 'one', 'will', 'notice', 'if', 'your', 'cousin', 's', 'rap', 'metal', 'band', 'offers', 'to', 'write', 'your', 'movie', 's', 'theme', 'for', 'free', 'politely', 'decline', 'zombie', 'movies', 'are', 'not', 'about', 'people', 'killing', 'zombies', 'they', 're', 'about', 'zombies', 'killing', 'people', 'preferably', 'in', 'the', 'most', 'gruesome', 'way', 'possible', 'that', 's', 'what', 'makes', 'them', 'scary', 'white', 'people', 'who', 'can', 'pay', 'to', 'get', 'to', 'a', 'rave', 'deserve', 'to', 'die', 'if', 'you', 'find', 'an', 'old', 'book', 'it', 'will', 'tell', 'you', 'everything', 'you', 'need', 'to', 'know', 'anything', 'else', 'you', 'will', 'figure', 'out', 'on', 'your', 'own', 'two', 'lines', 'after', 'someone', 'asks', 'what', 'was', 'that', 'or', 'where', 'are', 'we', 'bare', 'breasts', 'are', 'not', 'horror', 'movie', 'panacea', 'a', 'helicopter', 'boom', 'shot', 'and', 'a', 'licensing', 'deal', 'with', 'sega', 'magically', 'transforms', 'your', 'movie', 'from', 'student', 'film', 'to', 'major', 'studio', 'release', 'try', 'it', 'just', 'because', 'you', 'can', 'name', 'drop', 'all', 'three', 'living', 'dead', 'movies', 'that', 'does', 'not', 'make', 'you', 'george', 'romero', 'or', 'even', 'paul', 'w', 's', 'anderson', 'i', 've', 'seen', 'worse', 'movies', 'but', 'only', 'because', 'i', 've', 'seen', 'mortal', 'kombat', 'annihilation']\n"
     ]
    }
   ],
   "source": [
    "clean = clean.lower().split()\n",
    "print(list(clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we'll also remove any English stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# Examine the list of English stop words from the NLTK stop word dictionary\n",
    "print(stopwords.words(\"english\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question one sees movie bad necessarily movie bad get made even see awful first place learned experience learned rules horror movies catalogued satirized countless times last ten years mean someone go ahead make movie uses without shred humor irony movie described loosely based video game script problems black character may always die first asian character always know kung fu may proud figured matrix effect budget necessarily mean use ad nausea ron howard brother guarantee choice roles whenever scene edit together use footage video game one notice cousin rap metal band offers write movie theme free politely decline zombie movies people killing zombies zombies killing people preferably gruesome way possible makes scary white people pay get rave deserve die find old book tell everything need know anything else figure two lines someone asks bare breasts horror movie panacea helicopter boom shot licensing deal sega magically transforms movie student film major studio release try name drop three living dead movies make george romero even paul w anderson seen worse movies seen mortal kombat annihilation\n"
     ]
    }
   ],
   "source": [
    "# Use a list comprehension to remove any stop words from the 'clean' review\n",
    "# Convert the stop words to a set object to optimize search speed\n",
    "clean = [x for x in clean if not x in set(stopwords.words(\"english\"))]\n",
    "\n",
    "# Review the final, clean review\n",
    "clean = \" \".join(clean)\n",
    "print(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad!  This is definitely cleaner than what we started with.  Next we'll create a function that combines all the manual steps we performed above, and then feed the entire training set of review through it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the stop words to a set\n",
    "stopWords = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Clean IMDB review text\n",
    "def cleanReview(review, stopWords):\n",
    "    # Remove HTML\n",
    "    clean = BeautifulSoup(review)\n",
    "    \n",
    "    # Remove non-alpha chars\n",
    "    clean = re.sub(\"[^a-zA-Z]\", ' ', clean.get_text())\n",
    "    \n",
    "    # Convert to lower case and \"tokenize\"\n",
    "    clean = clean.lower().split()\n",
    "    \n",
    "    # Remove stop words\n",
    "    clean = [x for x in clean if not x in stopWords]\n",
    "\n",
    "    # Prepare final, cleaned review\n",
    "    clean = \" \".join(clean)\n",
    "    \n",
    "    # Return results\n",
    "    return clean\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and test the function on the \"messy\" review we've been using as our benchmark and ensure it works as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question one sees movie bad necessarily movie bad get made even see awful first place learned experience learned rules horror movies catalogued satirized countless times last ten years mean someone go ahead make movie uses without shred humor irony movie described loosely based video game script problems black character may always die first asian character always know kung fu may proud figured matrix effect budget necessarily mean use ad nausea ron howard brother guarantee choice roles whenever scene edit together use footage video game one notice cousin rap metal band offers write movie theme free politely decline zombie movies people killing zombies zombies killing people preferably gruesome way possible makes scary white people pay get rave deserve die find old book tell everything need know anything else figure two lines someone asks bare breasts horror movie panacea helicopter boom shot licensing deal sega magically transforms movie student film major studio release try name drop three living dead movies make george romero even paul w anderson seen worse movies seen mortal kombat annihilation\n"
     ]
    }
   ],
   "source": [
    "# Feed the \"messy\" review through the cleaning function\n",
    "cleanDef = cleanReview(df.loc[ df['id'] == '\"9170_1\"', 'review'].to_string(), stopWords)\n",
    "\n",
    "# Assert the function ouputs the same results as \"by hand\"\n",
    "assert(cleanDef == clean)\n",
    "\n",
    "# Examine the output\n",
    "print(cleanDef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we'll run the entire set of training reviews through the cleaning function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanReviews = [cleanReview(x, stopWords) for x in df['review']]\n",
    "assert(len(df) == (len(cleanReviews)))\n",
    "assert(clean == cleanReviews[108])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-words feature creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main goals of this write-up is the initial creating of a simple baseline model we can compare further efforts against.  We are going to do this via a [`bag-of-words model`](https://en.wikipedia.org/wiki/Bag-of-words_model) (BOW).\n",
    "\n",
    "In short the BOW doesn't care about grammar or word order.  It does; however, care about how many of each word appear in the target corpus.  \n",
    "\n",
    "> In practice, the Bag-of-words model is mainly used as a tool of feature generation. After transforming the text into a \"bag of words\", we can calculate various measures to characterize the text. The most common type of characteristics, or features calculated from the Bag-of-words model is term frequency, namely, the number of times a term appears in the text. [Source](https://en.wikipedia.org/wiki/Bag-of-words_model)\n",
    "\n",
    "So in the sample review '9170_1' we were examining above we notice that the word 'bad' appears twice, and the words 'worse' and 'awful' appear once.  It is highly likely that other reviews with a negative rating will also contain these words along with others such as 'hate', 'waste', etc.  In these cases the BOW decide that these reviews are similar and place them in the same 'bag' as review '9170_1' (i.e. a negative review classification).\n",
    "\n",
    "The Wikipedia article provides another example:\n",
    ">In Bayesian spam filtering, an e-mail message is modeled as an unordered collection of words selected from one of two probability distributions: one representing spam and one representing legitimate e-mail (\"ham\"). Imagine that there are two literal bags full of words. One bag is filled with words found in spam messages, and the other bag is filled with words found in legitimate e-mail. While any given word is likely to be found somewhere in both bags, the \"spam\" bag will contain spam-related words such as \"stock\", \"Viagra\", and \"buy\" much more frequently, while the \"ham\" bag will contain more words related to the user's friends or workplace.\n",
    "\n",
    ">To classify an e-mail message, the Bayesian spam filter assumes that the message is a pile of words that has been poured out randomly from one of the two bags, and uses Bayesian probability to determine which bag it is more likely to be.\n",
    "\n",
    "\n",
    "Scikit-Learn has a [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) module we can utilize to create the 'bags of words' numeric representation of the reviews suitable for the machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape:  (25000, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Utilize the defaults for the object instantiation other than max_features\n",
    "vec = CountVectorizer(max_features = 5000)\n",
    "\n",
    "# Similar to how almost every other Scikit-Learn objects works we'll call the fit() and transform() methods\n",
    "features = vec.fit_transform(cleanReviews)\n",
    "\n",
    "# And finally we'll convert to a np.array\n",
    "features = features.toarray()\n",
    "\n",
    "print(\"Features shape: \", features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the first 30 feature entries for review '9170_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(features[108,0:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed above that the word 'bad' appeared twice in the review.  Let's confirm the sparse feature matrix (i.e. bag of words) captured this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abandoned', 'abc', 'abilities', 'ability', 'able', 'abraham', 'absence', 'absent', 'absolute', 'absolutely']\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 10 words in the vocabulary\n",
    "vocab = vec.get_feature_names()\n",
    "print(vocab[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which index position is 'bad' in?\n",
    "vocab.index('bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many times did bad appear in review '9170_1'?\n",
    "features[108,323]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So everything appears to check out correctly.  Let's review the most and least occurring words in the 'bag', and then we'll move on to model implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = pd.DataFrame(data = features, columns = vocab).sum()\n",
    "_df.sort_values(ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10:\n",
      "\n",
      "movie     44031\n",
      "film      40147\n",
      "one       26788\n",
      "like      20274\n",
      "good      15140\n",
      "time      12724\n",
      "even      12646\n",
      "would     12436\n",
      "story     11983\n",
      "really    11736\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 10:\\n\")\n",
    "print(_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom 10:\n",
      "\n",
      "skull       78\n",
      "sopranos    78\n",
      "premiere    78\n",
      "bunny       78\n",
      "flair       78\n",
      "fishing     78\n",
      "awhile      78\n",
      "stumbled    78\n",
      "amused      78\n",
      "cream       78\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Bottom 10:\\n\")\n",
    "print(_df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, apparently the word 'cream' was used 78 times in the review corpus..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are finally ready to develop the baseline model on the data we've explored, cleaned, and processed.  Because the IMDB data set doesn't include a validation set we'll create one from a portion of the training data.  The processes is similar to our work in previous write-ups such as the [Iris classifier](.//Model-01.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape =  (25000, 5000)\n",
      "y.shape =  (25000,)\n",
      "--------\n",
      "xTrain.shape =  (20000, 5000)\n",
      "yTrain.shape =  (20000,)\n",
      "xVal.shape =  (5000, 5000)\n",
      "yVal.shape =  (5000,)\n"
     ]
    }
   ],
   "source": [
    "# Seperate X and Y values\n",
    "x = features\n",
    "y = df[\"sentiment\"]\n",
    "\n",
    "print(\"x.shape = \", x.shape)\n",
    "print(\"y.shape = \", y.shape)\n",
    "\n",
    "# Split out validation set -- 80/20 split\n",
    "valSize = 0.2\n",
    "\n",
    "xTrain, xVal, yTrain, yVal = train_test_split(x, y, test_size = valSize, random_state = seed)\n",
    "\n",
    "print(\"--------\")\n",
    "print(\"xTrain.shape = \", xTrain.shape)\n",
    "print(\"yTrain.shape = \", yTrain.shape)\n",
    "print(\"xVal.shape = \", xVal.shape)\n",
    "print(\"yVal.shape = \", yVal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial pass\n",
    "\n",
    "We'll apply a number of non-ensemble algorithms to the data set to start with.  Scikit-learn makes this very easy to do along with the fact that the data set isn't overly large, and we've already done similar work in previous write-ups we can 'borrow.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LR ....\n",
      "\n",
      "Training LDA ....\n",
      "\n",
      "Training KNN ....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Init vars\n",
    "folds = 10\n",
    "seed = 10\n",
    "models = []\n",
    "results = {}\n",
    "\n",
    "# Use accuracy since this is a classification\n",
    "score = 'accuracy'\n",
    "\n",
    "# Instantiate model objects\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "# Create a Pandas DF to hold all our spiffy results\n",
    "_df = pd.DataFrame(columns = ['Model', 'Accuracy', 'StdDev'])\n",
    "\n",
    "# Run the models\n",
    "for modelName, model in models:\n",
    "    print(\"Training\", modelName, \"....\")\n",
    "    # Implement K-fold cross validation where K = 10\n",
    "    kFold = KFold(n_splits = folds, random_state = seed)\n",
    "    results[modelName] = cross_val_score(model, xTrain, yTrain, cv = kFold, scoring = score)\n",
    "    _df.loc[len(_df)] = list([modelName, results[modelName].mean(), results[modelName].std()])\n",
    "\n",
    "# Print results sorted by Mean desc, StdDev asc, Model asc\n",
    "_df.sort_values(by = ['Accuracy', 'StdDev', 'Model'], ascending = [False, True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest = forest.fit( features, df[\"sentiment\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = forest.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score =  1.0 \n",
      "\n",
      "confusion_matrix\n",
      " [[12500     0]\n",
      " [    0 12500]] \n",
      "\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     12500\n",
      "          1       1.00      1.00      1.00     12500\n",
      "\n",
      "avg / total       1.00      1.00      1.00     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy_score = \", accuracy_score(df[\"sentiment\"], preds), \"\\n\")\n",
    "print(\"confusion_matrix\\n\", confusion_matrix(df[\"sentiment\"], preds), \"\\n\")\n",
    "print(\"classification_report\\n\", classification_report(df[\"sentiment\"], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
