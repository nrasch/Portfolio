{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#IMDB-Movie-Review-Sentiment-Classification\" data-toc-modified-id=\"IMDB-Movie-Review-Sentiment-Classification-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>IMDB Movie Review Sentiment Classification</a></span></li><li><span><a href=\"#Purpose\" data-toc-modified-id=\"Purpose-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Purpose</a></span></li><li><span><a href=\"#Methodology\" data-toc-modified-id=\"Methodology-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Methodology</a></span></li><li><span><a href=\"#Configure-notebook,-import-libraries,-and-import-dataset\" data-toc-modified-id=\"Configure-notebook,-import-libraries,-and-import-dataset-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Configure notebook, import libraries, and import dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-libraries\" data-toc-modified-id=\"Import-libraries-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Import libraries</a></span></li><li><span><a href=\"#Define-global-variables\" data-toc-modified-id=\"Define-global-variables-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Define global variables</a></span></li><li><span><a href=\"#Load-in-data-sets\" data-toc-modified-id=\"Load-in-data-sets-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Load in data sets</a></span></li></ul></li><li><span><a href=\"#Helper-Functions\" data-toc-modified-id=\"Helper-Functions-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Helper Functions</a></span></li><li><span><a href=\"#Examine-the-data\" data-toc-modified-id=\"Examine-the-data-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Examine the data</a></span></li><li><span><a href=\"#Cleaning-and-preprocessing\" data-toc-modified-id=\"Cleaning-and-preprocessing-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Cleaning and preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Write-helper-functions\" data-toc-modified-id=\"Write-helper-functions-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Write helper functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sentence-cleaner\" data-toc-modified-id=\"Sentence-cleaner-7.1.1\"><span class=\"toc-item-num\">7.1.1&nbsp;&nbsp;</span>Sentence cleaner</a></span></li></ul></li><li><span><a href=\"#Create-list-of-cleaned-and-processed-Doc2Vec-TaggedDocument-objects\" data-toc-modified-id=\"Create-list-of-cleaned-and-processed-Doc2Vec-TaggedDocument-objects-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Create list of cleaned and processed Doc2Vec TaggedDocument objects</a></span></li></ul></li><li><span><a href=\"#Doc2Vec-model-tuning\" data-toc-modified-id=\"Doc2Vec-model-tuning-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Doc2Vec model tuning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ensemble-process-sanity-check\" data-toc-modified-id=\"Ensemble-process-sanity-check-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Ensemble process sanity check</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sanity-check---Create-Doc2Vec-model,-build-vocab,-and-train\" data-toc-modified-id=\"Sanity-check---Create-Doc2Vec-model,-build-vocab,-and-train-8.1.1\"><span class=\"toc-item-num\">8.1.1&nbsp;&nbsp;</span>Sanity check - Create Doc2Vec model, build vocab, and train</a></span></li><li><span><a href=\"#Sanity-check---Split-Doc2Vec-vectors-into-train,-validation,-and-test-sets\" data-toc-modified-id=\"Sanity-check---Split-Doc2Vec-vectors-into-train,-validation,-and-test-sets-8.1.2\"><span class=\"toc-item-num\">8.1.2&nbsp;&nbsp;</span>Sanity check - Split Doc2Vec vectors into train, validation, and test sets</a></span></li><li><span><a href=\"#Sanity-check---Train-and-assess-classifier\" data-toc-modified-id=\"Sanity-check---Train-and-assess-classifier-8.1.3\"><span class=\"toc-item-num\">8.1.3&nbsp;&nbsp;</span>Sanity check - Train and assess classifier</a></span></li><li><span><a href=\"#Sanity-check---Comments\" data-toc-modified-id=\"Sanity-check---Comments-8.1.4\"><span class=\"toc-item-num\">8.1.4&nbsp;&nbsp;</span>Sanity check - Comments</a></span></li></ul></li></ul></li><li><span><a href=\"#Combining-Doc2Vec-models\" data-toc-modified-id=\"Combining-Doc2Vec-models-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Combining Doc2Vec models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-baseline-Doc2Vec-models,-train,-and-evaluate\" data-toc-modified-id=\"Create-baseline-Doc2Vec-models,-train,-and-evaluate-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>Create baseline Doc2Vec models, train, and evaluate</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-Doc2Vec-models\" data-toc-modified-id=\"Create-Doc2Vec-models-9.1.1\"><span class=\"toc-item-num\">9.1.1&nbsp;&nbsp;</span>Create Doc2Vec models</a></span></li><li><span><a href=\"#Assess-combined-model-outputs-on-XGBoost-classifier\" data-toc-modified-id=\"Assess-combined-model-outputs-on-XGBoost-classifier-9.1.2\"><span class=\"toc-item-num\">9.1.2&nbsp;&nbsp;</span>Assess combined model outputs on XGBoost classifier</a></span></li><li><span><a href=\"#Comments\" data-toc-modified-id=\"Comments-9.1.3\"><span class=\"toc-item-num\">9.1.3&nbsp;&nbsp;</span>Comments</a></span></li></ul></li><li><span><a href=\"#Doc2Vec-tuning\" data-toc-modified-id=\"Doc2Vec-tuning-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>Doc2Vec tuning</a></span></li><li><span><a href=\"#DM0-training\" data-toc-modified-id=\"DM0-training-9.3\"><span class=\"toc-item-num\">9.3&nbsp;&nbsp;</span>DM0 training</a></span></li><li><span><a href=\"#Train-best-Doc2Vec-models\" data-toc-modified-id=\"Train-best-Doc2Vec-models-9.4\"><span class=\"toc-item-num\">9.4&nbsp;&nbsp;</span>Train best Doc2Vec models</a></span></li><li><span><a href=\"#Tune-XGBoost-using-best-Doc2Vec-models\" data-toc-modified-id=\"Tune-XGBoost-using-best-Doc2Vec-models-9.5\"><span class=\"toc-item-num\">9.5&nbsp;&nbsp;</span>Tune XGBoost using best Doc2Vec models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pick-sane-model-param-defaults\" data-toc-modified-id=\"Pick-sane-model-param-defaults-9.5.1\"><span class=\"toc-item-num\">9.5.1&nbsp;&nbsp;</span>Pick sane model param defaults</a></span></li><li><span><a href=\"#Calculate-best-initial-n_estimators-value-(i.e.-number-of-trees)\" data-toc-modified-id=\"Calculate-best-initial-n_estimators-value-(i.e.-number-of-trees)-9.5.2\"><span class=\"toc-item-num\">9.5.2&nbsp;&nbsp;</span>Calculate best initial n_estimators value (i.e. number of trees)</a></span></li><li><span><a href=\"#Tune-max_depth-and-min_child_weight\" data-toc-modified-id=\"Tune-max_depth-and-min_child_weight-9.5.3\"><span class=\"toc-item-num\">9.5.3&nbsp;&nbsp;</span>Tune max_depth and min_child_weight</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fine-tune\" data-toc-modified-id=\"Fine-tune-9.5.3.1\"><span class=\"toc-item-num\">9.5.3.1&nbsp;&nbsp;</span>Fine tune</a></span></li></ul></li></ul></li><li><span><a href=\"#Tune-gamma,-subsample-and-colsample_bytree\" data-toc-modified-id=\"Tune-gamma,-subsample-and-colsample_bytree-9.6\"><span class=\"toc-item-num\">9.6&nbsp;&nbsp;</span>Tune gamma, subsample and colsample_bytree</a></span><ul class=\"toc-item\"><li><span><a href=\"#Gamma-tuning\" data-toc-modified-id=\"Gamma-tuning-9.6.1\"><span class=\"toc-item-num\">9.6.1&nbsp;&nbsp;</span>Gamma tuning</a></span></li><li><span><a href=\"#Calculate-optimal-n_estimators-value\" data-toc-modified-id=\"Calculate-optimal-n_estimators-value-9.6.2\"><span class=\"toc-item-num\">9.6.2&nbsp;&nbsp;</span>Calculate optimal n_estimators value</a></span></li><li><span><a href=\"#subsample-and-colsample_bytree-tuning\" data-toc-modified-id=\"subsample-and-colsample_bytree-tuning-9.6.3\"><span class=\"toc-item-num\">9.6.3&nbsp;&nbsp;</span>subsample and colsample_bytree tuning</a></span></li></ul></li><li><span><a href=\"#Tune-regularization-params,-reg_alpha-and-reg_lambda\" data-toc-modified-id=\"Tune-regularization-params,-reg_alpha-and-reg_lambda-9.7\"><span class=\"toc-item-num\">9.7&nbsp;&nbsp;</span>Tune regularization params, reg_alpha and reg_lambda</a></span></li><li><span><a href=\"#Obtain-new-n_estimators-value\" data-toc-modified-id=\"Obtain-new-n_estimators-value-9.8\"><span class=\"toc-item-num\">9.8&nbsp;&nbsp;</span>Obtain new n_estimators value</a></span></li><li><span><a href=\"#Tune-the-learning-rate-and-re-eval-n_estimators\" data-toc-modified-id=\"Tune-the-learning-rate-and-re-eval-n_estimators-9.9\"><span class=\"toc-item-num\">9.9&nbsp;&nbsp;</span>Tune the learning rate and re-eval n_estimators</a></span></li><li><span><a href=\"#Training-and-validation-on-the-entire-dataset\" data-toc-modified-id=\"Training-and-validation-on-the-entire-dataset-9.10\"><span class=\"toc-item-num\">9.10&nbsp;&nbsp;</span>Training and validation on the entire dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-best-Doc2Vec-models\" data-toc-modified-id=\"Train-best-Doc2Vec-models-9.10.1\"><span class=\"toc-item-num\">9.10.1&nbsp;&nbsp;</span>Train best Doc2Vec models</a></span></li><li><span><a href=\"#Train-best-XGBoost-model\" data-toc-modified-id=\"Train-best-XGBoost-model-9.10.2\"><span class=\"toc-item-num\">9.10.2&nbsp;&nbsp;</span>Train best XGBoost model</a></span></li><li><span><a href=\"#Examine-predictions\" data-toc-modified-id=\"Examine-predictions-9.10.3\"><span class=\"toc-item-num\">9.10.3&nbsp;&nbsp;</span>Examine predictions</a></span></li></ul></li><li><span><a href=\"#Training-and-validation-on-the-entire-dataset-with-stemming-and-contractions\" data-toc-modified-id=\"Training-and-validation-on-the-entire-dataset-with-stemming-and-contractions-9.11\"><span class=\"toc-item-num\">9.11&nbsp;&nbsp;</span>Training and validation on the entire dataset with stemming and contractions</a></span></li></ul></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Summary</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>IMDB Movie Review Sentiment Classification</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left; margin-right: 15px; width: 30%; height: 30%;\" src=\"images/imdb.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "The purpose of this write-up is to:\n",
    "\n",
    "1. Clean and process the IMDb source data\n",
    "1. Develop an ensemble:\n",
    "   1. Create and optimize two Doc2Vec models: Distributed bag of words (PV-DBOW) and Distributed memory (PV-DM)\n",
    "   1. Combine the outputs of these two models\n",
    "   1. Feed the combined output to a XGBoost classification model\n",
    "   1. Perform tuning on the XGBoost classification model\n",
    "1. Examine accuracy scores against the evaluation data set\n",
    "1. Submit results to Kaggle if improvements occur against our current best score of 0.88840 achieved via a CNN\n",
    "\n",
    "References:\n",
    "* [Gensim Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html)\n",
    "* [Original paper](https://arxiv.org/abs/1405.4053) by Mikilov and Le\n",
    "* [XGBoost API](https://xgboost.readthedocs.io/en/latest/python/python_api.html)\n",
    "\n",
    "Dataset source:  [IMDB Movie Reviews](https://www.kaggle.com/c/word2vec-nlp-tutorial/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "\n",
    "First, I normally develop the code and go through the process before finishing the narrative.  As such we'll cut some portions of the process out for brevity's sake where appropriate.  I will make note when this occurs.\n",
    "\n",
    "Next, progress and model performance was assessed against 1st) evaluation data set accuracy (which so far has shown positive correlation to Kaggle score), and then 2nd) Kaggle submission score.  \n",
    "\n",
    "(So far the best Kaggle score we've achieved is 0.88840 utilizing a CNN in (this write-up)[].)\n",
    "\n",
    "I also read in papers--and experienced personally via hands-on testing--that hyperparameter tuning only provided small, incremental improvements.  The largest improvements in classification accuracy came from preparation of the source data.  As such I added steps for resolving contractions, added a NLTK Lemmatizer, etc. to the data cleaning/processing steps.\n",
    "\n",
    "And finally the Doc2Vec and XGBoost models were first created and baselined with 'sane' defaults which I aggregated from research and reading followed by rounds of tuning to (hopefully) optimize performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure notebook, import libraries, and import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T15:16:22.416553Z",
     "start_time": "2018-10-16T15:16:22.413553Z"
    }
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T21:39:29.297291Z",
     "start_time": "2018-12-05T21:39:28.573708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "import os, re\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "from random import shuffle\n",
    "import copy\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import set_option\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import xgboost as xg\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# http://www.nltk.org/index.html\n",
    "# pip install nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# Creating function implementing punkt tokenizer for sentence splitting\n",
    "import nltk.data\n",
    "\n",
    "# Only need this the first time...\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# Opens a GUI that allows us to download the NLTK data\n",
    "# nltk.download()\n",
    "\n",
    "#from nltk.stem import WordNetLemmatizer as lemm\n",
    "\n",
    "\n",
    "# conda install -c conda-forge spacy\n",
    "# -OR-\n",
    "# pip install spacy\n",
    "# -then-\n",
    "# python -m spacy download en\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "\n",
    "# https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "# pip install BeautifulSoup4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# https://pypi.org/project/gensim/\n",
    "# pip install gensim\n",
    "import gensim.models.doc2vec\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "assert(gensim.models.doc2vec.FAST_VERSION > -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T17:38:26.172891Z",
     "start_time": "2018-12-05T17:38:23.139805Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the seeds\n",
    "seedVal = 10\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(seedVal)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(seedVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T17:38:26.494750Z",
     "start_time": "2018-12-05T17:38:26.175899Z"
    }
   },
   "outputs": [],
   "source": [
    "contractions = { \n",
    "\"ain't\": \"am not / are not / is not / has not / have not\",\n",
    "\"aren't\": \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had / he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall / he will\",\n",
    "\"he'll've\": \"he shall have / he will have\",\n",
    "\"he's\": \"he has / he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has / how is / how does\",\n",
    "\"I'd\": \"I had / I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I shall / I will\",\n",
    "\"I'll've\": \"I shall have / I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had / it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it shall / it will\",\n",
    "\"it'll've\": \"it shall have / it will have\",\n",
    "\"it's\": \"it has / it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had / she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she shall / she will\",\n",
    "\"she'll've\": \"she shall have / she will have\",\n",
    "\"she's\": \"she has / she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as / so is\",\n",
    "\"that'd\": \"that would / that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that has / that is\",\n",
    "\"there'd\": \"there had / there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there has / there is\",\n",
    "\"they'd\": \"they had / they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they shall / they will\",\n",
    "\"they'll've\": \"they shall have / they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had / we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what shall / what will\",\n",
    "\"what'll've\": \"what shall have / what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what has / what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when has / when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where has / where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who shall / who will\",\n",
    "\"who'll've\": \"who shall have / who will have\",\n",
    "\"who's\": \"who has / who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why has / why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had / you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you shall / you will\",\n",
    "\"you'll've\": \"you shall have / you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "contractionsObj = re.compile('(%s)' % '|'.join(contractions.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T17:38:28.419882Z",
     "start_time": "2018-12-05T17:38:26.496756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labDat.shape : (25000, 3)\n",
      "unlabDat.shape : (50000, 2)\n",
      "testDat.shape : (25000, 2)\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      "id           25000 non-null object\n",
      "sentiment    25000 non-null int64\n",
      "review       25000 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 586.0+ KB\n",
      "labDat.info() : None\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 3 columns):\n",
      "id           50000 non-null object\n",
      "review       50000 non-null object\n",
      "sentiment    0 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.1+ MB\n",
      "unlabDat.info() : None\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      "id           25000 non-null object\n",
      "review       25000 non-null object\n",
      "sentiment    0 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 586.0+ KB\n",
      "testDat.info() : None\n"
     ]
    }
   ],
   "source": [
    "dataPath = os.path.join('.', 'datasets', 'imdb_movie_reviews')\n",
    "labeledTrainData = os.path.join(dataPath, 'labeledTrainData.tsv')\n",
    "unlabeledTrainData = os.path.join(dataPath, 'unlabeledTrainData.tsv')\n",
    "testData = os.path.join(dataPath, 'testData.tsv')\n",
    "\n",
    "\n",
    "labDat = pd.read_csv(labeledTrainData, sep = '\\t', header = 0, quoting = 3)\n",
    "unlabDat = pd.read_csv(unlabeledTrainData, sep = '\\t', header = 0, quoting = 3)\n",
    "testDat = pd.read_csv(testData, sep = '\\t', header = 0, quoting = 3)\n",
    "\n",
    "\n",
    "# Sanity check\n",
    "print('labDat.shape :', labDat.shape)\n",
    "print('unlabDat.shape :', unlabDat.shape)\n",
    "print('testDat.shape :', testDat.shape)\n",
    "\n",
    "unlabDat['sentiment'] = None\n",
    "testDat['sentiment'] = None\n",
    "\n",
    "print(\"\\n\")\n",
    "print('labDat.info() :', labDat.info())\n",
    "print(\"\\n\")\n",
    "print('unlabDat.info() :', unlabDat.info())\n",
    "print(\"\\n\")\n",
    "print('testDat.info() :', testDat.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T17:38:28.793876Z",
     "start_time": "2018-12-05T17:38:28.420885Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 3)\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 3 columns):\n",
      "id           100000 non-null object\n",
      "review       100000 non-null object\n",
      "sentiment    25000 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "combinedDat = pd.concat(objs=[labDat, unlabDat, testDat], axis=0).reset_index(drop=True)\n",
    "print(combinedDat.shape)\n",
    "print(\"\\n\")\n",
    "print(combinedDat.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T17:38:29.123756Z",
     "start_time": "2018-12-05T17:38:28.794879Z"
    }
   },
   "outputs": [],
   "source": [
    "def expandContractions(txt, contractions = contractions):\n",
    "    def replace(match):\n",
    "        return contractions[match.group(0)]\n",
    "    return contractionsObj.sub(replace, txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the data\n",
    "\n",
    "Previously covered [here](./Model-06.ipynb#Examine-the-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write helper functions\n",
    "\n",
    "Doc2Vec expects a list of `TaggedDocument` objects.  The first argument of the `TaggedDocument` constructor is a contiguous list of words (which we'll clean as usual), and the second argument is a unique tag.  For example, here is what a sample `TaggedDocument` object looks like:\n",
    "\n",
    "```\n",
    "TaggedDocument(words=['with', 'all', 'this', 'stuff', 'going', 'down', 'at', 'the', 'moment', 'with', 'mj', 'i', 've', 'started', 'listening', 'to', 'his', ...... <SNIP>], tags=[0])\n",
    "```\n",
    "\n",
    "In order to facilitate this we'll first write the \"cleaner\" function to process the review text:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence cleaner\n",
    "\n",
    "Take a given sentence and process/clean it (i.e. remove HTML and other cruft, lower case the text, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T17:51:30.802800Z",
     "start_time": "2018-12-05T17:51:30.430807Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clean IMDB review text\n",
    "def cleanReview(review, removeStopWords = False, applyLemmatizing = False):\n",
    "    # Convert the stop words to a set\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    # Remove HTML\n",
    "    clean = BeautifulSoup(review).get_text()\n",
    "    \n",
    "    # Expand contractions (i.e. wasn't => was not)\n",
    "    clean = expandContractions(clean)\n",
    "    \n",
    "    # Remove non-alpha chars\n",
    "    clean = re.sub(\"[^a-zA-Z]\", ' ', clean)\n",
    "    \n",
    "    # Lemmatizer\n",
    "    if applyLemmatizing:\n",
    "        # This also results in the words being lower cased and tokenized\n",
    "        clean = nlp(clean)\n",
    "        clean = [token.lemma_ for token in clean]\n",
    "        # Remove any strings containing only spaces\n",
    "        clean = [x for x in clean if x.strip()]\n",
    "    else:\n",
    "        # Convert to lower case and \"tokenize\"\n",
    "        clean = clean.lower().split()\n",
    "    \n",
    "    # Remove stop words\n",
    "    if removeStopWords:\n",
    "        clean = [x for x in clean if not x in stopWords]\n",
    "    \n",
    "    # Return results\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick examination of the raw text and then the processed output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T17:51:31.199816Z",
     "start_time": "2018-12-05T17:51:30.871940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Looking for Quo Vadis at my local video store, I found this 1985 version that looked interesting. Wow! It was amazing! Very much a Ken Russell kind of film -quirky, stylized, very artistic, and of course \\\\\"different.\\\\\" Nero was presented not so much as evil incarnate, but as a wacky, unfulfilled emperor who would rather have had a circus career. He probably wondered why on earth he was put in the position of \\\\\"leading\\\\\" an empire -it wasn\\'t much fun, and fun is what he longed for. Klause Maria Bandaur had a tremendous time with this role and played it for all it was worth. Yes, Nero persecuted the Christians with a vengeance; one of many who did so. At one point one of his henchmen murmurs: \\\\\"No one will ever understand we were simply protecting ourselves.\\\\\" He got that right.\"'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine raw\n",
    "combinedDat.iloc[25,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T17:51:31.663054Z",
     "start_time": "2018-12-05T17:51:31.202824Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['look',\n",
       " 'quo',\n",
       " 'vadis',\n",
       " '-PRON-',\n",
       " 'local',\n",
       " 'video',\n",
       " 'store',\n",
       " '-PRON-',\n",
       " 'find',\n",
       " 'version',\n",
       " 'look',\n",
       " 'interesting']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine processed\n",
    "cleanReview(combinedDat.iloc[25,1], True, True)[:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create list of cleaned and processed Doc2Vec TaggedDocument objects\n",
    "\n",
    "Next we need to create a collection of cleaned and processed `TaggedDocument` objects using the helper functions we just wrote.  We'll want one TaggedDocument object for each review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T22:44:09.776000Z",
     "start_time": "2018-12-05T22:44:09.437096Z"
    }
   },
   "outputs": [],
   "source": [
    "# Allows us to write various cleaning/processing methods to different files if required\n",
    "#docsFileName = \"taggedDocs.p\"\n",
    "docsFileName = \"taggedDocsTrainOnly.p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T22:44:11.735726Z",
     "start_time": "2018-12-05T22:44:10.510459Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell if you've already cleaned and proccessed the reviews and want to load the previous results\n",
    "taggedDocs = pickle.load( open(docsFileName, \"rb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T20:31:03.714427Z",
     "start_time": "2018-12-05T20:25:58.000337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5e8fbd5dcf4108a0bf7198b15465fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell if you need to clean and proccesse the reviews\n",
    "writeToDisk = True\n",
    "trainOnly = True\n",
    "taggedDocs = []\n",
    "\n",
    "# Cleaning and processing params - Alter these to configure the cleaning/processing of the review text\n",
    "removeStopWords = True\n",
    "applyLemmatizing = True\n",
    "\n",
    "for i, s in tqdm(enumerate(combinedDat.iloc[:,1])):\n",
    "    # Allows us to only process the training data... useful if we want to explore the\n",
    "    # impact of different cleaning pipelines later on w/ various models\n",
    "    if (trainOnly) and (i == 25000):\n",
    "        break\n",
    "    # Remove stop words and apply Lemmatizing\n",
    "    clean = cleanReview(s, removeStopWords, applyLemmatizing)\n",
    "    taggedDocs.append(TaggedDocument(clean, [i]))\n",
    "    \n",
    "if writeToDisk:\n",
    "    # Write to disk, so we can load if/when we run the notebook again\n",
    "    pickle.dump( taggedDocs, open(docsFileName, \"wb\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T22:44:15.267029Z",
     "start_time": "2018-12-05T22:44:14.941161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check we have the same number of objects as reviews\n",
    "len(taggedDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T22:44:15.803811Z",
     "start_time": "2018-12-05T22:44:15.485960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['look', 'quo', 'vadis', '-PRON-', 'local', 'video', 'store', '-PRON-', 'find', 'version', 'look', 'interesting', 'wow', '-PRON-', 'amazing', 'much', 'ken', 'russell', 'kind', 'film', 'quirky', 'stylize', 'artistic', 'course', 'different', 'nero', 'present', 'much', 'evil', 'incarnate', 'wacky', 'unfulfilled', 'emperor', 'would', 'rather', 'circus', 'career', '-PRON-', 'probably', 'wonder', 'earth', '-PRON-', 'put', 'position', 'lead', 'empire', '-PRON-', 'much', 'fun', 'fun', '-PRON-', 'long', 'klause', 'maria', 'bandaur', 'tremendous', 'time', 'role', 'play', '-PRON-', '-PRON-', 'worth', 'yes', 'nero', 'persecute', 'christians', 'vengeance', 'one', 'many', 'one', 'point', 'one', '-PRON-', 'henchman', 'murmur', 'one', 'ever', 'understand', '-PRON-', 'simply', 'protect', '-PRON-', '-PRON-', 'get', 'right'], tags=[25])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine an example:\n",
    "taggedDocs[25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec model tuning \n",
    "\n",
    "We are now ready to train the Doc2Vec models.  The process will go something like this:\n",
    "1. Define two Doc2Vec model objects:  PV-DBOW and PV-DM\n",
    "2. Build vocabulary from a sequence of sentences (i.e. our cleaned and processed reviews)\n",
    "3. Train the Doc2Vec models (Doc2Vec uses a inner shallow neural network to create the embeddings)\n",
    "4. Create a combined feature set utilizing the trained Doc2Vec models\n",
    "5. Pass the combined feature set to the XGBoost model for evaluation\n",
    "\n",
    "Two very helpful resources for tuning:\n",
    "\n",
    "1. [The original paper itself](https://arxiv.org/abs/1405.4053) by Mikilov and Le\n",
    "2. [Gensim's Doc2Vec Tutorial](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-IMDB.ipynb)\n",
    "\n",
    "One note however:  During my research I came across some discussion/controversy about the validity of the final accuracy score in the original paper.  This also included skepticism voiced by one of the paper's authors, Mikilov.  As such we won't try to replicate the paper's accuracy metrics exactly, as there is some question as to whether that is possible or not on this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble process sanity check\n",
    "\n",
    "Let's begin by ensuring the process we outlined above works.  First we'll create a single Doc2Vec model instance, run the collection of tagged documents through it, and then feed the results to a XGBoost model.  We'll examine the accuracy and confirm the ensemble pipeline we wish to utilize outputs sane results.\n",
    "\n",
    "### Sanity check - Create Doc2Vec model, build vocab, and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T21:20:55.186264Z",
     "start_time": "2018-12-05T21:20:21.959552Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc2vecModel = Doc2Vec(dm = 0, vector_size = 100, negative = 5, hs = 0, min_count = 2, sample = 0, epochs = 20, workers = cores)\n",
    "doc2vecModel.build_vocab(taggedDocs)\n",
    "doc2vecModel.train(taggedDocs, total_examples = doc2vecModel.corpus_count, epochs = doc2vecModel.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T21:20:55.540198Z",
     "start_time": "2018-12-05T21:20:55.187266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(len(doc2vecModel.docvecs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check - Split Doc2Vec vectors into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T21:20:55.872077Z",
     "start_time": "2018-12-05T21:20:55.541203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "trainVecs = doc2vecModel.docvecs.doctag_syn0[:25000]\n",
    "\n",
    "if not trainOnly:\n",
    "    valVecs = doc2vecModel.docvecs.doctag_syn0[25000:75000]\n",
    "    testVecs = doc2vecModel.docvecs.doctag_syn0[75000:]\n",
    "\n",
    "trainLabels = list(combinedDat['sentiment'][:25000])\n",
    "\n",
    "print(len(trainVecs))\n",
    "print(len(trainLabels))\n",
    "\n",
    "if not trainOnly:\n",
    "    print(len(valVecs))\n",
    "    print(len(testVecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T21:20:56.226010Z",
     "start_time": "2018-12-05T21:20:55.876088Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_eval, y_train, y_eval = train_test_split(\n",
    "    trainVecs, \n",
    "    trainLabels, \n",
    "    test_size = 0.1, \n",
    "    shuffle = True, \n",
    "    random_state = seedVal, \n",
    "    stratify = trainLabels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check - Train and assess classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T21:20:56.591977Z",
     "start_time": "2018-12-05T21:20:56.227013Z"
    }
   },
   "outputs": [],
   "source": [
    "def plotHistory(history):\n",
    "    fig, (ax1) = plt.subplots(nrows = 1, ncols = 1, figsize = (8, 4))\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    ax1.plot(history['validation_0']['auc'])\n",
    "    ax1.plot(history['validation_1']['auc'])\n",
    "    ax1.set_title('Model AUC')\n",
    "    ax1.set_ylabel('AUC')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend(['Train', 'Val'], loc='upper left')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T21:21:21.564900Z",
     "start_time": "2018-12-05T21:20:56.592980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.768587\tvalidation_1-auc:0.757861\n",
      "[50]\tvalidation_0-auc:0.921614\tvalidation_1-auc:0.899597\n",
      "[99]\tvalidation_0-auc:0.946207\tvalidation_1-auc:0.922702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "       random_state=10, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xg.XGBClassifier(\n",
    "    objective = \"binary:logistic\",\n",
    "    random_state = seedVal\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    eval_set = [(X_train, y_train), (X_eval, y_eval)],\n",
    "    eval_metric = \"auc\",\n",
    "    verbose = False,\n",
    "    early_stopping_rounds = 5,\n",
    "    callbacks=[\n",
    "        xg.callback.print_evaluation(period = 50, show_stdv = True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T21:21:21.921844Z",
     "start_time": "2018-12-05T21:21:21.566904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1052  198]\n",
      " [ 182 1068]]\n",
      "0.848\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_eval)\n",
    "print(confusion_matrix(y_eval, preds))\n",
    "print(accuracy_score(y_eval, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T21:21:22.440210Z",
     "start_time": "2018-12-05T21:21:21.922847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotHistory(model.evals_result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check - Comments\n",
    "\n",
    "The ensemble process seems to be working well.  We achieved an eval data set accuracy rating of 0.848 right out of the gate which isn't too far off from what we achieved utilizing the best model to date (a CNN model written in a [previous write-up]().\n",
    "\n",
    "We can now continue with tuning the Doc2Vec and XGBoost models in the hopes of increasing performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Doc2Vec models\n",
    "\n",
    "Next we'll move on to combining the outputs of two Doc2Vec models into a single output and then evaluating performance.  We'll first explore two models with \"sane\" hyperparameter settings, record the results as a baseline, and then advance into tuning.\n",
    "\n",
    "One model will be a PV-DBOW and the other a PV-DM.\n",
    "\n",
    "(Note that I experimented with a few combinations of model parameters before I came up with good baselines, but I'll omit that testing and utilize only the two best baseline Doc2Vec models below.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create baseline Doc2Vec models, train, and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Doc2Vec models\n",
    "First, create and train the Doc2Vec models.  We'll also include a mechanism to shuffle the tagged documents each epoch, which the literature reports improves performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:08:20.684824Z",
     "start_time": "2018-12-05T23:06:50.051995Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "# Instantiate each model\n",
    "m2 = Doc2Vec(dm=0, vector_size=100, negative=5, hs=0, min_count=2, sample=0, workers=cores)\n",
    "m3 = Doc2Vec(dm=1, dm_mean=1, size=100, window=10, negative=5, hs=0, min_count=2, workers=cores)\n",
    "\n",
    "# Build vocab with first model\n",
    "m2.build_vocab(taggedDocs)\n",
    "\n",
    "# Share first model's vocab scan w/ the other model(s)\n",
    "m3.reset_from(m2)\n",
    "\n",
    "# Model training params\n",
    "alpha, min_alpha, passes = (0.025, 0.001, 20)\n",
    "alpha_delta = (alpha - min_alpha) / passes\n",
    "\n",
    "# We don't want to shuffle taggedDocs in place later on, so make a copy\n",
    "mixedUp = taggedDocs.copy()\n",
    "\n",
    "# Train the models.  We need to manually adjust the alpha since we want to \n",
    "# shuffle the tagged docs each epoch\n",
    "for epoch in range(passes):  \n",
    "    # Shuffle the documents; literature reports this provides the best results\n",
    "    random.Random(seedVal).shuffle(mixedUp)\n",
    "    \n",
    "    # Train the models  \n",
    "    m2.alpha, m2.min_alpha = alpha, alpha\n",
    "    m2.train(mixedUp, total_examples = m2.corpus_count, epochs = 1)\n",
    "    \n",
    "    m3.alpha, m3.min_alpha = alpha, alpha\n",
    "    m3.train(mixedUp, total_examples = m3.corpus_count, epochs = 1)\n",
    "   \n",
    "    alpha -= alpha_delta\n",
    "\n",
    "# From the docs:  If youre finished training a model (=no more updates, only querying, reduce memory usage),\n",
    "# you can do \"model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\"\n",
    "m2.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "m3.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "\n",
    "# Release memory\n",
    "del mixedUp\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess combined model outputs on XGBoost classifier\n",
    "\n",
    "Second, ensemble the Doc2Vec model vectors and feed through a XGBoost classification model, and then evaluate the ensemble's performance against the validation test set and establish a performance baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:44:25.119988Z",
     "start_time": "2018-12-05T23:44:24.786441Z"
    }
   },
   "outputs": [],
   "source": [
    "def assessXGB(xgModel, d2vM1, d2vM2, y):\n",
    "    # Build the feature set by combining vectors from multiple models (m1 and m2)\n",
    "    trainVecs = []\n",
    "\n",
    "    for i in range(0, 25000):\n",
    "        trainVecs.append(np.hstack((d2vM1.docvecs[i], d2vM2.docvecs[i])))\n",
    "\n",
    "    print(\"len(trainVecs)\", len(trainVecs))\n",
    "\n",
    "    X_train, X_eval, y_train, y_eval = train_test_split(\n",
    "        np.asarray(trainVecs), \n",
    "        y, \n",
    "        test_size = 0.1, \n",
    "        shuffle = True, \n",
    "        random_state = seedVal, \n",
    "        stratify = y\n",
    "    )\n",
    "    \n",
    "    xgModel.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        eval_set = [(X_train, y_train), (X_eval, y_eval)],\n",
    "        eval_metric = \"auc\",\n",
    "        verbose = False,\n",
    "        early_stopping_rounds = 10,\n",
    "        callbacks=[\n",
    "            xg.callback.print_evaluation(period = 50, show_stdv = True)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    preds = model.predict(X_eval)\n",
    "    print(confusion_matrix(y_eval, preds))\n",
    "    print(accuracy_score(y_eval, preds))\n",
    "\n",
    "    plotHistory(model.evals_result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:09:09.256975Z",
     "start_time": "2018-12-05T23:08:21.064834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(trainVecs) 25000\n",
      "[0]\tvalidation_0-auc:0.765762\tvalidation_1-auc:0.756649\n",
      "[50]\tvalidation_0-auc:0.928115\tvalidation_1-auc:0.91227\n",
      "[99]\tvalidation_0-auc:0.951627\tvalidation_1-auc:0.930465\n",
      "[[1078  172]\n",
      " [ 189 1061]]\n",
      "0.8556\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = xg.XGBClassifier(\n",
    "    objective = \"binary:logistic\",\n",
    "    random_state = seedVal,\n",
    ")\n",
    "\n",
    "assessXGB(model, m2, m3, list(combinedDat['sentiment'][:25000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "Combining outputs from the PV-DBOW model and the PV-DM model seems to be heading in the right direction.  Accuracy against the evaluation test set increased from 0.848 to 0.8556.\n",
    "\n",
    "Next we'll start hyperparameter tuning for the Doc2Vec models, and see if we can further increase performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec tuning\n",
    "\n",
    "We have two Doc2Vec models to tune hyperparameters for:  PV-DBOW and PV-DM\n",
    "\n",
    "First we'll need to write a function that will allow us to pass in a set of hyperparameters, create a Doc2Vec model utilizing those hyperparameters, and then train the model on the tagged documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:32:21.588811Z",
     "start_time": "2018-12-05T23:32:21.208138Z"
    }
   },
   "outputs": [],
   "source": [
    "def trainDoc2Vec(params):\n",
    "    m = Doc2Vec(\n",
    "        dm=params['dm'], \n",
    "        dm_concat=params['dm_concat'], \n",
    "        dm_mean=params['dm_mean'],\n",
    "        size=params['size'], \n",
    "        window=params['window'], \n",
    "        negative=params['negative'], \n",
    "        hs=params['hs'], \n",
    "        min_count=params['min_count'], \n",
    "        workers=cores,\n",
    "        vector_size=['vector_size'],\n",
    "        dbow_words=params['dbow_words']\n",
    "    )\n",
    "    \n",
    "    # Build vocab\n",
    "    m.build_vocab(taggedDocs)\n",
    "\n",
    "    # Calculate alpha delta\n",
    "    alpha = params['alpha']\n",
    "    alpha_delta = (params['alpha'] - params['minAlpha']) / params['passes']\n",
    "    \n",
    "    # We don't want to shuffle taggedDocs in place later on, so make a copy\n",
    "    mixedUp = taggedDocs.copy()\n",
    "\n",
    "    # Train the models\n",
    "    for epoch in range(params['passes']):  \n",
    "        # Shuffle the documents; literature reports this provides the best results\n",
    "        random.Random(seedVal).shuffle(mixedUp)\n",
    "\n",
    "        # Train the models\n",
    "        m.alpha, m.min_alpha = alpha, alpha\n",
    "        m.train(taggedDocs, total_examples = m.corpus_count, epochs = 1)\n",
    "        \n",
    "        alpha -= alpha_delta\n",
    "    \n",
    "    # Release memory\n",
    "    m.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "    del mixedUp\n",
    "        \n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need a function that combines the document vectors of the trained Doc2Vec models, splits them into training and evaluation sets, and then feeds the vectors into a XGBoost model to create predictions.  Finally, the accuracy of the predictions needs to be evaluated against the evaluation labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:48:41.021446Z",
     "start_time": "2018-12-05T23:48:40.690566Z"
    }
   },
   "outputs": [],
   "source": [
    "def assessXGB(xgModel, d2vM1, d2vM2, y, silent = True):\n",
    "    # Build the feature set by combining vectors from multiple models (m1 and m2)\n",
    "    # Or from just a single model if only one Doc2Vec model was passed to the function\n",
    "\n",
    "    # Do we have two Doc2Vec models to combine?\n",
    "    if (d2vM2 is not None):\n",
    "        # Yes, combine\n",
    "        trainVecs = []\n",
    "        for i in range(0, 25000):\n",
    "            trainVecs.append(np.hstack((d2vM1.docvecs[i], d2vM2.docvecs[i])))\n",
    "    else:\n",
    "        # No, just use the values from the single model\n",
    "        trainVecs = d2vM1.docvecs.doctag_syn0[:25000]\n",
    "    \n",
    "    if not silent:\n",
    "        print(\"len(trainVecs)\", len(trainVecs))\n",
    "\n",
    "    # Split the Doc2Vec vectors into training and evaluation data sets\n",
    "    X_train, X_eval, y_train, y_eval = train_test_split(\n",
    "        np.asarray(trainVecs), \n",
    "        trainLabels, \n",
    "        test_size = 0.1, \n",
    "        shuffle = True, \n",
    "        random_state = seedVal, \n",
    "        stratify = trainLabels\n",
    "    )\n",
    "    \n",
    "    # Train the XGBoost model\n",
    "    xgModel.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        eval_set = [(X_train, y_train), (X_eval, y_eval)],\n",
    "        eval_metric = \"auc\",\n",
    "        verbose = False,\n",
    "        early_stopping_rounds = 10,\n",
    "        callbacks=[\n",
    "            #xg.callback.print_evaluation(period = 50, show_stdv = True)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Make predictions\n",
    "    preds = model.predict(X_eval)\n",
    "    \n",
    "    if not silent:\n",
    "        print(confusion_matrix(y_eval, preds))\n",
    "        print(accuracy_score(y_eval, preds))\n",
    "\n",
    "        plotHistory(model.evals_result())\n",
    "    else:\n",
    "        # Return the accuracy on the evaluation data set labels\n",
    "        return accuracy_score(y_eval, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:54:13.257908Z",
     "start_time": "2018-12-05T23:54:12.916000Z"
    }
   },
   "source": [
    "And finally we need another function that passes various hyperparameter combinations to the Doc2Vec model we are tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:48:42.047966Z",
     "start_time": "2018-12-05T23:48:41.729119Z"
    }
   },
   "outputs": [],
   "source": [
    "def searchDoc2VecParams(silent = True):\n",
    "    print(\"**Starting run!\\n\")\n",
    "    \n",
    "    resultsDF = pd.DataFrame(columns = ['Model', 'Accuracy', 'Params'])\n",
    "    labels = list(combinedDat['sentiment'][:25000])\n",
    "    \n",
    "    params = []\n",
    "    base = {'dm':1, 'dm_concat':0, 'dm_mean': 1, 'size':500, 'window':3, 'negative':5, \n",
    "            'hs':0, 'min_count':2, 'passes':2, 'vector_size':300, 'dbow_words':0,\n",
    "            'alpha':0.025, 'minAlpha':0.001}\n",
    "    \n",
    "    for negative_ in np.linspace(5, 11, 4):\n",
    "        for min_count_ in np.linspace(2, 5, 4):\n",
    "            for vector_size_ in np.linspace(300, 500, 2):\n",
    "                _ = copy.deepcopy(base)\n",
    "                _['negative'] = negative_\n",
    "                _['min_count'] = min_count_\n",
    "                _['vector_size'] = vector_size_\n",
    "                params.append(_)\n",
    "    \n",
    "    for i, p in enumerate(params):\n",
    "        if not silent:\n",
    "                print(\"  Starting param run\", i, \"out of\", len(params)-1, \"...\")\n",
    "        \n",
    "        start = timer()\n",
    "        doc2vecModel = trainDoc2Vec(p)\n",
    "        end = timer()\n",
    "        if not silent:\n",
    "            print(\"    Doc2Vec training finished in\", round((end-start)/60, 2), \" mins\")\n",
    "        \n",
    "        xgModel = xg.XGBClassifier(\n",
    "            objective = \"binary:logistic\",\n",
    "            random_state = seedVal\n",
    "        )\n",
    "        \n",
    "        start = timer()\n",
    "        assessXGB(xgModel, doc2vecModel, None, labels, silent = True)\n",
    "        end = timer()\n",
    "        if not silent:\n",
    "            print(\"    xgModel training finished in\", round((end-start)/60, 2), \" mins with accuracy\", results)\n",
    "    \n",
    "        resultsDF.loc[len(resultsDF)] = list([\n",
    "            'Pass ' +  str(len(resultsDF)), \n",
    "            results,\n",
    "            p,\n",
    "        ])\n",
    "            \n",
    "    if not silent:\n",
    "        print(\"\\n**Finished!\")\n",
    "    \n",
    "    return resultsDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T23:53:03.505121Z",
     "start_time": "2018-12-05T23:51:01.584576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Starting run!\n",
      "\n",
      "[0]\tvalidation_0-auc:0.755908\tvalidation_1-auc:0.748513\n",
      "[50]\tvalidation_0-auc:0.845364\tvalidation_1-auc:0.824101\n",
      "[99]\tvalidation_0-auc:0.865268\tvalidation_1-auc:0.83335\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180', 'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188', 'f189', 'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198', 'f199'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180', 'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188', 'f189', 'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198', 'f199', 'f200', 'f201', 'f202', 'f203', 'f204', 'f205', 'f206', 'f207', 'f208', 'f209', 'f210', 'f211', 'f212', 'f213', 'f214', 'f215', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222', 'f223', 'f224', 'f225', 'f226', 'f227', 'f228', 'f229', 'f230', 'f231', 'f232', 'f233', 'f234', 'f235', 'f236', 'f237', 'f238', 'f239', 'f240', 'f241', 'f242', 'f243', 'f244', 'f245', 'f246', 'f247', 'f248', 'f249', 'f250', 'f251', 'f252', 'f253', 'f254', 'f255', 'f256', 'f257', 'f258', 'f259', 'f260', 'f261', 'f262', 'f263', 'f264', 'f265', 'f266', 'f267', 'f268', 'f269', 'f270', 'f271', 'f272', 'f273', 'f274', 'f275', 'f276', 'f277', 'f278', 'f279', 'f280', 'f281', 'f282', 'f283', 'f284', 'f285', 'f286', 'f287', 'f288', 'f289', 'f290', 'f291', 'f292', 'f293', 'f294', 'f295', 'f296', 'f297', 'f298', 'f299', 'f300', 'f301', 'f302', 'f303', 'f304', 'f305', 'f306', 'f307', 'f308', 'f309', 'f310', 'f311', 'f312', 'f313', 'f314', 'f315', 'f316', 'f317', 'f318', 'f319', 'f320', 'f321', 'f322', 'f323', 'f324', 'f325', 'f326', 'f327', 'f328', 'f329', 'f330', 'f331', 'f332', 'f333', 'f334', 'f335', 'f336', 'f337', 'f338', 'f339', 'f340', 'f341', 'f342', 'f343', 'f344', 'f345', 'f346', 'f347', 'f348', 'f349', 'f350', 'f351', 'f352', 'f353', 'f354', 'f355', 'f356', 'f357', 'f358', 'f359', 'f360', 'f361', 'f362', 'f363', 'f364', 'f365', 'f366', 'f367', 'f368', 'f369', 'f370', 'f371', 'f372', 'f373', 'f374', 'f375', 'f376', 'f377', 'f378', 'f379', 'f380', 'f381', 'f382', 'f383', 'f384', 'f385', 'f386', 'f387', 'f388', 'f389', 'f390', 'f391', 'f392', 'f393', 'f394', 'f395', 'f396', 'f397', 'f398', 'f399', 'f400', 'f401', 'f402', 'f403', 'f404', 'f405', 'f406', 'f407', 'f408', 'f409', 'f410', 'f411', 'f412', 'f413', 'f414', 'f415', 'f416', 'f417', 'f418', 'f419', 'f420', 'f421', 'f422', 'f423', 'f424', 'f425', 'f426', 'f427', 'f428', 'f429', 'f430', 'f431', 'f432', 'f433', 'f434', 'f435', 'f436', 'f437', 'f438', 'f439', 'f440', 'f441', 'f442', 'f443', 'f444', 'f445', 'f446', 'f447', 'f448', 'f449', 'f450', 'f451', 'f452', 'f453', 'f454', 'f455', 'f456', 'f457', 'f458', 'f459', 'f460', 'f461', 'f462', 'f463', 'f464', 'f465', 'f466', 'f467', 'f468', 'f469', 'f470', 'f471', 'f472', 'f473', 'f474', 'f475', 'f476', 'f477', 'f478', 'f479', 'f480', 'f481', 'f482', 'f483', 'f484', 'f485', 'f486', 'f487', 'f488', 'f489', 'f490', 'f491', 'f492', 'f493', 'f494', 'f495', 'f496', 'f497', 'f498', 'f499']\ntraining data did not have the following fields: f332, f376, f447, f450, f477, f493, f341, f314, f271, f301, f281, f331, f464, f426, f432, f206, f278, f443, f431, f491, f322, f436, f386, f499, f324, f298, f227, f379, f351, f420, f453, f457, f362, f260, f410, f284, f201, f364, f230, f486, f373, f393, f203, f305, f318, f462, f359, f248, f401, f425, f434, f421, f217, f231, f360, f343, f221, f419, f487, f273, f325, f413, f321, f211, f384, f412, f261, f246, f327, f250, f275, f329, f309, f215, f485, f446, f422, f264, f300, f320, f399, f208, f400, f371, f448, f409, f375, f280, f352, f326, f476, f287, f459, f383, f279, f276, f249, f317, f216, f497, f243, f437, f225, f483, f274, f456, f262, f335, f292, f398, f484, f214, f349, f296, f272, f356, f366, f404, f467, f308, f494, f254, f202, f475, f323, f312, f222, f340, f357, f337, f368, f295, f430, f347, f339, f445, f382, f204, f498, f406, f435, f461, f207, f361, f255, f200, f299, f220, f240, f488, f495, f387, f374, f338, f492, f210, f388, f285, f454, f218, f265, f345, f259, f473, f378, f439, f365, f258, f293, f479, f233, f226, f470, f482, f244, f270, f333, f402, f334, f267, f256, f344, f469, f251, f205, f291, f350, f458, f424, f490, f478, f397, f304, f377, f315, f209, f311, f266, f245, f369, f247, f242, f346, f480, f427, f263, f428, f237, f212, f282, f463, f297, f489, f348, f313, f460, f283, f451, f438, f303, f310, f213, f268, f328, f433, f429, f363, f442, f355, f481, f385, f241, f319, f449, f392, f306, f408, f395, f418, f330, f353, f232, f223, f367, f466, f235, f228, f391, f389, f416, f236, f269, f358, f302, f239, f307, f465, f381, f257, f370, f224, f468, f440, f417, f474, f288, f472, f496, f277, f415, f396, f394, f342, f289, f423, f252, f455, f390, f407, f294, f336, f405, f444, f471, f354, f238, f441, f452, f286, f372, f229, f403, f253, f234, f290, f380, f316, f414, f219, f411",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-241-3e619cd4b104>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0m_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearchDoc2VecParams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Print results sorted by Accuracy desc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'display.max_colwidth'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0m_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-239-d72ec6b41ecb>\u001b[0m in \u001b[0;36msearchDoc2VecParams\u001b[1;34m(silent)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0massessXGB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc2vecModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-238-7834c3af423a>\u001b[0m in \u001b[0;36massessXGB\u001b[1;34m(xgModel, d2vM1, d2vM2, y, silent)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m# Make predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_eval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, validate_features)\u001b[0m\n\u001b[0;32m    757\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m                                                  \u001b[0mntree_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                                                  validate_features=validate_features)\n\u001b[0m\u001b[0;32m    760\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m             \u001b[1;31m# If output_margin is active, simply return the scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[0;32m   1216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1218\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m         \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1540\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[1;32m-> 1541\u001b[1;33m                                             data.feature_names))\n\u001b[0m\u001b[0;32m   1542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1543\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180', 'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188', 'f189', 'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198', 'f199'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f63', 'f64', 'f65', 'f66', 'f67', 'f68', 'f69', 'f70', 'f71', 'f72', 'f73', 'f74', 'f75', 'f76', 'f77', 'f78', 'f79', 'f80', 'f81', 'f82', 'f83', 'f84', 'f85', 'f86', 'f87', 'f88', 'f89', 'f90', 'f91', 'f92', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98', 'f99', 'f100', 'f101', 'f102', 'f103', 'f104', 'f105', 'f106', 'f107', 'f108', 'f109', 'f110', 'f111', 'f112', 'f113', 'f114', 'f115', 'f116', 'f117', 'f118', 'f119', 'f120', 'f121', 'f122', 'f123', 'f124', 'f125', 'f126', 'f127', 'f128', 'f129', 'f130', 'f131', 'f132', 'f133', 'f134', 'f135', 'f136', 'f137', 'f138', 'f139', 'f140', 'f141', 'f142', 'f143', 'f144', 'f145', 'f146', 'f147', 'f148', 'f149', 'f150', 'f151', 'f152', 'f153', 'f154', 'f155', 'f156', 'f157', 'f158', 'f159', 'f160', 'f161', 'f162', 'f163', 'f164', 'f165', 'f166', 'f167', 'f168', 'f169', 'f170', 'f171', 'f172', 'f173', 'f174', 'f175', 'f176', 'f177', 'f178', 'f179', 'f180', 'f181', 'f182', 'f183', 'f184', 'f185', 'f186', 'f187', 'f188', 'f189', 'f190', 'f191', 'f192', 'f193', 'f194', 'f195', 'f196', 'f197', 'f198', 'f199', 'f200', 'f201', 'f202', 'f203', 'f204', 'f205', 'f206', 'f207', 'f208', 'f209', 'f210', 'f211', 'f212', 'f213', 'f214', 'f215', 'f216', 'f217', 'f218', 'f219', 'f220', 'f221', 'f222', 'f223', 'f224', 'f225', 'f226', 'f227', 'f228', 'f229', 'f230', 'f231', 'f232', 'f233', 'f234', 'f235', 'f236', 'f237', 'f238', 'f239', 'f240', 'f241', 'f242', 'f243', 'f244', 'f245', 'f246', 'f247', 'f248', 'f249', 'f250', 'f251', 'f252', 'f253', 'f254', 'f255', 'f256', 'f257', 'f258', 'f259', 'f260', 'f261', 'f262', 'f263', 'f264', 'f265', 'f266', 'f267', 'f268', 'f269', 'f270', 'f271', 'f272', 'f273', 'f274', 'f275', 'f276', 'f277', 'f278', 'f279', 'f280', 'f281', 'f282', 'f283', 'f284', 'f285', 'f286', 'f287', 'f288', 'f289', 'f290', 'f291', 'f292', 'f293', 'f294', 'f295', 'f296', 'f297', 'f298', 'f299', 'f300', 'f301', 'f302', 'f303', 'f304', 'f305', 'f306', 'f307', 'f308', 'f309', 'f310', 'f311', 'f312', 'f313', 'f314', 'f315', 'f316', 'f317', 'f318', 'f319', 'f320', 'f321', 'f322', 'f323', 'f324', 'f325', 'f326', 'f327', 'f328', 'f329', 'f330', 'f331', 'f332', 'f333', 'f334', 'f335', 'f336', 'f337', 'f338', 'f339', 'f340', 'f341', 'f342', 'f343', 'f344', 'f345', 'f346', 'f347', 'f348', 'f349', 'f350', 'f351', 'f352', 'f353', 'f354', 'f355', 'f356', 'f357', 'f358', 'f359', 'f360', 'f361', 'f362', 'f363', 'f364', 'f365', 'f366', 'f367', 'f368', 'f369', 'f370', 'f371', 'f372', 'f373', 'f374', 'f375', 'f376', 'f377', 'f378', 'f379', 'f380', 'f381', 'f382', 'f383', 'f384', 'f385', 'f386', 'f387', 'f388', 'f389', 'f390', 'f391', 'f392', 'f393', 'f394', 'f395', 'f396', 'f397', 'f398', 'f399', 'f400', 'f401', 'f402', 'f403', 'f404', 'f405', 'f406', 'f407', 'f408', 'f409', 'f410', 'f411', 'f412', 'f413', 'f414', 'f415', 'f416', 'f417', 'f418', 'f419', 'f420', 'f421', 'f422', 'f423', 'f424', 'f425', 'f426', 'f427', 'f428', 'f429', 'f430', 'f431', 'f432', 'f433', 'f434', 'f435', 'f436', 'f437', 'f438', 'f439', 'f440', 'f441', 'f442', 'f443', 'f444', 'f445', 'f446', 'f447', 'f448', 'f449', 'f450', 'f451', 'f452', 'f453', 'f454', 'f455', 'f456', 'f457', 'f458', 'f459', 'f460', 'f461', 'f462', 'f463', 'f464', 'f465', 'f466', 'f467', 'f468', 'f469', 'f470', 'f471', 'f472', 'f473', 'f474', 'f475', 'f476', 'f477', 'f478', 'f479', 'f480', 'f481', 'f482', 'f483', 'f484', 'f485', 'f486', 'f487', 'f488', 'f489', 'f490', 'f491', 'f492', 'f493', 'f494', 'f495', 'f496', 'f497', 'f498', 'f499']\ntraining data did not have the following fields: f332, f376, f447, f450, f477, f493, f341, f314, f271, f301, f281, f331, f464, f426, f432, f206, f278, f443, f431, f491, f322, f436, f386, f499, f324, f298, f227, f379, f351, f420, f453, f457, f362, f260, f410, f284, f201, f364, f230, f486, f373, f393, f203, f305, f318, f462, f359, f248, f401, f425, f434, f421, f217, f231, f360, f343, f221, f419, f487, f273, f325, f413, f321, f211, f384, f412, f261, f246, f327, f250, f275, f329, f309, f215, f485, f446, f422, f264, f300, f320, f399, f208, f400, f371, f448, f409, f375, f280, f352, f326, f476, f287, f459, f383, f279, f276, f249, f317, f216, f497, f243, f437, f225, f483, f274, f456, f262, f335, f292, f398, f484, f214, f349, f296, f272, f356, f366, f404, f467, f308, f494, f254, f202, f475, f323, f312, f222, f340, f357, f337, f368, f295, f430, f347, f339, f445, f382, f204, f498, f406, f435, f461, f207, f361, f255, f200, f299, f220, f240, f488, f495, f387, f374, f338, f492, f210, f388, f285, f454, f218, f265, f345, f259, f473, f378, f439, f365, f258, f293, f479, f233, f226, f470, f482, f244, f270, f333, f402, f334, f267, f256, f344, f469, f251, f205, f291, f350, f458, f424, f490, f478, f397, f304, f377, f315, f209, f311, f266, f245, f369, f247, f242, f346, f480, f427, f263, f428, f237, f212, f282, f463, f297, f489, f348, f313, f460, f283, f451, f438, f303, f310, f213, f268, f328, f433, f429, f363, f442, f355, f481, f385, f241, f319, f449, f392, f306, f408, f395, f418, f330, f353, f232, f223, f367, f466, f235, f228, f391, f389, f416, f236, f269, f358, f302, f239, f307, f465, f381, f257, f370, f224, f468, f440, f417, f474, f288, f472, f496, f277, f415, f396, f394, f342, f289, f423, f252, f455, f390, f407, f294, f336, f405, f444, f471, f354, f238, f441, f452, f286, f372, f229, f403, f253, f234, f290, f380, f316, f414, f219, f411"
     ]
    }
   ],
   "source": [
    "_df = searchDoc2VecParams()\n",
    "\n",
    "# Print results sorted by Accuracy desc\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "_df.sort_values(by = ['Accuracy'], ascending = [False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-30T23:47:53.126814Z",
     "start_time": "2018-11-30T23:41:24.705313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Starting run!\n",
      "\n",
      "  Starting param run 0 out of 2 ...\n",
      "    Doc2Vec training finished in 1.55  mins\n",
      "    xgModel training finished in 0.77  mins with accuracy 0.5836\n",
      "  Starting param run 1 out of 2 ...\n",
      "    Doc2Vec training finished in 1.64  mins\n",
      "    xgModel training finished in 0.49  mins with accuracy 0.58\n",
      "  Starting param run 2 out of 2 ...\n",
      "    Doc2Vec training finished in 1.63  mins\n",
      "    xgModel training finished in 0.37  mins with accuracy 0.572\n",
      "\n",
      "**Finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pass 0</td>\n",
       "      <td>0.5836</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pass 1</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 5, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pass 2</td>\n",
       "      <td>0.5720</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 7, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  Accuracy  \\\n",
       "0  Pass 0  0.5836     \n",
       "1  Pass 1  0.5800     \n",
       "2  Pass 2  0.5720     \n",
       "\n",
       "                                                                                                                   Params  \n",
       "0  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2}  \n",
       "1  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 5, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2}  \n",
       "2  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 7, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2}  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df = searchParams(False)\n",
    "\n",
    "# Print results sorted by Accuracy desc\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "_df.sort_values(by = ['Accuracy'], ascending = [False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-30T23:55:10.417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Starting run!\n",
      "\n",
      "  Starting param run 0 out of 15 ...\n",
      "    Doc2Vec training finished in 1.58  mins\n",
      "    xgModel training finished in 0.42  mins with accuracy 0.578\n",
      "  Starting param run 1 out of 15 ...\n"
     ]
    }
   ],
   "source": [
    "_df = searchParams(False)\n",
    "\n",
    "# Print results sorted by Accuracy desc\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "_df.sort_values(by = ['Accuracy'], ascending = [False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T21:51:12.471911Z",
     "start_time": "2018-12-02T19:49:32.840093Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Starting run!\n",
      "\n",
      "  Starting param run 0 out of 31 ...\n",
      "    Doc2Vec training finished in 0.54  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.09  mins with accuracy 0.736\n",
      "  Starting param run 1 out of 31 ...\n",
      "    Doc2Vec training finished in 0.54  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.16  mins with accuracy 0.7268\n",
      "  Starting param run 2 out of 31 ...\n",
      "    Doc2Vec training finished in 0.54  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.12  mins with accuracy 0.7224\n",
      "  Starting param run 3 out of 31 ...\n",
      "    Doc2Vec training finished in 0.53  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.13  mins with accuracy 0.7252\n",
      "  Starting param run 4 out of 31 ...\n",
      "    Doc2Vec training finished in 0.53  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.09  mins with accuracy 0.7304\n",
      "  Starting param run 5 out of 31 ...\n",
      "    Doc2Vec training finished in 0.52  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.2  mins with accuracy 0.7404\n",
      "  Starting param run 6 out of 31 ...\n",
      "    Doc2Vec training finished in 0.51  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.2  mins with accuracy 0.7212\n",
      "  Starting param run 7 out of 31 ...\n",
      "    Doc2Vec training finished in 0.53  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.08  mins with accuracy 0.7184\n",
      "  Starting param run 8 out of 31 ...\n",
      "    Doc2Vec training finished in 0.64  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.07  mins with accuracy 0.728\n",
      "  Starting param run 9 out of 31 ...\n",
      "    Doc2Vec training finished in 0.64  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.12  mins with accuracy 0.7236\n",
      "  Starting param run 10 out of 31 ...\n",
      "    Doc2Vec training finished in 0.64  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.08  mins with accuracy 0.7416\n",
      "  Starting param run 11 out of 31 ...\n",
      "    Doc2Vec training finished in 0.62  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.2  mins with accuracy 0.7144\n",
      "  Starting param run 12 out of 31 ...\n",
      "    Doc2Vec training finished in 0.62  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.11  mins with accuracy 0.7352\n",
      "  Starting param run 13 out of 31 ...\n",
      "    Doc2Vec training finished in 0.62  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.21  mins with accuracy 0.7288\n",
      "  Starting param run 14 out of 31 ...\n",
      "    Doc2Vec training finished in 0.61  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.24  mins with accuracy 0.7228\n",
      "  Starting param run 15 out of 31 ...\n",
      "    Doc2Vec training finished in 0.62  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.1  mins with accuracy 0.7348\n",
      "  Starting param run 16 out of 31 ...\n",
      "    Doc2Vec training finished in 0.73  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.18  mins with accuracy 0.7412\n",
      "  Starting param run 17 out of 31 ...\n",
      "    Doc2Vec training finished in 0.73  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.13  mins with accuracy 0.7432\n",
      "  Starting param run 18 out of 31 ...\n",
      "    Doc2Vec training finished in 0.73  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.12  mins with accuracy 0.7392\n",
      "  Starting param run 19 out of 31 ...\n",
      "    Doc2Vec training finished in 0.72  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.21  mins with accuracy 0.7464\n",
      "  Starting param run 20 out of 31 ...\n",
      "    Doc2Vec training finished in 0.71  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.1  mins with accuracy 0.7476\n",
      "  Starting param run 21 out of 31 ...\n",
      "    Doc2Vec training finished in 0.72  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.09  mins with accuracy 0.74\n",
      "  Starting param run 22 out of 31 ...\n",
      "    Doc2Vec training finished in 0.71  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.08  mins with accuracy 0.7496\n",
      "  Starting param run 23 out of 31 ...\n",
      "    Doc2Vec training finished in 0.71  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.1  mins with accuracy 0.7476\n",
      "  Starting param run 24 out of 31 ...\n",
      "    Doc2Vec training finished in 0.85  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.09  mins with accuracy 0.7464\n",
      "  Starting param run 25 out of 31 ...\n",
      "    Doc2Vec training finished in 0.83  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.1  mins with accuracy 0.7488\n",
      "  Starting param run 26 out of 31 ...\n",
      "    Doc2Vec training finished in 0.82  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.11  mins with accuracy 0.758\n",
      "  Starting param run 27 out of 31 ...\n",
      "    Doc2Vec training finished in 0.83  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.12  mins with accuracy 0.7392\n",
      "  Starting param run 28 out of 31 ...\n",
      "    Doc2Vec training finished in 0.81  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.07  mins with accuracy 0.7432\n",
      "  Starting param run 29 out of 31 ...\n",
      "    Doc2Vec training finished in 0.81  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.12  mins with accuracy 0.7444\n",
      "  Starting param run 30 out of 31 ...\n",
      "    Doc2Vec training finished in 0.8  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.09  mins with accuracy 0.7444\n",
      "  Starting param run 31 out of 31 ...\n",
      "    Doc2Vec training finished in 0.8  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 3.07  mins with accuracy 0.7428\n",
      "\n",
      "**Finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Pass 26</td>\n",
       "      <td>0.7580</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11.0, 'hs': 0, 'min_count': 3.0, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Pass 22</td>\n",
       "      <td>0.7496</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 9.0, 'hs': 0, 'min_count': 5.0, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Pass 25</td>\n",
       "      <td>0.7488</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11.0, 'hs': 0, 'min_count': 2.0, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Pass 23</td>\n",
       "      <td>0.7476</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 9.0, 'hs': 0, 'min_count': 5.0, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pass 20</td>\n",
       "      <td>0.7476</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 9.0, 'hs': 0, 'min_count': 4.0, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Pass 24</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11.0, 'hs': 0, 'min_count': 2.0, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Pass 19</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 9.0, 'hs': 0, 'min_count': 3.0, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Pass 30</td>\n",
       "      <td>0.7444</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11.0, 'hs': 0, 'min_count': 5.0, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Pass 29</td>\n",
       "      <td>0.7444</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11.0, 'hs': 0, 'min_count': 4.0, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Pass 17</td>\n",
       "      <td>0.7432</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 9.0, 'hs': 0, 'min_count': 2.0, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Pass 28</td>\n",
       "      <td>0.7432</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11.0, 'hs': 0, 'min_count': 4.0, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Pass 31</td>\n",
       "      <td>0.7428</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11.0, 'hs': 0, 'min_count': 5.0, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pass 10</td>\n",
       "      <td>0.7416</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7.0, 'hs': 0, 'min_count': 3.0, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pass 16</td>\n",
       "      <td>0.7412</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 9.0, 'hs': 0, 'min_count': 2.0, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pass 5</td>\n",
       "      <td>0.7404</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 5.0, 'hs': 0, 'min_count': 4.0, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pass 21</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 9.0, 'hs': 0, 'min_count': 4.0, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pass 18</td>\n",
       "      <td>0.7392</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 9.0, 'hs': 0, 'min_count': 3.0, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Pass 27</td>\n",
       "      <td>0.7392</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11.0, 'hs': 0, 'min_count': 3.0, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pass 0</td>\n",
       "      <td>0.7360</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 5.0, 'hs': 0, 'min_count': 2.0, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pass 12</td>\n",
       "      <td>0.7352</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7.0, 'hs': 0, 'min_count': 4.0, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pass 15</td>\n",
       "      <td>0.7348</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7.0, 'hs': 0, 'min_count': 5.0, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pass 4</td>\n",
       "      <td>0.7304</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 5.0, 'hs': 0, 'min_count': 4.0, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pass 13</td>\n",
       "      <td>0.7288</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7.0, 'hs': 0, 'min_count': 4.0, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pass 8</td>\n",
       "      <td>0.7280</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7.0, 'hs': 0, 'min_count': 2.0, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pass 1</td>\n",
       "      <td>0.7268</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 5.0, 'hs': 0, 'min_count': 2.0, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pass 3</td>\n",
       "      <td>0.7252</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 5.0, 'hs': 0, 'min_count': 3.0, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pass 9</td>\n",
       "      <td>0.7236</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7.0, 'hs': 0, 'min_count': 2.0, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pass 14</td>\n",
       "      <td>0.7228</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7.0, 'hs': 0, 'min_count': 5.0, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pass 2</td>\n",
       "      <td>0.7224</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 5.0, 'hs': 0, 'min_count': 3.0, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pass 6</td>\n",
       "      <td>0.7212</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 5.0, 'hs': 0, 'min_count': 5.0, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pass 7</td>\n",
       "      <td>0.7184</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 5.0, 'hs': 0, 'min_count': 5.0, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pass 11</td>\n",
       "      <td>0.7144</td>\n",
       "      <td>{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7.0, 'hs': 0, 'min_count': 3.0, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy  \\\n",
       "26  Pass 26  0.7580     \n",
       "22  Pass 22  0.7496     \n",
       "25  Pass 25  0.7488     \n",
       "23  Pass 23  0.7476     \n",
       "20  Pass 20  0.7476     \n",
       "24  Pass 24  0.7464     \n",
       "19  Pass 19  0.7464     \n",
       "30  Pass 30  0.7444     \n",
       "29  Pass 29  0.7444     \n",
       "17  Pass 17  0.7432     \n",
       "28  Pass 28  0.7432     \n",
       "31  Pass 31  0.7428     \n",
       "10  Pass 10  0.7416     \n",
       "16  Pass 16  0.7412     \n",
       "5   Pass 5   0.7404     \n",
       "21  Pass 21  0.7400     \n",
       "18  Pass 18  0.7392     \n",
       "27  Pass 27  0.7392     \n",
       "0   Pass 0   0.7360     \n",
       "12  Pass 12  0.7352     \n",
       "15  Pass 15  0.7348     \n",
       "4   Pass 4   0.7304     \n",
       "13  Pass 13  0.7288     \n",
       "8   Pass 8   0.7280     \n",
       "1   Pass 1   0.7268     \n",
       "3   Pass 3   0.7252     \n",
       "9   Pass 9   0.7236     \n",
       "14  Pass 14  0.7228     \n",
       "2   Pass 2   0.7224     \n",
       "6   Pass 6   0.7212     \n",
       "7   Pass 7   0.7184     \n",
       "11  Pass 11  0.7144     \n",
       "\n",
       "                                                                                                                                               Params  \n",
       "26  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11.0, 'hs': 0, 'min_count': 3.0, 'passes': 2, 'vector_size': 300.0}  \n",
       "22  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 9.0, 'hs': 0, 'min_count': 5.0, 'passes': 2, 'vector_size': 300.0}   \n",
       "25  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11.0, 'hs': 0, 'min_count': 2.0, 'passes': 2, 'vector_size': 500.0}  \n",
       "23  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 9.0, 'hs': 0, 'min_count': 5.0, 'passes': 2, 'vector_size': 500.0}   \n",
       "20  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 9.0, 'hs': 0, 'min_count': 4.0, 'passes': 2, 'vector_size': 300.0}   \n",
       "24  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11.0, 'hs': 0, 'min_count': 2.0, 'passes': 2, 'vector_size': 300.0}  \n",
       "19  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 9.0, 'hs': 0, 'min_count': 3.0, 'passes': 2, 'vector_size': 500.0}   \n",
       "30  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11.0, 'hs': 0, 'min_count': 5.0, 'passes': 2, 'vector_size': 300.0}  \n",
       "29  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11.0, 'hs': 0, 'min_count': 4.0, 'passes': 2, 'vector_size': 500.0}  \n",
       "17  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 9.0, 'hs': 0, 'min_count': 2.0, 'passes': 2, 'vector_size': 500.0}   \n",
       "28  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11.0, 'hs': 0, 'min_count': 4.0, 'passes': 2, 'vector_size': 300.0}  \n",
       "31  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11.0, 'hs': 0, 'min_count': 5.0, 'passes': 2, 'vector_size': 500.0}  \n",
       "10  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7.0, 'hs': 0, 'min_count': 3.0, 'passes': 2, 'vector_size': 300.0}   \n",
       "16  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 9.0, 'hs': 0, 'min_count': 2.0, 'passes': 2, 'vector_size': 300.0}   \n",
       "5   {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 5.0, 'hs': 0, 'min_count': 4.0, 'passes': 2, 'vector_size': 500.0}   \n",
       "21  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 9.0, 'hs': 0, 'min_count': 4.0, 'passes': 2, 'vector_size': 500.0}   \n",
       "18  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 9.0, 'hs': 0, 'min_count': 3.0, 'passes': 2, 'vector_size': 300.0}   \n",
       "27  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11.0, 'hs': 0, 'min_count': 3.0, 'passes': 2, 'vector_size': 500.0}  \n",
       "0   {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 5.0, 'hs': 0, 'min_count': 2.0, 'passes': 2, 'vector_size': 300.0}   \n",
       "12  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7.0, 'hs': 0, 'min_count': 4.0, 'passes': 2, 'vector_size': 300.0}   \n",
       "15  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7.0, 'hs': 0, 'min_count': 5.0, 'passes': 2, 'vector_size': 500.0}   \n",
       "4   {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 5.0, 'hs': 0, 'min_count': 4.0, 'passes': 2, 'vector_size': 300.0}   \n",
       "13  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7.0, 'hs': 0, 'min_count': 4.0, 'passes': 2, 'vector_size': 500.0}   \n",
       "8   {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7.0, 'hs': 0, 'min_count': 2.0, 'passes': 2, 'vector_size': 300.0}   \n",
       "1   {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 5.0, 'hs': 0, 'min_count': 2.0, 'passes': 2, 'vector_size': 500.0}   \n",
       "3   {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 5.0, 'hs': 0, 'min_count': 3.0, 'passes': 2, 'vector_size': 500.0}   \n",
       "9   {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7.0, 'hs': 0, 'min_count': 2.0, 'passes': 2, 'vector_size': 500.0}   \n",
       "14  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7.0, 'hs': 0, 'min_count': 5.0, 'passes': 2, 'vector_size': 300.0}   \n",
       "2   {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 5.0, 'hs': 0, 'min_count': 3.0, 'passes': 2, 'vector_size': 300.0}   \n",
       "6   {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 5.0, 'hs': 0, 'min_count': 5.0, 'passes': 2, 'vector_size': 300.0}   \n",
       "7   {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 5.0, 'hs': 0, 'min_count': 5.0, 'passes': 2, 'vector_size': 500.0}   \n",
       "11  {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 7.0, 'hs': 0, 'min_count': 3.0, 'passes': 2, 'vector_size': 500.0}   "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df = searchParams(False)\n",
    "\n",
    "# Print results sorted by Accuracy desc\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "_df.sort_values(by = ['Accuracy'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best so far for dm1:\n",
    "\n",
    "26 \tPass 26 \t0.7580 \t{'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11.0, 'hs': 0, 'min_count': 3.0, 'passes': 2, 'vector_size': 300.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DM0 training\n",
    "\n",
    "From previous write-up:  m2 = Doc2Vec(dm=0, size=100, negative=5, hs=0, min_count=2, workers=cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T23:27:18.835764Z",
     "start_time": "2018-12-02T23:27:18.505758Z"
    }
   },
   "outputs": [],
   "source": [
    "def searchParams2(silent = True):\n",
    "    print(\"**Starting run!\\n\")\n",
    "    \n",
    "    resultsDF = pd.DataFrame(columns = ['Model', 'Accuracy', 'Params'])\n",
    "    \n",
    "    params = []\n",
    "    # Set concat and mean to 1\n",
    "    #  3 \tPass 3 \t0.7436 \t{'dm': 0, 'dm_concat': 1.0, 'dm_mean': 1.0, 'size': 100, 'window': 3, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300}\n",
    "    \n",
    "    base = {'dm':0, 'dm_concat':1, 'dm_mean': 1, 'size':100, 'window':3, 'negative':5, \n",
    "            'hs':0, 'min_count':2, 'passes':2, 'vector_size':300}\n",
    "    \n",
    "    #for dm_concat_ in np.linspace(0, 1, 2):\n",
    "    #    for dm_mean_ in np.linspace(0, 1, 2):\n",
    "    #        _ = copy.deepcopy(base)\n",
    "    #        _['dm_concat'] = dm_concat_\n",
    "    #        _['dm_mean'] = dm_mean_\n",
    "    #        params.append(_)\n",
    "                \n",
    "    for size_ in np.linspace(100, 500, 3):\n",
    "        for window_ in np.linspace(3, 7, 3):\n",
    "            for vector_size_ in np.linspace(100, 700, 4):\n",
    "                _ = copy.deepcopy(base)\n",
    "                _['size'] = size_\n",
    "                _['window'] = window_\n",
    "                _['vector_size'] = vector_size_\n",
    "                params.append(_)\n",
    "    \n",
    "    for i, p in enumerate(params):\n",
    "        if not silent:\n",
    "                print(\"  Starting param run\", i, \"out of\", len(params)-1, \"...\")\n",
    "        \n",
    "        start = timer()\n",
    "        doc2vecModel = trainDoc2Vec(p)\n",
    "        end = timer()\n",
    "        if not silent:\n",
    "            print(\"    Doc2Vec training finished in\", round((end-start)/60, 2), \" mins\")\n",
    "        \n",
    "        xgModel = xg.XGBClassifier(\n",
    "            objective = \"binary:logistic\",\n",
    "            random_state = seedVal\n",
    "        )\n",
    "        \n",
    "        start = timer()\n",
    "        results = assessSingleXGB(xgModel, doc2vecModel, list(combinedDat['sentiment'][:25000]))\n",
    "        end = timer()\n",
    "        if not silent:\n",
    "            print(\"    xgModel training finished in\", round((end-start)/60, 2), \" mins with accuracy\", results)\n",
    "    \n",
    "        resultsDF.loc[len(resultsDF)] = list([\n",
    "            'Pass ' +  str(len(resultsDF)), \n",
    "            results,\n",
    "            p,\n",
    "        ])\n",
    "            \n",
    "    if not silent:\n",
    "        print(\"\\n**Finished!\")\n",
    "    \n",
    "    return resultsDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T23:20:59.207656Z",
     "start_time": "2018-12-02T23:17:18.039307Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Starting run!\n",
      "\n",
      "  Starting param run 0 out of 3 ...\n",
      "    Doc2Vec training finished in 0.25  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 0.66  mins with accuracy 0.732\n",
      "  Starting param run 1 out of 3 ...\n",
      "    Doc2Vec training finished in 0.25  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 0.68  mins with accuracy 0.7388\n",
      "  Starting param run 2 out of 3 ...\n",
      "    Doc2Vec training finished in 0.26  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 0.66  mins with accuracy 0.7308\n",
      "  Starting param run 3 out of 3 ...\n",
      "    Doc2Vec training finished in 0.26  mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nathan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    xgModel training finished in 0.66  mins with accuracy 0.7436\n",
      "\n",
      "**Finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pass 3</td>\n",
       "      <td>0.7436</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1.0, 'dm_mean': 1.0, 'size': 100, 'window': 3, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pass 1</td>\n",
       "      <td>0.7388</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 0.0, 'dm_mean': 1.0, 'size': 100, 'window': 3, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pass 0</td>\n",
       "      <td>0.7320</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 0.0, 'dm_mean': 0.0, 'size': 100, 'window': 3, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pass 2</td>\n",
       "      <td>0.7308</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1.0, 'dm_mean': 0.0, 'size': 100, 'window': 3, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  Accuracy  \\\n",
       "3  Pass 3  0.7436     \n",
       "1  Pass 1  0.7388     \n",
       "0  Pass 0  0.7320     \n",
       "2  Pass 2  0.7308     \n",
       "\n",
       "                                                                                                                                           Params  \n",
       "3  {'dm': 0, 'dm_concat': 1.0, 'dm_mean': 1.0, 'size': 100, 'window': 3, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300}  \n",
       "1  {'dm': 0, 'dm_concat': 0.0, 'dm_mean': 1.0, 'size': 100, 'window': 3, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300}  \n",
       "0  {'dm': 0, 'dm_concat': 0.0, 'dm_mean': 0.0, 'size': 100, 'window': 3, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300}  \n",
       "2  {'dm': 0, 'dm_concat': 1.0, 'dm_mean': 0.0, 'size': 100, 'window': 3, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300}  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df = searchParams2(False)\n",
    "\n",
    "# Print results sorted by Accuracy desc\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "_df.sort_values(by = ['Accuracy'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T03:54:13.004543Z",
     "start_time": "2018-12-03T02:28:31.222583Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Starting run!\n",
      "\n",
      "  Starting param run 0 out of 35 ...\n",
      "    Doc2Vec training finished in 4.81  mins\n",
      "    xgModel training finished in 0.69  mins with accuracy 0.7524\n",
      "  Starting param run 1 out of 35 ...\n",
      "    Doc2Vec training finished in 0.27  mins\n",
      "    xgModel training finished in 0.66  mins with accuracy 0.7516\n",
      "  Starting param run 2 out of 35 ...\n",
      "    Doc2Vec training finished in 0.26  mins\n",
      "    xgModel training finished in 0.65  mins with accuracy 0.7444\n",
      "  Starting param run 3 out of 35 ...\n",
      "    Doc2Vec training finished in 0.27  mins\n",
      "    xgModel training finished in 0.68  mins with accuracy 0.7516\n",
      "  Starting param run 4 out of 35 ...\n",
      "    Doc2Vec training finished in 0.26  mins\n",
      "    xgModel training finished in 0.67  mins with accuracy 0.738\n",
      "  Starting param run 5 out of 35 ...\n",
      "    Doc2Vec training finished in 0.26  mins\n",
      "    xgModel training finished in 0.66  mins with accuracy 0.7492\n",
      "  Starting param run 6 out of 35 ...\n",
      "    Doc2Vec training finished in 0.26  mins\n",
      "    xgModel training finished in 0.65  mins with accuracy 0.7436\n",
      "  Starting param run 7 out of 35 ...\n",
      "    Doc2Vec training finished in 0.25  mins\n",
      "    xgModel training finished in 0.64  mins with accuracy 0.7532\n",
      "  Starting param run 8 out of 35 ...\n",
      "    Doc2Vec training finished in 0.25  mins\n",
      "    xgModel training finished in 0.64  mins with accuracy 0.76\n",
      "  Starting param run 9 out of 35 ...\n",
      "    Doc2Vec training finished in 0.25  mins\n",
      "    xgModel training finished in 0.64  mins with accuracy 0.7492\n",
      "  Starting param run 10 out of 35 ...\n",
      "    Doc2Vec training finished in 0.26  mins\n",
      "    xgModel training finished in 0.65  mins with accuracy 0.7332\n",
      "  Starting param run 11 out of 35 ...\n",
      "    Doc2Vec training finished in 0.25  mins\n",
      "    xgModel training finished in 0.64  mins with accuracy 0.7456\n",
      "  Starting param run 12 out of 35 ...\n",
      "    Doc2Vec training finished in 0.36  mins\n",
      "    xgModel training finished in 1.89  mins with accuracy 0.7332\n",
      "  Starting param run 13 out of 35 ...\n",
      "    Doc2Vec training finished in 0.35  mins\n",
      "    xgModel training finished in 1.87  mins with accuracy 0.746\n",
      "  Starting param run 14 out of 35 ...\n",
      "    Doc2Vec training finished in 0.37  mins\n",
      "    xgModel training finished in 1.88  mins with accuracy 0.7436\n",
      "  Starting param run 15 out of 35 ...\n",
      "    Doc2Vec training finished in 0.35  mins\n",
      "    xgModel training finished in 1.87  mins with accuracy 0.74\n",
      "  Starting param run 16 out of 35 ...\n",
      "    Doc2Vec training finished in 0.35  mins\n",
      "    xgModel training finished in 1.88  mins with accuracy 0.7488\n",
      "  Starting param run 17 out of 35 ...\n",
      "    Doc2Vec training finished in 0.36  mins\n",
      "    xgModel training finished in 1.86  mins with accuracy 0.7456\n",
      "  Starting param run 18 out of 35 ...\n",
      "    Doc2Vec training finished in 0.35  mins\n",
      "    xgModel training finished in 1.87  mins with accuracy 0.746\n",
      "  Starting param run 19 out of 35 ...\n",
      "    Doc2Vec training finished in 0.35  mins\n",
      "    xgModel training finished in 1.92  mins with accuracy 0.7352\n",
      "  Starting param run 20 out of 35 ...\n",
      "    Doc2Vec training finished in 0.35  mins\n",
      "    xgModel training finished in 1.89  mins with accuracy 0.732\n",
      "  Starting param run 21 out of 35 ...\n",
      "    Doc2Vec training finished in 0.36  mins\n",
      "    xgModel training finished in 1.83  mins with accuracy 0.7472\n",
      "  Starting param run 22 out of 35 ...\n",
      "    Doc2Vec training finished in 0.35  mins\n",
      "    xgModel training finished in 1.88  mins with accuracy 0.7416\n",
      "  Starting param run 23 out of 35 ...\n",
      "    Doc2Vec training finished in 0.35  mins\n",
      "    xgModel training finished in 1.88  mins with accuracy 0.7392\n",
      "  Starting param run 24 out of 35 ...\n",
      "    Doc2Vec training finished in 0.46  mins\n",
      "    xgModel training finished in 3.11  mins with accuracy 0.7472\n",
      "  Starting param run 25 out of 35 ...\n",
      "    Doc2Vec training finished in 0.47  mins\n",
      "    xgModel training finished in 3.1  mins with accuracy 0.7384\n",
      "  Starting param run 26 out of 35 ...\n",
      "    Doc2Vec training finished in 0.46  mins\n",
      "    xgModel training finished in 3.13  mins with accuracy 0.7324\n",
      "  Starting param run 27 out of 35 ...\n",
      "    Doc2Vec training finished in 0.46  mins\n",
      "    xgModel training finished in 3.1  mins with accuracy 0.7388\n",
      "  Starting param run 28 out of 35 ...\n",
      "    Doc2Vec training finished in 0.47  mins\n",
      "    xgModel training finished in 3.21  mins with accuracy 0.7424\n",
      "  Starting param run 29 out of 35 ...\n",
      "    Doc2Vec training finished in 0.46  mins\n",
      "    xgModel training finished in 3.12  mins with accuracy 0.7364\n",
      "  Starting param run 30 out of 35 ...\n",
      "    Doc2Vec training finished in 0.46  mins\n",
      "    xgModel training finished in 3.12  mins with accuracy 0.7484\n",
      "  Starting param run 31 out of 35 ...\n",
      "    Doc2Vec training finished in 0.46  mins\n",
      "    xgModel training finished in 3.12  mins with accuracy 0.7536\n",
      "  Starting param run 32 out of 35 ...\n",
      "    Doc2Vec training finished in 0.47  mins\n",
      "    xgModel training finished in 3.14  mins with accuracy 0.7272\n",
      "  Starting param run 33 out of 35 ...\n",
      "    Doc2Vec training finished in 0.46  mins\n",
      "    xgModel training finished in 3.1  mins with accuracy 0.7416\n",
      "  Starting param run 34 out of 35 ...\n",
      "    Doc2Vec training finished in 0.46  mins\n",
      "    xgModel training finished in 3.12  mins with accuracy 0.7452\n",
      "  Starting param run 35 out of 35 ...\n",
      "    Doc2Vec training finished in 0.48  mins\n",
      "    xgModel training finished in 3.1  mins with accuracy 0.7476\n",
      "\n",
      "**Finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pass 8</td>\n",
       "      <td>0.7600</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Pass 31</td>\n",
       "      <td>0.7536</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 700.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pass 7</td>\n",
       "      <td>0.7532</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 700.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pass 0</td>\n",
       "      <td>0.7524</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pass 3</td>\n",
       "      <td>0.7516</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 700.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pass 1</td>\n",
       "      <td>0.7516</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pass 5</td>\n",
       "      <td>0.7492</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pass 9</td>\n",
       "      <td>0.7492</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pass 16</td>\n",
       "      <td>0.7488</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Pass 30</td>\n",
       "      <td>0.7484</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Pass 35</td>\n",
       "      <td>0.7476</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 700.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Pass 24</td>\n",
       "      <td>0.7472</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pass 21</td>\n",
       "      <td>0.7472</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Pass 18</td>\n",
       "      <td>0.7460</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pass 13</td>\n",
       "      <td>0.7460</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Pass 17</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pass 11</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 700.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Pass 34</td>\n",
       "      <td>0.7452</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pass 2</td>\n",
       "      <td>0.7444</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pass 14</td>\n",
       "      <td>0.7436</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pass 6</td>\n",
       "      <td>0.7436</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Pass 28</td>\n",
       "      <td>0.7424</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Pass 22</td>\n",
       "      <td>0.7416</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Pass 33</td>\n",
       "      <td>0.7416</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pass 15</td>\n",
       "      <td>0.7400</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 700.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Pass 23</td>\n",
       "      <td>0.7392</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 700.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Pass 27</td>\n",
       "      <td>0.7388</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 700.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Pass 25</td>\n",
       "      <td>0.7384</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pass 4</td>\n",
       "      <td>0.7380</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Pass 29</td>\n",
       "      <td>0.7364</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Pass 19</td>\n",
       "      <td>0.7352</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 700.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pass 10</td>\n",
       "      <td>0.7332</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pass 12</td>\n",
       "      <td>0.7332</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Pass 26</td>\n",
       "      <td>0.7324</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 500.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pass 20</td>\n",
       "      <td>0.7320</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Pass 32</td>\n",
       "      <td>0.7272</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy  \\\n",
       "8   Pass 8   0.7600     \n",
       "31  Pass 31  0.7536     \n",
       "7   Pass 7   0.7532     \n",
       "0   Pass 0   0.7524     \n",
       "3   Pass 3   0.7516     \n",
       "1   Pass 1   0.7516     \n",
       "5   Pass 5   0.7492     \n",
       "9   Pass 9   0.7492     \n",
       "16  Pass 16  0.7488     \n",
       "30  Pass 30  0.7484     \n",
       "35  Pass 35  0.7476     \n",
       "24  Pass 24  0.7472     \n",
       "21  Pass 21  0.7472     \n",
       "18  Pass 18  0.7460     \n",
       "13  Pass 13  0.7460     \n",
       "17  Pass 17  0.7456     \n",
       "11  Pass 11  0.7456     \n",
       "34  Pass 34  0.7452     \n",
       "2   Pass 2   0.7444     \n",
       "14  Pass 14  0.7436     \n",
       "6   Pass 6   0.7436     \n",
       "28  Pass 28  0.7424     \n",
       "22  Pass 22  0.7416     \n",
       "33  Pass 33  0.7416     \n",
       "15  Pass 15  0.7400     \n",
       "23  Pass 23  0.7392     \n",
       "27  Pass 27  0.7388     \n",
       "25  Pass 25  0.7384     \n",
       "4   Pass 4   0.7380     \n",
       "29  Pass 29  0.7364     \n",
       "19  Pass 19  0.7352     \n",
       "10  Pass 10  0.7332     \n",
       "12  Pass 12  0.7332     \n",
       "26  Pass 26  0.7324     \n",
       "20  Pass 20  0.7320     \n",
       "32  Pass 32  0.7272     \n",
       "\n",
       "                                                                                                                                              Params  \n",
       "8   {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100.0}  \n",
       "31  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 700.0}  \n",
       "7   {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 700.0}  \n",
       "0   {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100.0}  \n",
       "3   {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 700.0}  \n",
       "1   {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300.0}  \n",
       "5   {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300.0}  \n",
       "9   {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300.0}  \n",
       "16  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100.0}  \n",
       "30  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 500.0}  \n",
       "35  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 700.0}  \n",
       "24  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100.0}  \n",
       "21  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300.0}  \n",
       "18  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 500.0}  \n",
       "13  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300.0}  \n",
       "17  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300.0}  \n",
       "11  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 700.0}  \n",
       "34  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 500.0}  \n",
       "2   {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 500.0}  \n",
       "14  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 500.0}  \n",
       "6   {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 500.0}  \n",
       "28  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100.0}  \n",
       "22  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 500.0}  \n",
       "33  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300.0}  \n",
       "15  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 700.0}  \n",
       "23  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 700.0}  \n",
       "27  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 700.0}  \n",
       "25  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300.0}  \n",
       "4   {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100.0}  \n",
       "29  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300.0}  \n",
       "19  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 5.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 700.0}  \n",
       "10  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 500.0}  \n",
       "12  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100.0}  \n",
       "26  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 3.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 500.0}  \n",
       "20  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 300.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100.0}  \n",
       "32  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 500.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100.0}  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df = searchParams2(False)\n",
    "\n",
    "# Print results sorted by Accuracy desc\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "_df.sort_values(by = ['Accuracy'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best so far for dm0\n",
    "\n",
    "8 \tPass 8 \t0.7600 \t{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100.0, 'window': 7.0, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T16:19:03.393148Z",
     "start_time": "2018-12-05T16:19:03.067273Z"
    }
   },
   "outputs": [],
   "source": [
    "def searchParams3(silent = True):\n",
    "    print(\"**Starting run!\\n\")\n",
    "    \n",
    "    resultsDF = pd.DataFrame(columns = ['Model', 'Accuracy', 'Params'])\n",
    "    \n",
    "    params = []\n",
    "    # Set concat and mean to 1\n",
    "    #  3 \tPass 3 \t0.7436 \t{'dm': 0, 'dm_concat': 1.0, 'dm_mean': 1.0, 'size': 100, 'window': 3, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 300}\n",
    "    \n",
    "    base = {'dm':0, 'dm_concat':1, 'dm_mean': 1, 'size':100, 'window':7, 'negative':5, \n",
    "            'hs':0, 'min_count':2, 'passes':2, 'vector_size':100, 'dbow_words':1}\n",
    "     \n",
    "    params.append(base)\n",
    "    \n",
    "    for i, p in enumerate(params):\n",
    "        if not silent:\n",
    "                print(\"  Starting param run\", i, \"out of\", len(params)-1, \"...\")\n",
    "        \n",
    "        start = timer()\n",
    "        doc2vecModel = trainDoc2Vec(p)\n",
    "        end = timer()\n",
    "        if not silent:\n",
    "            print(\"    Doc2Vec training finished in\", round((end-start)/60, 2), \" mins\")\n",
    "        \n",
    "        xgModel = xg.XGBClassifier(\n",
    "            objective = \"binary:logistic\",\n",
    "            random_state = seedVal\n",
    "        )\n",
    "        \n",
    "        start = timer()\n",
    "        results = assessSingleXGB(xgModel, doc2vecModel, list(combinedDat['sentiment'][:25000]))\n",
    "        end = timer()\n",
    "        if not silent:\n",
    "            print(\"    xgModel training finished in\", round((end-start)/60, 2), \" mins with accuracy\", results)\n",
    "    \n",
    "        resultsDF.loc[len(resultsDF)] = list([\n",
    "            'Pass ' +  str(len(resultsDF)), \n",
    "            results,\n",
    "            p,\n",
    "        ])\n",
    "            \n",
    "    if not silent:\n",
    "        print(\"\\n**Finished!\")\n",
    "    \n",
    "    return resultsDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-05T16:20:51.322055Z",
     "start_time": "2018-12-05T16:20:04.766443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Starting run!\n",
      "\n",
      "  Starting param run 0 out of 0 ...\n",
      "    Doc2Vec training finished in 0.34  mins\n",
      "    xgModel training finished in 0.43  mins with accuracy 0.8192\n",
      "\n",
      "**Finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pass 0</td>\n",
       "      <td>0.8192</td>\n",
       "      <td>{'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100, 'window': 7, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100, 'dbow_words': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  Accuracy  \\\n",
       "0  Pass 0  0.8192     \n",
       "\n",
       "                                                                                                                                                        Params  \n",
       "0  {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100, 'window': 7, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100, 'dbow_words': 1}  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df = searchParams3(False)\n",
    "\n",
    "# Print results sorted by Accuracy desc\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "_df.sort_values(by = ['Accuracy'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train best Doc2Vec models\n",
    "\n",
    "We'll train and assign the best two Doc2Vec models into variables for use later on.\n",
    "\n",
    "Best params so far for dm0\n",
    "* Pass 8 0.7600 {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100, 'window': 7, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100}\n",
    "\n",
    "Best params so far for dm1:\n",
    "* Pass 26 0.7580 {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11.0, 'hs': 0, 'min_count': 3, 'passes': 2, 'vector_size': 300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T16:06:04.553750Z",
     "start_time": "2018-12-03T16:03:12.345366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "docs = taggedDocs[:25000]\n",
    "\n",
    "# Instantiate each model\n",
    "m1 = Doc2Vec(dm=0, dm_concat=1, dm_mean=1, size=100, window=7, negative=5,  hs=0, min_count=2, vector_size=100, workers=cores)\n",
    "m2 = Doc2Vec(dm=1, dm_concat=0, dm_mean=1, size=500, window=3, negative=11, hs=0, min_count=3, vector_size=300, workers=cores)\n",
    "\n",
    "# Build vocab with first model\n",
    "m1.build_vocab(docs)\n",
    "\n",
    "# Share first model's vocab scan w/ the other models\n",
    "m2.reset_from(m1)\n",
    "\n",
    "# Model training params\n",
    "alpha, min_alpha, passes = (0.025, 0.001, 20)\n",
    "\n",
    "# Train each model on the labeled training data\n",
    "m1.train(docs, total_examples = m1.corpus_count, start_alpha = alpha, end_alpha = min_alpha, epochs = passes)\n",
    "m2.train(docs, total_examples = m2.corpus_count, start_alpha = alpha, end_alpha = min_alpha, epochs = passes)\n",
    "\n",
    "# Combine the document vectors, so we can pass to XGBoost model as the feature set\n",
    "#featureSet = np.hstack(m1.docvecs.doctag_syn0, m2.docvecs.doctag_syn0)\n",
    "\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T16:06:04.895506Z",
     "start_time": "2018-12-03T16:06:04.554756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 100)\n",
      "(25000, 500)\n"
     ]
    }
   ],
   "source": [
    "print(m1.docvecs.doctag_syn0.shape)\n",
    "print(m2.docvecs.doctag_syn0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T16:06:05.308316Z",
     "start_time": "2018-12-03T16:06:04.896512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 600)\n"
     ]
    }
   ],
   "source": [
    "featureSet = np.hstack((m1.docvecs.doctag_syn0, m2.docvecs.doctag_syn0))\n",
    "print(featureSet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T18:05:03.109090Z",
     "start_time": "2018-12-03T18:05:02.731075Z"
    }
   },
   "outputs": [],
   "source": [
    "y = list(combinedDat['sentiment'][:25000])\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(\n",
    "    featureSet,  \n",
    "    y, \n",
    "    test_size = 0.1, \n",
    "    shuffle = True, \n",
    "    random_state = seedVal, \n",
    "    stratify = y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune XGBoost using best Doc2Vec models\n",
    "\n",
    "Training XGBoost isn't as straightforward as other models.  Our strategy will be as follows:\n",
    "\n",
    "1. Pick some sane model param defaults\n",
    "2. Calculate best initial n_estimators value (i.e. number of trees)\n",
    "3. Tune max_depth and min_child_weight\n",
    "4. Tune gamma, subsample and colsample_bytree\n",
    "5. Tune regularization params, reg_alpha and reg_lambda\n",
    "6. Obtain new n_estimators value\n",
    "7. Tune the learning rate and re-eval n_estimators\n",
    "\n",
    "References:\n",
    "* https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "* https://towardsdatascience.com/fine-tuning-xgboost-in-python-like-a-boss-b4543ed8b1e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T17:58:32.035638Z",
     "start_time": "2018-12-03T17:58:31.661972Z"
    }
   },
   "source": [
    "### Pick sane model param defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T18:37:07.125037Z",
     "start_time": "2018-12-03T18:35:10.886355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=10,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1 = xg.XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=5000,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=1,\n",
    "    random_state=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate best initial n_estimators value (i.e. number of trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T19:07:12.841117Z",
     "start_time": "2018-12-03T18:46:28.377502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=918,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=10,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = xgb1.get_xgb_params()\n",
    "dmatrix = xg.DMatrix(X_train, label=y_train)\n",
    "\n",
    "cv = xg.cv(\n",
    "    params, \n",
    "    dmatrix, \n",
    "    num_boost_round = xgb1.get_params()['n_estimators'], \n",
    "    nfold = 5,\n",
    "    metrics = 'auc',\n",
    "    early_stopping_rounds=25\n",
    ")\n",
    "\n",
    "# Assign best n_estimators value to our model\n",
    "xgb1.set_params(n_estimators = cv.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T19:18:43.993146Z",
     "start_time": "2018-12-03T19:18:02.791878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on eval data:  0.8648\n"
     ]
    }
   ],
   "source": [
    "xgb1.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    eval_set = [(X_train, y_train), (X_eval, y_eval)],\n",
    "    eval_metric = \"auc\",\n",
    "    verbose = False,\n",
    "    early_stopping_rounds = 5,\n",
    ")\n",
    "    \n",
    "preds = xgb1.predict(X_eval)\n",
    "print(\"Accuracy on eval data: \", accuracy_score(y_eval, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T19:46:30.147642Z",
     "start_time": "2018-12-03T19:46:29.842817Z"
    }
   },
   "outputs": [],
   "source": [
    "def getXGBModel():\n",
    "    model = xg.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=5, min_child_weight=1, missing=None, n_estimators=918,\n",
    "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=10,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=0.8)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T19:24:59.411798Z",
     "start_time": "2018-12-04T19:24:59.060867Z"
    }
   },
   "outputs": [],
   "source": [
    "def evalXGB(model, silent = True, early_stopping_rounds = 25):\n",
    "    start = timer()\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        eval_set = [(X_train, y_train), (X_eval, y_eval)],\n",
    "        eval_metric = \"auc\",\n",
    "        verbose = False,\n",
    "        early_stopping_rounds = early_stopping_rounds,\n",
    "    )\n",
    "    \n",
    "    preds = model.predict(X_eval)\n",
    "    acc = accuracy_score(y_eval, preds)\n",
    "    \n",
    "    end = timer()\n",
    "    \n",
    "    if not silent:\n",
    "        print(\"    Model training finished in\", round((end-start)/60, 2), \"mins with accuracy\", acc)\n",
    "            \n",
    "    return(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T21:02:50.416622Z",
     "start_time": "2018-12-03T19:55:32.498097Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training round 1\n",
      "    Model training finished in 1.99  mins with accuracy 0.8836\n",
      "Training round 2\n",
      "    Model training finished in 2.75  mins with accuracy 0.8872\n",
      "Training round 3\n",
      "    Model training finished in 2.83  mins with accuracy 0.89\n",
      "Training round 4\n",
      "    Model training finished in 2.93  mins with accuracy 0.89\n",
      "Training round 5\n",
      "    Model training finished in 1.96  mins with accuracy 0.888\n",
      "Training round 6\n",
      "    Model training finished in 2.05  mins with accuracy 0.8868\n",
      "Training round 7\n",
      "    Model training finished in 1.9  mins with accuracy 0.8864\n",
      "Training round 8\n",
      "    Model training finished in 2.26  mins with accuracy 0.8852\n",
      "Training round 9\n",
      "    Model training finished in 2.38  mins with accuracy 0.878\n",
      "Training round 10\n",
      "    Model training finished in 4.76  mins with accuracy 0.8848\n",
      "Training round 11\n",
      "    Model training finished in 3.99  mins with accuracy 0.8928\n",
      "Training round 12\n",
      "    Model training finished in 3.04  mins with accuracy 0.888\n",
      "Training round 13\n",
      "    Model training finished in 2.01  mins with accuracy 0.8804\n",
      "Training round 14\n",
      "    Model training finished in 4.77  mins with accuracy 0.8824\n",
      "Training round 15\n",
      "    Model training finished in 4.21  mins with accuracy 0.8844\n",
      "Training round 16\n",
      "    Model training finished in 3.62  mins with accuracy 0.89\n",
      "Training round 17\n",
      "    Model training finished in 7.07  mins with accuracy 0.8876\n",
      "Training round 18\n",
      "    Model training finished in 4.56  mins with accuracy 0.8788\n",
      "Training round 19\n",
      "    Model training finished in 3.42  mins with accuracy 0.8816\n",
      "Training round 20\n",
      "    Model training finished in 4.78  mins with accuracy 0.8888\n",
      "\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "resultsDF = pd.DataFrame(columns = ['Accuracy', 'Params'])\n",
    "counter = 1\n",
    "\n",
    "for max_depth in np.linspace(2, 10, 5):\n",
    "    for min_child_weight in np.linspace(2, 8, 4):\n",
    "        print(\"Training round\", counter)\n",
    "        xgb1 = getXGBModel()\n",
    "        xgb1.set_params(max_depth = int(max_depth), min_child_weight = int(min_child_weight))\n",
    "        acc = evalXGB(xgb1, False)\n",
    "            \n",
    "        resultsDF.loc[len(resultsDF)] = list([\n",
    "            acc,\n",
    "            xgb1.get_params()\n",
    "        ])\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "print(\"\\nFinished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T21:02:50.756539Z",
     "start_time": "2018-12-03T21:02:50.420632Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.8928</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 6, 'min_child_weight': 6, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.8900</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 8, 'min_child_weight': 8, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8900</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 2, 'min_child_weight': 6, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8900</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 2, 'min_child_weight': 8, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.8888</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.8880</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 6, 'min_child_weight': 8, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8880</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 2, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.8876</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 2, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8872</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 2, 'min_child_weight': 4, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8868</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 4, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8864</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 6, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8852</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 8, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8848</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 6, 'min_child_weight': 4, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.8844</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 8, 'min_child_weight': 6, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8836</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 2, 'min_child_weight': 2, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.8824</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 8, 'min_child_weight': 4, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.8816</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 6, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.8804</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 8, 'min_child_weight': 2, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.8788</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 4, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8780</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 6, 'min_child_weight': 2, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  \\\n",
       "10  0.8928     \n",
       "15  0.8900     \n",
       "2   0.8900     \n",
       "3   0.8900     \n",
       "19  0.8888     \n",
       "11  0.8880     \n",
       "4   0.8880     \n",
       "16  0.8876     \n",
       "1   0.8872     \n",
       "5   0.8868     \n",
       "6   0.8864     \n",
       "7   0.8852     \n",
       "9   0.8848     \n",
       "14  0.8844     \n",
       "0   0.8836     \n",
       "13  0.8824     \n",
       "18  0.8816     \n",
       "12  0.8804     \n",
       "17  0.8788     \n",
       "8   0.8780     \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                   Params  \n",
       "10  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 6, 'min_child_weight': 6, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}   \n",
       "15  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 8, 'min_child_weight': 8, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}   \n",
       "2   {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 2, 'min_child_weight': 6, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}   \n",
       "3   {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 2, 'min_child_weight': 8, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}   \n",
       "19  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 8, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}  \n",
       "11  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 6, 'min_child_weight': 8, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}   \n",
       "4   {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 2, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}   \n",
       "16  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 2, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}  \n",
       "1   {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 2, 'min_child_weight': 4, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}   \n",
       "5   {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 4, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}   \n",
       "6   {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 6, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}   \n",
       "7   {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 4, 'min_child_weight': 8, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}   \n",
       "9   {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 6, 'min_child_weight': 4, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}   \n",
       "14  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 8, 'min_child_weight': 6, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}   \n",
       "0   {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 2, 'min_child_weight': 2, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}   \n",
       "13  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 8, 'min_child_weight': 4, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}   \n",
       "18  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 6, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}  \n",
       "12  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 8, 'min_child_weight': 2, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}   \n",
       "17  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 10, 'min_child_weight': 4, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}  \n",
       "8   {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 6, 'min_child_weight': 2, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}   "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "resultsDF.sort_values(by = ['Accuracy'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine tune \n",
    "\n",
    "Best params for `max_depth` and `min_child_weight` were both 6 with a 0.8928 accuracy rate against the evaluation data set.  Next we'll fine tune around the best params, since our initial grid was wide (increased in steps of 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T21:53:54.984899Z",
     "start_time": "2018-12-03T21:39:07.307850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training round 1\n",
      "    Model training finished in 2.61  mins with accuracy 0.8848\n",
      "Training round 2\n",
      "    Model training finished in 2.53  mins with accuracy 0.8832\n",
      "Training round 3\n",
      "    Model training finished in 5.63  mins with accuracy 0.8948\n",
      "Training round 4\n",
      "    Model training finished in 4.01  mins with accuracy 0.8948\n",
      "\n",
      "Finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8948</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 5, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8948</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8848</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 5, 'min_child_weight': 5, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8832</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 5, 'min_child_weight': 7, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  \\\n",
       "2  0.8948     \n",
       "3  0.8948     \n",
       "0  0.8848     \n",
       "1  0.8832     \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                 Params  \n",
       "2  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 5, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}  \n",
       "3  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}  \n",
       "0  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 5, 'min_child_weight': 5, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}  \n",
       "1  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 5, 'min_child_weight': 7, 'missing': None, 'n_estimators': 918, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsDF = pd.DataFrame(columns = ['Accuracy', 'Params'])\n",
    "counter = 1\n",
    "\n",
    "for max_depth in [5, 7]:\n",
    "    for min_child_weight in [5, 7]:\n",
    "        print(\"Training round\", counter)\n",
    "        xgb1 = getXGBModel()\n",
    "        xgb1.set_params(max_depth = int(max_depth), min_child_weight = int(min_child_weight))\n",
    "        acc = evalXGB(xgb1, False)\n",
    "            \n",
    "        resultsDF.loc[len(resultsDF)] = list([\n",
    "            acc,\n",
    "            xgb1.get_params()\n",
    "        ])\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "print(\"\\nFinished!\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "resultsDF.sort_values(by = ['Accuracy'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a small increase from 0.8928 to 0.8948 using `max_depth: 7` and `min_child_weight: 7`.  We'll adopt these as the new, optimal parameters.  \n",
    "\n",
    "Note that another model with `min_child_weight: 5` also had an accuracy of 0.8948, but we'll pick the larger value as it has a greater impact against over fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune gamma, subsample and colsample_bytree\n",
    "\n",
    "We'll start by creating a new function that returns a fresh copy of the XGBoost model w/ the most effective parameters we've found so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T22:02:30.382494Z",
     "start_time": "2018-12-03T22:02:30.058631Z"
    }
   },
   "outputs": [],
   "source": [
    "def getXGBModelv2():\n",
    "    model = xg.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=7, min_child_weight=7, missing=None, n_estimators=918,\n",
    "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=10,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=0.8)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma tuning\n",
    "\n",
    "From my research there wasn't a clear consensus on a good, initial value for gamma tuning.  As such we'll start with a wide range and then zero in on the best value for our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training results--not shown here--for the following gamma values had no effect on the model's performance:\n",
    "\n",
    "* [.1, .5, 1, 5]\n",
    "* [10, 15, 20]\n",
    "* [.01, .001, .0001]\n",
    "\n",
    "As such the gamma value of zero will be retained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T21:35:06.309933Z",
     "start_time": "2018-12-03T21:35:05.989563Z"
    }
   },
   "source": [
    "### Calculate optimal n_estimators value\n",
    "\n",
    "Let's go ahead and update--if required--the optimal n_estimators value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:13:22.707465Z",
     "start_time": "2018-12-03T22:53:03.186600Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb1 = getXGBModelv2()\n",
    "xgb1.set_params(gamma = 0, n_estimators=5000)\n",
    "\n",
    "params = xgb1.get_xgb_params()\n",
    "dmatrix = xg.DMatrix(X_train, label=y_train)\n",
    "\n",
    "cv = xg.cv(\n",
    "    params, \n",
    "    dmatrix, \n",
    "    num_boost_round = xgb1.get_params()['n_estimators'], \n",
    "    nfold = 5,\n",
    "    metrics = 'auc',\n",
    "    early_stopping_rounds=25\n",
    ")\n",
    "\n",
    "# Assign best n_estimators value to our model\n",
    "xgb1.set_params(n_estimators = cv.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  subsample and colsample_bytree tuning\n",
    "\n",
    "* subsample [default=1]\n",
    "  * Same as the subsample of GBM. Denotes the fraction of observations to be randomly samples for each tree.\n",
    "  * Lower values make the algorithm more conservative and prevents overfitting but too small values might lead to under-fitting.\n",
    "  * Typical values: 0.5-1\n",
    "\n",
    "\n",
    "* colsample_bytree [default=1]\n",
    "  * Similar to max_features in GBM. Denotes the fraction of columns to be randomly samples for each tree.\n",
    "  * Typical values: 0.5-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-03T23:21:40.040694Z",
     "start_time": "2018-12-03T23:21:39.625585Z"
    }
   },
   "outputs": [],
   "source": [
    "def getXGBModelv3():\n",
    "    model = xg.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=7, min_child_weight=7, missing=None, n_estimators=800,\n",
    "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=10,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=0.8)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T00:35:08.924391Z",
     "start_time": "2018-12-03T23:23:09.598309Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training round 1\n",
      "    Model training finished in 1.67 mins with accuracy 0.8852\n",
      "Training round 2\n",
      "    Model training finished in 1.12 mins with accuracy 0.8812\n",
      "Training round 3\n",
      "    Model training finished in 2.39 mins with accuracy 0.8808\n",
      "Training round 4\n",
      "    Model training finished in 2.19 mins with accuracy 0.8852\n",
      "Training round 5\n",
      "    Model training finished in 2.64 mins with accuracy 0.8848\n",
      "Training round 6\n",
      "    Model training finished in 1.34 mins with accuracy 0.8812\n",
      "Training round 7\n",
      "    Model training finished in 1.21 mins with accuracy 0.8776\n",
      "Training round 8\n",
      "    Model training finished in 2.7 mins with accuracy 0.8836\n",
      "Training round 9\n",
      "    Model training finished in 4.63 mins with accuracy 0.884\n",
      "Training round 10\n",
      "    Model training finished in 2.43 mins with accuracy 0.884\n",
      "Training round 11\n",
      "    Model training finished in 2.91 mins with accuracy 0.8896\n",
      "Training round 12\n",
      "    Model training finished in 1.56 mins with accuracy 0.882\n",
      "Training round 13\n",
      "    Model training finished in 2.95 mins with accuracy 0.89\n",
      "Training round 14\n",
      "    Model training finished in 3.22 mins with accuracy 0.8872\n",
      "Training round 15\n",
      "    Model training finished in 4.3 mins with accuracy 0.8876\n",
      "Training round 16\n",
      "    Model training finished in 3.44 mins with accuracy 0.8852\n",
      "Training round 17\n",
      "    Model training finished in 3.58 mins with accuracy 0.886\n",
      "Training round 18\n",
      "    Model training finished in 2.96 mins with accuracy 0.8896\n",
      "Training round 19\n",
      "    Model training finished in 3.97 mins with accuracy 0.8948\n",
      "Training round 20\n",
      "    Model training finished in 6.09 mins with accuracy 0.888\n",
      "Training round 21\n",
      "    Model training finished in 1.92 mins with accuracy 0.8876\n",
      "Training round 22\n",
      "    Model training finished in 2.19 mins with accuracy 0.8844\n",
      "Training round 23\n",
      "    Model training finished in 3.06 mins with accuracy 0.8864\n",
      "Training round 24\n",
      "    Model training finished in 2.52 mins with accuracy 0.8848\n",
      "Training round 25\n",
      "    Model training finished in 4.98 mins with accuracy 0.884\n",
      "\n",
      "Finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.8948</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.8900</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.7, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.8896</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.7, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.8896</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.8880</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.9, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  \\\n",
       "18  0.8948     \n",
       "12  0.8900     \n",
       "17  0.8896     \n",
       "10  0.8896     \n",
       "19  0.8880     \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                  Params  \n",
       "18  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}  \n",
       "12  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.7, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.7}  \n",
       "17  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.7, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}  \n",
       "10  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.5, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.7}  \n",
       "19  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.9, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsDF = pd.DataFrame(columns = ['Accuracy', 'Params'])\n",
    "counter = 1\n",
    "\n",
    "for subsample in np.linspace(0.5, 0.9, 5):\n",
    "    for colsample_bytree in np.linspace(0.5, 0.9, 5):\n",
    "        print(\"Training round\", counter)\n",
    "        xgb1 = getXGBModelv3()\n",
    "        xgb1.set_params(subsample = subsample, colsample_bytree = colsample_bytree)\n",
    "        acc = evalXGB(xgb1, False)\n",
    "            \n",
    "        resultsDF.loc[len(resultsDF)] = list([\n",
    "            acc,\n",
    "            xgb1.get_params()\n",
    "        ])\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "print(\"\\nFinished!\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "resultsDF.sort_values(by = ['Accuracy'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T15:47:04.525008Z",
     "start_time": "2018-12-04T15:40:31.464618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training round 1\n",
      "    Model training finished in 6.52 mins with accuracy 0.8888\n",
      "\n",
      "Finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8888</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  \\\n",
       "0  0.8888     \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                             Params  \n",
       "0  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 1}  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsDF = pd.DataFrame(columns = ['Accuracy', 'Params'])\n",
    "counter = 1\n",
    "\n",
    "for subsample in [1]:\n",
    "    for colsample_bytree in [1]:\n",
    "        if (subsample == .8) and (colsample_bytree == .8):\n",
    "            continue\n",
    "        print(\"Training round\", counter)\n",
    "        xgb1 = getXGBModelv3()\n",
    "        xgb1.set_params(subsample = subsample, colsample_bytree = colsample_bytree)\n",
    "        acc = evalXGB(xgb1, False)\n",
    "            \n",
    "        resultsDF.loc[len(resultsDF)] = list([\n",
    "            acc,\n",
    "            xgb1.get_params()\n",
    "        ])\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "print(\"\\nFinished!\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "resultsDF.sort_values(by = ['Accuracy'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No improvements, so keep initial values of  subsample and colsample_bytree equal to 0.8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune regularization params, reg_alpha and reg_lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* reg_lambda [default=1]\n",
    "  * L2 regularization term on weights (analogous to Ridge regression)\n",
    "  * This used to handle the regularization part of XGBoost. Though many data scientists dont use it often, it should be explored to reduce overfitting.\n",
    "\n",
    "\n",
    "* reg_alpha [default=0]\n",
    "  * L1 regularization term on weight (analogous to Lasso regression)\n",
    "  * Can be used in case of very high dimensionality so that the algorithm runs faster when implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T15:58:26.057038Z",
     "start_time": "2018-12-04T15:58:25.762246Z"
    }
   },
   "outputs": [],
   "source": [
    "def getXGBModelv4():\n",
    "    model = xg.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=7, min_child_weight=7, missing=None, n_estimators=800,\n",
    "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=10,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=0.8)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T18:59:59.750128Z",
     "start_time": "2018-12-04T17:26:40.419731Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training round 1\n",
      "    Model training finished in 3.1 mins with accuracy 0.882\n",
      "Training round 2\n",
      "    Model training finished in 6.2 mins with accuracy 0.8924\n",
      "Training round 3\n",
      "    Model training finished in 4.4 mins with accuracy 0.89\n",
      "Training round 4\n",
      "    Model training finished in 3.05 mins with accuracy 0.8836\n",
      "Training round 5\n",
      "    Model training finished in 3.5 mins with accuracy 0.8816\n",
      "Training round 6\n",
      "    Model training finished in 4.11 mins with accuracy 0.8896\n",
      "Training round 7\n",
      "    Model training finished in 3.65 mins with accuracy 0.8884\n",
      "Training round 8\n",
      "    Model training finished in 3.38 mins with accuracy 0.8876\n",
      "Training round 9\n",
      "    Model training finished in 3.85 mins with accuracy 0.8836\n",
      "Training round 10\n",
      "    Model training finished in 3.37 mins with accuracy 0.8876\n",
      "Training round 11\n",
      "    Model training finished in 4.28 mins with accuracy 0.8948\n",
      "Training round 12\n",
      "    Model training finished in 4.22 mins with accuracy 0.8916\n",
      "Training round 13\n",
      "    Model training finished in 4.14 mins with accuracy 0.89\n",
      "Training round 14\n",
      "    Model training finished in 4.91 mins with accuracy 0.8832\n",
      "Training round 15\n",
      "    Model training finished in 3.51 mins with accuracy 0.888\n",
      "Training round 16\n",
      "    Model training finished in 3.26 mins with accuracy 0.8856\n",
      "Training round 17\n",
      "    Model training finished in 2.59 mins with accuracy 0.8812\n",
      "Training round 18\n",
      "    Model training finished in 2.85 mins with accuracy 0.8864\n",
      "Training round 19\n",
      "    Model training finished in 4.62 mins with accuracy 0.888\n",
      "Training round 20\n",
      "    Model training finished in 3.21 mins with accuracy 0.8856\n",
      "Training round 21\n",
      "    Model training finished in 2.28 mins with accuracy 0.8828\n",
      "Training round 22\n",
      "    Model training finished in 3.68 mins with accuracy 0.882\n",
      "Training round 23\n",
      "    Model training finished in 2.85 mins with accuracy 0.8816\n",
      "Training round 24\n",
      "    Model training finished in 3.9 mins with accuracy 0.8912\n",
      "Training round 25\n",
      "    Model training finished in 4.36 mins with accuracy 0.8892\n",
      "\n",
      "Finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.8948</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8924</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0.0001, 'reg_lambda': 0.1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.8916</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0.0001, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.8912</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0.1, 'reg_lambda': 2, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.8900</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0.001, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy  \\\n",
       "10  0.8948     \n",
       "1   0.8924     \n",
       "11  0.8916     \n",
       "23  0.8912     \n",
       "12  0.8900     \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                         Params  \n",
       "10  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}         \n",
       "1   {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0.0001, 'reg_lambda': 0.1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}  \n",
       "11  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0.0001, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}    \n",
       "23  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0.1, 'reg_lambda': 2, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}       \n",
       "12  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0.001, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}     "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsDF = pd.DataFrame(columns = ['Accuracy', 'Params'])\n",
    "counter = 1\n",
    "\n",
    "for reg_lambda in [0.1, 0.5, 1, 1.5, 2]:\n",
    "    for reg_alpha in [0, 0.0001, 0.001, 0.1, 1]:\n",
    "        print(\"Training round\", counter)\n",
    "        xgb1 = getXGBModelv4()\n",
    "        xgb1.set_params(reg_lambda = reg_lambda, reg_alpha = reg_alpha)\n",
    "        acc = evalXGB(xgb1, False)\n",
    "            \n",
    "        resultsDF.loc[len(resultsDF)] = list([\n",
    "            acc,\n",
    "            xgb1.get_params()\n",
    "        ])\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "print(\"\\nFinished!\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "resultsDF.sort_values(by = ['Accuracy'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again no improvement, so we'll keep the existing regularization parameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain new n_estimators value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T19:22:21.211996Z",
     "start_time": "2018-12-04T19:02:02.135925Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=7, min_child_weight=7, missing=None, n_estimators=800,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=10,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1 = getXGBModelv4()\n",
    "xgb1.set_params(n_estimators=5000)\n",
    "\n",
    "params = xgb1.get_xgb_params()\n",
    "dmatrix = xg.DMatrix(X_train, label=y_train)\n",
    "\n",
    "cv = xg.cv(\n",
    "    params, \n",
    "    dmatrix, \n",
    "    num_boost_round = xgb1.get_params()['n_estimators'], \n",
    "    nfold = 5,\n",
    "    metrics = 'auc',\n",
    "    early_stopping_rounds=25\n",
    ")\n",
    "\n",
    "# Assign best n_estimators value to our model\n",
    "xgb1.set_params(n_estimators = cv.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators=800 remains 800, which makes sense as we didn't alter any parameters after grid searching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune the learning rate and re-eval n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T19:22:58.886383Z",
     "start_time": "2018-12-04T19:22:58.517404Z"
    }
   },
   "outputs": [],
   "source": [
    "def getXGBModelv5():\n",
    "    model = xg.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=7, min_child_weight=7, missing=None, n_estimators=800,\n",
    "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=10,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=0.8)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T19:35:31.752324Z",
     "start_time": "2018-12-04T19:25:17.542180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training round 1\n",
      "    Model training finished in 6.67 mins with accuracy 0.8176\n",
      "Training round 2\n",
      "    Model training finished in 2.08 mins with accuracy 0.8712\n",
      "Training round 3\n",
      "    Model training finished in 1.32 mins with accuracy 0.82\n",
      "Training round 4\n",
      "    Model training finished in 0.16 mins with accuracy 0.7228\n",
      "\n",
      "Finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8712</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.5, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8200</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 1.5, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8176</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.001, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7228</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 3, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  \\\n",
       "1  0.8712     \n",
       "2  0.8200     \n",
       "0  0.8176     \n",
       "3  0.7228     \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                   Params  \n",
       "1  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.5, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}    \n",
       "2  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 1.5, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}    \n",
       "0  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.001, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}  \n",
       "3  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 3, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}      "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsDF = pd.DataFrame(columns = ['Accuracy', 'Params'])\n",
    "counter = 1\n",
    "\n",
    "for learning_rate in [0.001, .5, 1.5, 3]:\n",
    "    print(\"Training round\", counter)\n",
    "    xgb1 = getXGBModelv5()\n",
    "    xgb1.set_params(learning_rate = learning_rate)\n",
    "    acc = evalXGB(xgb1, False, 50)\n",
    "\n",
    "    resultsDF.loc[len(resultsDF)] = list([\n",
    "        acc,\n",
    "        xgb1.get_params()\n",
    "    ])\n",
    "\n",
    "    counter += 1\n",
    "        \n",
    "print(\"\\nFinished!\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "resultsDF.sort_values(by = ['Accuracy'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T20:08:03.194218Z",
     "start_time": "2018-12-04T19:48:50.229908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training round 1\n",
      "    Model training finished in 5.85 mins with accuracy 0.8928\n",
      "Training round 2\n",
      "    Model training finished in 2.64 mins with accuracy 0.8808\n",
      "Training round 3\n",
      "    Model training finished in 2.97 mins with accuracy 0.8804\n",
      "Training round 4\n",
      "    Model training finished in 2.84 mins with accuracy 0.8816\n",
      "Training round 5\n",
      "    Model training finished in 2.54 mins with accuracy 0.8716\n",
      "Training round 6\n",
      "    Model training finished in 2.36 mins with accuracy 0.8604\n",
      "\n",
      "Finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8928</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.08, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.8816</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.3, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8808</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.09, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8804</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.2, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8716</td>\n",
       "      <td>{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.7, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  \\\n",
       "0  0.8928     \n",
       "3  0.8816     \n",
       "1  0.8808     \n",
       "2  0.8804     \n",
       "4  0.8716     \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                  Params  \n",
       "0  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.08, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}  \n",
       "3  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.3, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}   \n",
       "1  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.09, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}  \n",
       "2  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.2, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}   \n",
       "4  {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.7, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}   "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsDF = pd.DataFrame(columns = ['Accuracy', 'Params'])\n",
    "counter = 1\n",
    "\n",
    "for learning_rate in [.08, .09, .2, .3, .7, .8]:\n",
    "    print(\"Training round\", counter)\n",
    "    xgb1 = getXGBModelv5()\n",
    "    xgb1.set_params(learning_rate = learning_rate)\n",
    "    acc = evalXGB(xgb1, False, 50)\n",
    "\n",
    "    resultsDF.loc[len(resultsDF)] = list([\n",
    "        acc,\n",
    "        xgb1.get_params()\n",
    "    ])\n",
    "\n",
    "    counter += 1\n",
    "        \n",
    "print(\"\\nFinished!\")\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "resultsDF.sort_values(by = ['Accuracy'], ascending = [False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation on the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train best Doc2Vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T23:44:47.570186Z",
     "start_time": "2018-12-04T23:33:11.401634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n",
      "(100000, 100)\n",
      "(100000, 500)\n",
      "(25000, 600)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate each model\n",
    "m1 = Doc2Vec(dm=0, dm_concat=1, dm_mean=1, size=100, window=7, negative=5,  hs=0, min_count=2, vector_size=100, workers=cores)\n",
    "m2 = Doc2Vec(dm=1, dm_concat=0, dm_mean=1, size=500, window=3, negative=11, hs=0, min_count=3, vector_size=300, workers=cores)\n",
    "\n",
    "# Build vocab with first model\n",
    "m1.build_vocab(taggedDocs)\n",
    "\n",
    "# Share first model's vocab scan w/ the other models\n",
    "m2.reset_from(m1)\n",
    "\n",
    "# Model training params\n",
    "alpha, min_alpha, passes = (0.025, 0.001, 20)\n",
    "\n",
    "# Train each model on the labeled training data\n",
    "m1.train(taggedDocs, total_examples = m1.corpus_count, start_alpha = alpha, end_alpha = min_alpha, epochs = passes)\n",
    "m2.train(taggedDocs, total_examples = m2.corpus_count, start_alpha = alpha, end_alpha = min_alpha, epochs = passes)\n",
    "\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(m1.docvecs.doctag_syn0.shape)\n",
    "print(m2.docvecs.doctag_syn0.shape)\n",
    "\n",
    "featureSet = np.hstack((m1.docvecs.doctag_syn0[:25000], m2.docvecs.doctag_syn0[:25000]))\n",
    "print(featureSet.shape)\n",
    "\n",
    "y = list(combinedDat['sentiment'][:25000])\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(\n",
    "    featureSet,  \n",
    "    y, \n",
    "    test_size = 0.1, \n",
    "    shuffle = True, \n",
    "    random_state = seedVal, \n",
    "    stratify = y \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train best XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T23:47:12.116627Z",
     "start_time": "2018-12-04T23:44:47.571189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=7, min_child_weight=7, missing=None, n_estimators=800,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=10,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1 = getXGBModelv5()\n",
    "\n",
    "xgb1.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    eval_set = [(X_train, y_train), (X_eval, y_eval)],\n",
    "    eval_metric = \"auc\",\n",
    "    verbose = False,\n",
    "    early_stopping_rounds = 25,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-04T23:47:12.480596Z",
     "start_time": "2018-12-04T23:47:12.117630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on eval data:  0.8824\n"
     ]
    }
   ],
   "source": [
    "preds = xgb1.predict(X_eval)\n",
    "print(\"Accuracy on eval data: \", accuracy_score(y_eval, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we see that utilizing the whole set of reviews seems to actually drop performance.  Thus our best model to date is an ensemble from the PV-DBOW and PV-DM Dov2Vec models fed into a XGBoost implementation with an evaluation data set accuracy of 0.8948.  The hyper parameters for the entities are as follows:\n",
    "\n",
    "* Distributed bag of words (PV-DBOW) (i.e. dm-0)\n",
    "  * {'dm': 0, 'dm_concat': 1, 'dm_mean': 1, 'size': 100, 'window': 7, 'negative': 5, 'hs': 0, 'min_count': 2, 'passes': 2, 'vector_size': 100}\n",
    "\n",
    "\n",
    "* Distributed memory (PV-DM) (i.e. dm=1)\n",
    "  * {'dm': 1, 'dm_concat': 0, 'dm_mean': 1, 'size': 500, 'window': 3, 'negative': 11.0, 'hs': 0, 'min_count': 3, 'passes': 2, 'vector_size': 300}\n",
    "\n",
    "\n",
    "* XGBoost\n",
    "  * {'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 7, 'min_child_weight': 7, 'missing': None, 'n_estimators': 800, 'n_jobs': 1, 'nthread': 4, 'objective': 'binary:logistic', 'random_state': 10, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation on the entire dataset with stemming and contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T18:51:23.751678Z",
     "start_time": "2018-11-08T18:51:23.283886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this write-up we accomplished the following:\n",
    "\n",
    "1. Created a set of document vectors from the IMDb movie review text utilizing [Doc2Vec](https://radimrehurek.com/gensim/models/doc2vec.html)\n",
    "2. Tuned and trained a number of Doc2Vec models on the movie review corpus \n",
    "2. Ran the models from the [first write-up](./Model-06.ipynb) against the Doc2Vec feature set outputs\n",
    "3. Evaluated if utilizing Doc2Vec improved our ability to correctly classify movie review sentiment\n",
    "\n",
    "\n",
    "Performance metrics so far:\n",
    "\n",
    "|Model|Accuracy|Best Params                                      |\n",
    "|--------------------------|--------|-----------------------------------|\n",
    "|LR (baseline)             |86.35%  |{'LR__C': 0.1, 'LR__penalty': 'l1'}|\n",
    "|SVM centroid              |86.36%  |Scikit-learn defaults              |\n",
    "|SVM Doc2Vec               |84.48%  |Scikit-learn defaults              |\n",
    "|SVM Doc2Vec Init tuning   |88.45%  |dm0, vs100, ng5, hs0, mc2, sm0, e20|\n",
    "|LR manual/combined        |89.51%  |model1, model2, model3             |\n",
    "<div style=\"clear:both\"></div>\n",
    "\n",
    "\n",
    "Utilizing Doc2Vec with manual training and combining model outputs has given us the best classification results to date.  We were able to gain over 3 percentage points in performance from the LR baseline model.\n",
    "\n",
    "If we were to continue this write-up it would be interesting to explore adding many models together and seeing how that affected the output  similar to bagging.  We could also likely spend a lot of time with further tuning, because both the Doc2Vec and Scikit-learn models have a large number of tunable parameters we could leverage.  The best strategy would likely be to start with a randomized grid search due to the large number of parameters, and then focus in on a more narrow set once the more performant combinations started to emerge.\n",
    "\n",
    "And lastly, I'd also like to try taking the combined model feature set and feeding it to a neural network or LSTM for final classification.  It would be interesting to see how one of these more complex algorithms compared against the Scikit-learn linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
