{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Iris-Classification-with-Keras\" data-toc-modified-id=\"Iris-Classification-with-Keras-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Iris Classification with Keras</a></span></li><li><span><a href=\"#Load-libraries-and-data\" data-toc-modified-id=\"Load-libraries-and-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load libraries and data</a></span></li><li><span><a href=\"#Helper-functions\" data-toc-modified-id=\"Helper-functions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Helper functions</a></span></li><li><span><a href=\"#Inspect-and-visualize-the-data\" data-toc-modified-id=\"Inspect-and-visualize-the-data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Inspect and visualize the data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Descriptive-statistics\" data-toc-modified-id=\"Descriptive-statistics-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Descriptive statistics</a></span></li><li><span><a href=\"#Visualizations\" data-toc-modified-id=\"Visualizations-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Visualizations</a></span></li></ul></li><li><span><a href=\"#Model-the-data\" data-toc-modified-id=\"Model-the-data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Model the data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-validation-data-set\" data-toc-modified-id=\"Create-validation-data-set-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Create validation data set</a></span></li><li><span><a href=\"#Build-the-model\" data-toc-modified-id=\"Build-the-model-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Build the model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Initial-pass\" data-toc-modified-id=\"Initial-pass-5.2.1\"><span class=\"toc-item-num\">5.2.1&nbsp;&nbsp;</span>Initial pass</a></span></li><li><span><a href=\"#Hyperparameter-tuning\" data-toc-modified-id=\"Hyperparameter-tuning-5.2.2\"><span class=\"toc-item-num\">5.2.2&nbsp;&nbsp;</span>Hyperparameter tuning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Predictions\" data-toc-modified-id=\"Predictions-5.2.2.1\"><span class=\"toc-item-num\">5.2.2.1&nbsp;&nbsp;</span>Predictions</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Iris Classification with Keras</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left; margin-right: 15px;\" src=\"images/iris.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "The purpose of this write-up is to build upon the [first](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/04-Classic-Datasets/Model-01.ipynb) write-up involving the Iris dataset.  \n",
    "\n",
    "Goals include:\n",
    "* Build a predictive regression model via neural networks\n",
    "* Perform hyperparameter tuning on the neural network\n",
    "* Make predictions with the training model and examine accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset source:  [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pandas import read_csv\n",
    "from pandas.plotting import scatter_matrix\n",
    "from pandas import set_option\n",
    "from pandas import DataFrame\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFile = os.path.join(\".\", \"datasets\", \"iris.data.csv\")\n",
    "data = read_csv(dataFile, header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeRange(start, stop, step, multi, dec):\n",
    "    vals = []\n",
    "    for i in range(start, stop, step):\n",
    "        vals.append(np.round(multi * i, decimals = dec))\n",
    "        \n",
    "    return vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect and visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please the [first Iris data's write-up](https://nbviewer.jupyter.org/github/nrasch/Portfolio/blob/master/Machine-Learning/Python/04-Classic-Datasets/Model-01.ipynb#Inspect-and-visualize-the-data) details on this topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape =  (150, 4)\n",
      "y.shape =  (150,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0\n",
       "Iris-setosa        50\n",
       "Iris-versicolor    50\n",
       "Iris-virginica     50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperate X and Y values\n",
    "x = data.values[:, 0:4]\n",
    "y = data.values[:, 4]\n",
    "\n",
    "print(\"x.shape = \", x.shape)\n",
    "print(\"y.shape = \", y.shape)\n",
    "\n",
    "DataFrame(y).groupby([0]).size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the Y values to one hot encodings for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_tmp = LabelEncoder().fit(y).transform(y)\n",
    "yHot = np_utils.to_categorical(_tmp)\n",
    "yHot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the validation set utilizing the one hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "xTrain.shape =  (120, 4)\n",
      "yTrain.shape =  (120, 3)\n",
      "xVal.shape =  (30, 4)\n",
      "yVal.shape =  (30, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split out validation set -- 80/20 split\n",
    "seed = 10\n",
    "valSize = 0.2\n",
    "\n",
    "xTrain, xVal, yTrain, yVal = train_test_split(x, yHot, test_size = valSize, random_state = seed)\n",
    "\n",
    "print(\"--------\")\n",
    "print(\"xTrain.shape = \", xTrain.shape)\n",
    "print(\"yTrain.shape = \", yTrain.shape)\n",
    "print(\"xVal.shape = \", xVal.shape)\n",
    "print(\"yVal.shape = \", yVal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use Keras with Scikit-Learn we'll utilize these handy [wrappers](https://keras.io/scikit-learn-api/).  So first thing we need to do is write a function to build our model that we can pass to the `build_fn` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do:  Edit function to accept params and dynamicly set everything up...\n",
    "def buildModel():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim = 4, activation = 'relu'))\n",
    "    model.add(Dense(3, activation = 'softmax'))\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write the rest of the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.50% (5.34%)\n"
     ]
    }
   ],
   "source": [
    "# Define vars and init\n",
    "folds = 10\n",
    "seed = 10\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "model = KerasClassifier(build_fn = buildModel, epochs = 200, batch_size = 5, verbose = 0)\n",
    "kFold = KFold(n_splits = folds, random_state = seed)\n",
    "results = cross_val_score(model, xTrain, yTrain, cv = kFold)\n",
    "\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next well see how the model performs on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model error: 3.33%\n",
      "Accuracy score: 96.67% \n",
      "\n",
      "Confusion Matrix\n",
      " [[10  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0  7]] \n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        10\n",
      "          1       1.00      0.92      0.96        13\n",
      "          2       0.88      1.00      0.93         7\n",
      "\n",
      "avg / total       0.97      0.97      0.97        30\n",
      " \n",
      "\n",
      "--------\n",
      "Actual class predictions vs. true values:\n",
      "Y-hat :  [1 2 0 1 0 1 2 1 0 1 1 2 1 0 0 2 1 0 0 0 2 2 2 0 1 0 1 1 1 2]\n",
      "Y     :  [1 2 0 1 0 1 1 1 0 1 1 2 1 0 0 2 1 0 0 0 2 2 2 0 1 0 1 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Create the model and train it\n",
    "model = buildModel()\n",
    "model.fit(xTrain, yTrain, epochs = 200, batch_size = 5, verbose = 0)\n",
    "\n",
    "# Run the model against the test data\n",
    "scores = model.evaluate(xVal, yVal, verbose=0)\n",
    "print(\"Model error: %.2f%%\" % (100-scores[1]*100))\n",
    "\n",
    "# Examine the predictions for the classes\n",
    "preds = model.predict_classes(xVal)\n",
    "trueVals = np.argmax(yVal, axis = 1)\n",
    "\n",
    "print(\"Accuracy score: %.2f%%\" % (accuracy_score(trueVals, preds) * 100), \"\\n\")\n",
    "print(\"Confusion Matrix\\n\", confusion_matrix(trueVals, preds), \"\\n\")\n",
    "print(\"Classification Report\\n\", classification_report(trueVals, preds), \"\\n\")\n",
    "\n",
    "print(\"--------\")\n",
    "print(\"Actual class predictions vs. true values:\")\n",
    "print(\"Y-hat : \", preds)\n",
    "print(\"Y     : \", trueVals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll borrow a function we wrote in a previous write-up for [Sonar, Mines vs. Rocks](./Model-03.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuneModel(modelName, modelObj, params, returnModel = False, showSummary = True):\n",
    "    # Init vars and params\n",
    "    featureResults = {}\n",
    "    featureFolds = 10\n",
    "    featureSeed = 10\n",
    "\n",
    "    # Use accuracy since this is a classification problem\n",
    "    score = 'accuracy'\n",
    "\n",
    "    # Create a Pandas DF to hold all our spiffy results\n",
    "    featureDF = DataFrame(columns = ['Model', 'Accuracy', 'Best Params'])\n",
    "\n",
    "    # Create feature union\n",
    "    features = []\n",
    "    features.append(('Scaler', StandardScaler()))\n",
    "    featureUnion = FeatureUnion(features)\n",
    "\n",
    "    # Search for the best combination of parameters\n",
    "    featureResults = GridSearchCV(\n",
    "        Pipeline(\n",
    "            steps = [\n",
    "                ('FeatureUnion', featureUnion),\n",
    "                (modelName, modelObj)\n",
    "        ]),\n",
    "        param_grid = params,\n",
    "        scoring = score,\n",
    "        cv = KFold(n_splits = featureFolds, random_state = featureSeed)      \n",
    "    ).fit(xTrain, np.argmax(yTrain, axis=1))\n",
    "\n",
    "    featureDF.loc[len(featureDF)] = list([\n",
    "        modelName, \n",
    "        featureResults.best_score_,\n",
    "        featureResults.best_params_,\n",
    "    ])\n",
    "\n",
    "    if showSummary:\n",
    "        set_option('display.max_colwidth', -1)\n",
    "        display(featureDF)\n",
    "    \n",
    "    if returnModel:\n",
    "        return featureResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the following:  https://github.com/keras-team/keras/issues/9331\n",
    "\n",
    "Because a categorical transformation was applied to the `y` values above the following error was occuring:\n",
    "\n",
    "```\n",
    "ValueError: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets.\n",
    "```\n",
    "\n",
    "To resolve this the categorical transformation in the `tuneModel` function above needs to be reversed:\n",
    "\n",
    "```python\n",
    ").fit(xTrain, np.argmax(yTrain, axis=1))\n",
    "```\n",
    "\n",
    "Also note that the data inspection indicated the iris didn't need to have the `StandardScaler` applied.  However, for the sake of completeness that feature will be implemented in the `tuneModel` code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>irisTuned</td>\n",
       "      <td>0.96</td>\n",
       "      <td>{'irisTuned__batch_size': 1, 'irisTuned__epochs': 150}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  Accuracy                                             Best Params\n",
       "0  irisTuned  0.96      {'irisTuned__batch_size': 1, 'irisTuned__epochs': 150}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelName = \"irisTuned\"\n",
    "modelObj =  KerasClassifier(build_fn = buildModel, verbose = 0)\n",
    "params = {\n",
    "    'irisTuned__epochs' : makeRange(100, 200, 50, 1, 1),\n",
    "    'irisTuned__batch_size' : makeRange(1, 3, 1, 1, 1),\n",
    "}\n",
    "\n",
    "tuneModel(modelName, modelObj, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model error: 3.33%\n",
      "Accuracy score: 96.67% \n",
      "\n",
      "Confusion Matrix\n",
      " [[10  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0  7]] \n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        10\n",
      "          1       1.00      0.92      0.96        13\n",
      "          2       0.88      1.00      0.93         7\n",
      "\n",
      "avg / total       0.97      0.97      0.97        30\n",
      " \n",
      "\n",
      "--------\n",
      "Actual class predictions vs. true values:\n",
      "Y-hat :  [1 2 0 1 0 1 2 1 0 1 1 2 1 0 0 2 1 0 0 0 2 2 2 0 1 0 1 1 1 2]\n",
      "Y     :  [1 2 0 1 0 1 1 1 0 1 1 2 1 0 0 2 1 0 0 0 2 2 2 0 1 0 1 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Create the model and train it\n",
    "model = buildModel()\n",
    "model.fit(xTrain, yTrain, epochs = 150, batch_size = 1, verbose = 0)\n",
    "\n",
    "# Run the model against the test data\n",
    "scores = model.evaluate(xVal, yVal, verbose=0)\n",
    "print(\"Model error: %.2f%%\" % (100-scores[1]*100))\n",
    "\n",
    "# Examine the predictions for the classes\n",
    "preds = model.predict_classes(xVal)\n",
    "trueVals = np.argmax(yVal, axis = 1)\n",
    "\n",
    "print(\"Accuracy score: %.2f%%\" % (accuracy_score(trueVals, preds) * 100), \"\\n\")\n",
    "print(\"Confusion Matrix\\n\", confusion_matrix(trueVals, preds), \"\\n\")\n",
    "print(\"Classification Report\\n\", classification_report(trueVals, preds), \"\\n\")\n",
    "\n",
    "print(\"--------\")\n",
    "print(\"Actual class predictions vs. true values:\")\n",
    "print(\"Y-hat : \", preds)\n",
    "print(\"Y     : \", trueVals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not surprisingly we get pretty much the same results...."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
